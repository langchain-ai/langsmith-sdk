{"messages": [{"content": "how do i upload a pdf", "additional_kwargs": {}, "response_metadata": {}, "type": "human", "id": "acdae6e0-4fa7-459f-8906-67b9372aba8f", "example": false}, {"content": "To upload a PDF using LangChain, you can utilize the `PDFMinerLoader` or `PDFPlumberLoader`. Here\u2019s a brief overview of how to do it with each loader:\n\n### Using PDFMinerLoader\n1. **Install the required package**:\n   ```bash\n   pip install langchain_community\n   ```\n\n2. **Load the PDF**:\n   ```python\n   from langchain_community.document_loaders import PDFMinerLoader\n\n   file_path = \"./path_to_your_pdf/document.pdf\"\n   loader = PDFMinerLoader(file_path)\n   docs = loader.load()\n   ```\n\n### Using PDFPlumberLoader\n1. **Install the required package**:\n   ```bash\n   pip install langchain_community\n   ```\n\n2. **Load the PDF**:\n   ```python\n   from langchain_community.document_loaders import PDFPlumberLoader\n\n   loader = PDFPlumberLoader(\"./path_to_your_pdf/document.pdf\")\n   docs = loader.load()\n   ```\n\n### Notes\n- Both loaders will return a list of documents, where each document corresponds to a page in the PDF.\n- No special credentials are needed to use these loaders.\n\nFor more detailed information, you can refer to the API references for [PDFMinerLoader](https://python.langchain.com/api_reference/community/document_loaders/langchain_community.document_loaders.pdf.PDFMinerLoader.html) and [PDFPlumberLoader](https://python.langchain.com/api_reference/community/document_loaders/langchain_community.document_loaders.pdf.PDFPlumberLoader.html).", "additional_kwargs": {}, "response_metadata": {"finish_reason": "stop", "model_name": "gpt-4o-mini-2024-07-18", "system_fingerprint": "fp_0705bf87c0"}, "type": "ai", "id": "run-646bc662-d299-4ff8-9700-03482e843756", "example": false, "tool_calls": [], "invalid_tool_calls": []}, {"content": "https://www.cambridge.org/core/services/aop-cambridge-core/content/view/0D4357A9A6150E706CC261B86BA47733/S0008423923000793a.pdf/ascent_of_the_canadian_judicial_council_bill_c9_and_the_move_towards_judicialized_governance.pdf  can you open this to answer questions for me ", "additional_kwargs": {}, "response_metadata": {}, "type": "human", "id": "97919fe7-0599-486c-90d0-7355c6c587d1", "example": false}, {"content": "I'm unable to access external URLs or open documents directly. However, you can download the PDF from the provided link and then use LangChain to load it into your environment. Once you have the PDF loaded, you can ask questions based on its content.\n\nIf you need help with loading the PDF using LangChain, please let me know!", "additional_kwargs": {}, "response_metadata": {"finish_reason": "stop", "model_name": "gpt-4o-mini-2024-07-18", "system_fingerprint": "fp_0705bf87c0"}, "type": "ai", "id": "run-09e45f81-1165-41b1-82bd-faef49c1aa71", "example": false, "tool_calls": [], "invalid_tool_calls": []}], "steps": [], "documents": [{"metadata": {"language": "en", "description": "Portable Document Format (PDF), standardized as ISO 32000, is a file format developed by Adobe in 1992 to present documents, including text formatting and images, in a manner independent of application software, hardware, and operating systems.", "changefreq": "weekly", "source": "https://python.langchain.com/docs/how_to/document_loader_pdf/", "title": "How to load PDFs | \ud83e\udd9c\ufe0f\ud83d\udd17 LangChain", "lastmod": null, "content_type": null, "priority": "0.5", "loc": "https://python.langchain.com/docs/how_to/document_loader_pdf/", "uuid": "a3f9bbc3-306a-5a26-94ac-f0fe755afbb7"}, "page_content": "How to load PDFs | \ud83e\udd9c\ufe0f\ud83d\udd17 LangChain\n\n[Skip to main content](#__docusaurus_skipToContent_fallback)# How to load PDFs\n\n[Portable Document Format (PDF)](https://en.wikipedia.org/wiki/PDF), standardized as ISO 32000, is a file format developed by Adobe in 1992 to present documents, including text formatting and images, in a manner independent of application software, hardware, and operating systems.\n\nThis guide covers how to [load](/docs/concepts/document_loaders/) `PDF` documents into the LangChain [Document](https://python.langchain.com/api_reference/core/documents/langchain_core.documents.base.Document.html) format that we use downstream.\n\nText in PDFs is typically represented via text boxes. They may also contain images. A PDF parser might do some combination of the following:\n\n- Agglomerate text boxes into lines, paragraphs, and other structures via heuristics or ML inference;\n\n- Run [OCR](https://en.wikipedia.org/wiki/Optical_character_recognition) on images to detect text therein;\n\n- Classify text as belonging to paragraphs, lists, tables, or other structures;\n\n- Structure text into table rows and columns, or key-value pairs.\n\nLangChain integrates with a host of PDF parsers. Some are simple and relatively low-level; others will support OCR and image-processing, or perform advanced document layout analysis. The right choice will depend on your needs. Below we enumerate the possibilities.\n\nWe will demonstrate these approaches on a [sample file](https://github.com/langchain-ai/langchain/blob/master/libs/community/tests/integration_tests/examples/layout-parser-paper.pdf):\n\n```python\nfile_path = (\n    \"../../docs/integrations/document_loaders/example_data/layout-parser-paper.pdf\"\n)\n```\n\nA note on multimodal modelsMany modern LLMs support inference over multimodal inputs (e.g., images). In some applications -- such as question-answering over PDFs with complex layouts, diagrams, or scans -- it may be advantageous to skip the PDF parsing, instead casting a PDF page to an image and passing it to a model directly. We demonstrate an example of this in the [Use of multimodal models](/docs/how_to/document_loader_pdf/#use-of-multimodal-models) section below.\n\n## Simple and fast text extraction\u200b\n\nIf you are looking for a simple string representation of text that is embedded in a PDF, the method below is appropriate. It will return a list of [Document](https://python.langchain.com/api_reference/core/documents/langchain_core.documents.base.Document.html) objects-- one per page-- containing a single string of the page's text in the Document's `page_content` attribute. It will not parse text in images or scanned PDF pages. Under the hood it uses the [pypdf](https://pypdf.readthedocs.io/en/stable/) Python library.\n\nLangChain [document loaders](/docs/concepts/document_loaders/) implement `lazy_load` and its async variant, `alazy_load`, which return iterators of `Document` objects. We will use these below.\n\n```python\n%pip install -qU pypdf\n```\n\n```python\nfrom langchain_community.document_loaders import PyPDFLoader\n\nloader = PyPDFLoader(file_path)\npages = []\nasync for page in loader.alazy_load():\n    pages.append(page)\n```\n\n**API Reference:**[PyPDFLoader](https://python.langchain.com/api_reference/community/document_loaders/langchain_community.document_loaders.pdf.PyPDFLoader.html)\n```python\nprint(f\"{pages[0].metadata}\\n\")\nprint(pages[0].page_content)\n```\n\n```output\n{'source': '../../docs/integrations/document_loaders/example_data/layout-parser-paper.pdf', 'page': 0}", "type": "Document"}, {"metadata": {"description": "Overview", "language": "en", "changefreq": "weekly", "source": "https://python.langchain.com/docs/integrations/document_loaders/unstructured_pdfloader/", "title": "UnstructuredPDFLoader | \ud83e\udd9c\ufe0f\ud83d\udd17 LangChain", "lastmod": null, "content_type": null, "priority": "0.5", "loc": "https://python.langchain.com/docs/integrations/document_loaders/unstructured_pdfloader/", "uuid": "8e7d3de8-e7e7-5cc2-bee5-618901e9e15f"}, "page_content": "**API Reference:**[OnlinePDFLoader](https://python.langchain.com/api_reference/community/document_loaders/langchain_community.document_loaders.pdf.OnlinePDFLoader.html)\n```output", "type": "Document"}, {"metadata": {"description": "Overview", "language": "en", "changefreq": "weekly", "source": "https://python.langchain.com/docs/integrations/document_loaders/unstructured_pdfloader/", "title": "UnstructuredPDFLoader | \ud83e\udd9c\ufe0f\ud83d\udd17 LangChain", "lastmod": null, "content_type": null, "priority": "0.5", "loc": "https://python.langchain.com/docs/integrations/document_loaders/unstructured_pdfloader/", "uuid": "f896de9c-6074-587c-8ebd-21697b8fcf4e"}, "page_content": "```python\nprint(docs[0].metadata)\n```\n\n```output\n{'source': './example_data/layout-parser-paper.pdf'}\n```\n\n### Retain Elements\u200b\n\nUnder the hood, Unstructured creates different \"elements\" for different chunks of text. By default we combine those together, but you can easily keep that separation by specifying `mode=\"elements\"`.\n\n```python\nfile_path = \"./example_data/layout-parser-paper.pdf\"\nloader = UnstructuredPDFLoader(file_path, mode=\"elements\")\n\ndata = loader.load()\ndata[0]\n```\n\n```output\nDocument(metadata={'source': './example_data/layout-parser-paper.pdf', 'coordinates': {'points': ((16.34, 213.36), (16.34, 253.36), (36.34, 253.36), (36.34, 213.36)), 'system': 'PixelSpace', 'layout_width': 612, 'layout_height': 792}, 'file_directory': './example_data', 'filename': 'layout-parser-paper.pdf', 'languages': ['eng'], 'last_modified': '2024-07-25T21:28:58', 'page_number': 1, 'filetype': 'application/pdf', 'category': 'UncategorizedText', 'element_id': 'd3ce55f220dfb75891b4394a18bcb973'}, page_content='1 2 0 2')\n```\n\nSee the full set of element types for this particular document:\n\n```python\nset(doc.metadata[\"category\"] for doc in data)\n```\n\n```output\n{'ListItem', 'NarrativeText', 'Title', 'UncategorizedText'}\n```\n\n### Fetching remote PDFs using Unstructured\u200b\n\nThis covers how to load online PDFs into a document format that we can use downstream. This can be used for various online PDF sites such as [https://open.umn.edu/opentextbooks/textbooks/](https://open.umn.edu/opentextbooks/textbooks/) and [https://arxiv.org/archive/](https://arxiv.org/archive/)\n\nNote: all other PDF loaders can also be used to fetch remote PDFs, but `OnlinePDFLoader` is a legacy function, and works specifically with `UnstructuredPDFLoader`.\n\n```python\nfrom langchain_community.document_loaders import OnlinePDFLoader\n\nloader = OnlinePDFLoader(\"https://arxiv.org/pdf/2302.03803.pdf\")\ndata = loader.load()\ndata[0]\n```", "type": "Document"}, {"metadata": {"language": "en", "description": "DocumentLoaders load data into the standard LangChain Document format.", "changefreq": "weekly", "source": "https://python.langchain.com/docs/integrations/document_loaders/", "title": "Document loaders | \ud83e\udd9c\ufe0f\ud83d\udd17 LangChain", "content_type": null, "lastmod": null, "priority": "0.5", "loc": "https://python.langchain.com/docs/integrations/document_loaders/", "uuid": "cbcffc89-a3d2-5630-9fc5-b89ee88d3d68"}, "page_content": "#### Was this page helpful?\n\n- [Webpages](#webpages)\n\n- [PDFs](#pdfs)\n\n- [Cloud Providers](#cloud-providers)\n\n- [Social Platforms](#social-platforms)\n\n- [Messaging Services](#messaging-services)\n\n- [Productivity tools](#productivity-tools)\n\n- [Common File Types](#common-file-types)\n\n- [All document loaders](#all-document-loaders)", "type": "Document"}, {"metadata": {"description": "Overview", "language": "en", "changefreq": "weekly", "source": "https://python.langchain.com/docs/integrations/document_loaders/pdfminer/", "title": "PDFMiner | \ud83e\udd9c\ufe0f\ud83d\udd17 LangChain", "content_type": null, "lastmod": null, "priority": "0.5", "loc": "https://python.langchain.com/docs/integrations/document_loaders/pdfminer/", "uuid": "85d9d38c-a640-5f59-b00d-5ff43f93ac91"}, "page_content": "5 shows two examples of how\\n<br></span><span style=\"font-family: CMTT10; font-size:9px\">LayoutParser </span><span style=\"font-family: CMR10; font-size:9px\">can be used in practical DIA projects, and Section 6 concludes.\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:134px; top:1990px; width:102px; height:11px;\"><span style=\"font-family: CMBX12; font-size:11px\">2 Related Work\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:134px; top:2016px; width:347px; height:81px;\"><span style=\"font-family: CMR10; font-size:9px\">Recently, various DL models and datasets have been developed for layout analysis\\n<br>tasks. The dhSegment [22] utilizes fully convolutional networks [20] for segmen-\\n<br>tation tasks on historical documents. Object detection-based methods like Faster\\n<br>R-CNN [28] and Mask R-CNN [12] are used for identifying document elements [38]\\n<br>and detecting tables [30, 26]. Most recently, Graph Neural Networks [29] have also\\n<br>been used in table detection [27]. However, these models are usually implemented\\n<br>individually and there is no uni\ufb01ed framework to load and use such models.\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:134px; top:2100px; width:348px; height:189px;\"><span style=\"font-family: CMR10; font-size:9px\">There has been a surge of interest in creating open-source tools for document\\n<br>image processing: a search of </span><span style=\"font-family: CMTT10; font-size:9px\">document image analysis </span><span style=\"font-family: CMR10; font-size:9px\">in Github leads to 5M\\n<br>relevant code pieces </span><span style=\"font-family: CMR7; font-size:6px\">6</span><span style=\"font-family: CMR10; font-size:9px\">; yet most of them rely on traditional rule-based methods\\n<br>or provide limited functionalities. The closest prior research to our work is the\\n<br>OCR-D project</span><span style=\"font-family: CMR7; font-size:6px\">7</span><span style=\"font-family: CMR10; font-size:9px\">, which also tries to build a complete toolkit for DIA. However,\\n<br>similar to the platform developed by Neudecker et al. [21], it is designed for\\n<br>analyzing historical documents, and provides no supports for recent DL models.\\n<br>The </span><span style=\"font-family: CMTT10; font-size:9px\">DocumentLayoutAnalysis </span><span style=\"font-family: CMR10; font-size:9px\">project</span><span style=\"font-family: CMR7; font-size:6px\">8 </span><span style=\"font-family: CMR10; font-size:9px\">focuses on processing born-digital PDF\\n<br>documents via analyzing the stored PDF data. Repositories like </span><span style=\"font-family: CMTT10; font-size:9px\">DeepLayout</span><span style=\"font-family: CMR7; font-size:6px\">9\\n<br></span><span style=\"font-family: CMR10; font-size:9px\">and </span><span style=\"font-family: CMTT10; font-size:9px\">Detectron2-PubLayNet</span><span style=\"font-family: CMR7; font-size:6px\">10 </span><span style=\"font-family: CMR10; font-size:9px\">are individual deep learning models trained on\\n<br>layout analysis datasets without support for the full DIA pipeline. The Document\\n<br>Analysis and Exploitation (DAE) platform [15] and the DeepDIVA project [2]\\n<br>aim to improve the reproducibility of DIA methods (or DL models), yet they\\n<br>are not actively maintained. OCR engines like </span><span style=\"font-family: CMTT10; font-size:9px\">Tesseract </span><span style=\"font-family: CMR10; font-size:9px\">[14], </span><span style=\"font-family: CMTT10; font-size:9px\">easyOCR</span><span style=\"font-family: CMR7; font-size:6px\">11 </span><span style=\"font-family: CMR10; font-size:9px\">and\\n<br></span><span style=\"font-family: CMTT10; font-size:9px\">paddleOCR</span><span style=\"font-family: CMR7; font-size:6px\">12 </span><span style=\"font-family: CMR10; font-size:9px\">usually do not come with comprehensive functionalities for other\\n<br>DIA tasks like layout", "type": "Document"}, {"metadata": {"description": "Overview", "language": "en", "changefreq": "weekly", "source": "https://python.langchain.com/docs/integrations/document_loaders/pdfminer/", "title": "PDFMiner | \ud83e\udd9c\ufe0f\ud83d\udd17 LangChain", "lastmod": null, "content_type": null, "priority": "0.5", "loc": "https://python.langchain.com/docs/integrations/document_loaders/pdfminer/", "uuid": "c86c93ad-5ca1-59e1-8dfe-832cf69ffa35"}, "page_content": "CMR9; font-size:8px\">the maximum is 1.\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:133px; top:9955px; width:348px; height:10px;\"><span style=\"font-family: CMR6; font-size:5px\">17 </span><span style=\"font-family: CMR9; font-size:8px\">This measures the number of edits from the ground-truth text to the predicted text,\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:144px; top:9967px; width:78px; height:8px;\"><span style=\"font-family: CMR9; font-size:8px\">and lower is better.\\n<br></span></div><span style=\"position:absolute; border: black 1px solid; left:134px; top:9931px; width:56px; height:0px;\"></span>\\n<span style=\"position:absolute; border: gray 1px solid; left:0px; top:10154px; width:612px; height:792px;\"></span>\\n<div style=\"position:absolute; top:10154px;\"><a name=\"13\">Page 13</a></div>\\n<div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:237px; top:10246px; width:210px; height:9px;\"><span style=\"font-family: CMTT9; font-size:8px\">LayoutParser</span><span style=\"font-family: CMR9; font-size:8px\">: A Uni\ufb01ed Toolkit for DL-Based DIA\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:471px; top:10246px; width:9px; height:8px;\"><span style=\"font-family: CMR9; font-size:8px\">13\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:134px; top:10398px; width:346px; height:45px;\"><span style=\"font-family: CMR10; font-size:9px\">Fig. 6: This lightweight table detector can identify tables (outlined in red) and\\n<br>cells (shaded in blue) in di\ufb00erent locations on a page. In very few cases (d), it\\n<br>might generate minor error predictions, e.g, failing to capture the top text line of\\n<br></span><span style=\"font-family: CMR10; font-size:9px\">a table.\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:134px; top:10478px; width:216px; height:9px;\"><span style=\"font-family: CMBX10; font-size:9px\">5.2 A light-weight Visual Table Extractor\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:134px; top:10518px; width:347px; height:81px;\"><span style=\"font-family: CMR10; font-size:9px\">Detecting tables and parsing their structures (table extraction) are of central im-\\n<br>portance for many document digitization tasks. Many previous works [26, 30, 27]\\n<br>and tools </span><span style=\"font-family: CMR7; font-size:6px\">18 </span><span style=\"font-family: CMR10; font-size:9px\">have been developed to identify and parse table structures. Yet they\\n<br>might require training complicated models from scratch, or are only applicable\\n<br>for born-digital PDF documents. In this section, we show how </span><span style=\"font-family: CMTT10; font-size:9px\">LayoutParser </span><span style=\"font-family: CMR10; font-size:9px\">can\\n<br>help build a light-weight accurate visual table extractor for legal docket tables\\n<br>using the existing resources with minimal e\ufb00ort.\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:134px; top:10606px; width:347px; height:177px;\"><span style=\"font-family: CMR10; font-size:9px\">The extractor uses a pre-trained layout detection model for identifying the\\n<br>table regions and some simple rules for pairing the rows and the columns in the\\n<br>PDF image. Mask R-CNN [12] trained on the PubLayNet dataset [38] from the\\n<br></span><span style=\"font-family: CMTT10; font-size:9px\">LayoutParser </span><span style=\"font-family: CMR10; font-size:9px\">Model Zoo can be used for detecting table regions. By \ufb01ltering\\n<br>out model predictions of low con\ufb01dence and removing overlapping predictions,\\n<br></span><span style=\"font-family: CMTT10; font-size:9px\">LayoutParser </span><span style=\"font-family: CMR10; font-size:9px\">can identify the tabular", "type": "Document"}, {"metadata": {"description": "Portable Document Format (PDF), standardized as ISO 32000, is a file format developed by Adobe in 1992 to present documents, including text formatting and images, in a manner independent of application software, hardware, and operating systems.", "language": "en", "changefreq": "weekly", "source": "https://python.langchain.com/docs/how_to/document_loader_pdf/", "title": "How to load PDFs | \ud83e\udd9c\ufe0f\ud83d\udd17 LangChain", "content_type": null, "lastmod": null, "priority": "0.5", "loc": "https://python.langchain.com/docs/how_to/document_loader_pdf/", "uuid": "5a2a91d5-0d47-5a95-8791-d9a4adade490"}, "page_content": "```output\n{'source': '../../docs/integrations/document_loaders/example_data/layout-parser-paper.pdf', 'page': 0}\n\nLayoutParser : A Uni\ufb01ed Toolkit for Deep\nLearning Based Document Image Analysis\nZejiang Shen1( \ufffd), Ruochen Zhang2, Melissa Dell3, Benjamin Charles Germain\nLee4, Jacob Carlson3, and Weining Li5\n1Allen Institute for AI\nshannons@allenai.org\n2Brown University\nruochen zhang@brown.edu\n3Harvard University\n{melissadell,jacob carlson }@fas.harvard.edu\n4University of Washington\nbcgl@cs.washington.edu\n5University of Waterloo\nw422li@uwaterloo.ca\nAbstract. Recent advances in document image analysis (DIA) have been\nprimarily driven by the application of neural networks. Ideally, research\noutcomes could be easily deployed in production and extended for further\ninvestigation. However, various factors like loosely organized codebases\nand sophisticated model con\ufb01gurations complicate the easy reuse of im-\nportant innovations by a wide audience. Though there have been on-going\ne\ufb00orts to improve reusability and simplify deep learning (DL) model\ndevelopment in disciplines like natural language processing and computer\nvision, none of them are optimized for challenges in the domain of DIA.\nThis represents a major gap in the existing toolkit, as DIA is central to\nacademic research across a wide range of disciplines in the social sciences\nand humanities. This paper introduces LayoutParser , an open-source\nlibrary for streamlining the usage of DL in DIA research and applica-\ntions. The core LayoutParser library comes with a set of simple and\nintuitive interfaces for applying and customizing DL models for layout de-\ntection, character recognition, and many other document processing tasks.\nTo promote extensibility, LayoutParser also incorporates a community\nplatform for sharing both pre-trained models and full document digiti-\nzation pipelines. We demonstrate that LayoutParser is helpful for both\nlightweight and large-scale digitization pipelines in real-word use cases.\nThe library is publicly available at https://layout-parser.github.io .\nKeywords: Document Image Analysis \u00b7Deep Learning \u00b7Layout Analysis\n\u00b7Character Recognition \u00b7Open Source library \u00b7Toolkit.\n1 Introduction\nDeep Learning(DL)-based approaches are the state-of-the-art for a wide range of\ndocument image analysis (DIA) tasks including document image classi\ufb01cation [ 11,arXiv:2103.15348v2  [cs.CV]  21 Jun 2021\n```\n\nNote that the metadata of each document stores the corresponding page number.\n\n### Vector search over PDFs\u200b\n\nOnce we have loaded PDFs into LangChain `Document` objects, we can index them (e.g., a RAG application) in the usual way. Below we use OpenAI embeddings, although any LangChain [embeddings](https://python.langchain.com/docs/concepts/embedding_models) model will suffice.\n\n```python\n%pip install -qU langchain-openai\n```\n\n```python\nimport getpass\nimport os\n\nif \"OPENAI_API_KEY\" not in os.environ:\n    os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"OpenAI API Key:\")\n```\n\n```python\nfrom langchain_core.vectorstores import InMemoryVectorStore\nfrom langchain_openai import OpenAIEmbeddings\n\nvector_store = InMemoryVectorStore.from_documents(pages, OpenAIEmbeddings())\ndocs = vector_store.similarity_search(\"What is LayoutParser?\", k=2)\nfor doc in docs:\n    print(f'Page {doc.metadata[\"page\"]}: {doc.page_content[:300]}\\n')\n```\n\n**API Reference:**[InMemoryVectorStore](https://python.langchain.com/api_reference/core/vectorstores/langchain_core.vectorstores.in_memory.InMemoryVectorStore.html) | [OpenAIEmbeddings](https://python.langchain.com/api_reference/openai/embeddings/langchain_openai.embeddings.base.OpenAIEmbeddings.html)\n```output\nPage 13: 14 Z. Shen et al.\n6 Conclusion\nLayoutParser provides a comprehensive toolkit for deep learning-based document\nimage analysis. The o\ufb00-the-shelf library is easy to install, and can be used to\nbuild \ufb02exible and accurate pipelines for processing documents with complicated\nstructures. It also supports hi", "type": "Document"}, {"metadata": {"language": "en", "description": "The pace of AI application development is often rate-limited by high-quality evaluations because there is a paradox of choice. Developers often wonder how to engineer their prompt or which LLM best balances accuracy, latency, and cost. High quality evaluations can help you rapidly answer these types of questions with confidence.", "changefreq": null, "source": "https://docs.smith.langchain.com/evaluation/concepts", "title": "Concepts | \ud83e\udd9c\ufe0f\ud83d\udee0\ufe0f LangSmith", "content_type": "text/html; charset=utf-8", "lastmod": null, "priority": null, "loc": null, "uuid": "e07006e1-3edd-5630-8851-49f0e2518263"}, "page_content": "Use CaseDetailReference-free?LLM-as-judge?Pairwise relevantCriteriaTag if specific criteria is metYesYes - promptNoAccuracyStandard definitionNo (ground truth class)NoNoPrecisionStandard definitionNo (ground truth class)NoNoRecallStandard definitionNo (ground truth class)NoNoWas this page helpful?You can leave detailed feedback on GitHub.PreviousQuick StartNextEvaluation how-to guidesDatasetsCreating datasetsPartitioning datasetsEvaluatorsHumanHeuristicLLM-as-judgePairwiseApplying evaluationsUnit TestsRegression TestingBack-testingPairwise-testingOnline EvaluationExperiment ConfigurationsAgentsEvaluating an agent's final responseEvaluating a single step of an agentEvaluating an agent's trajectoryBest practicesRetrieval Augmented Generation (RAG)DatasetEvaluatorApplying RAG EvaluationRAG evaluation summaryCommon use-casesSummarizationClassification / TaggingCommunityDiscordTwitterGitHubDocs CodeLangSmith SDKPythonJS/TSMoreHomepageBlogLangChain Python DocsLangChain JS/TS DocsCopyright \u00a9 2024 LangChain, Inc.", "type": "Document"}, {"metadata": {"description": "AnalyticDB for PostgreSQL is a massively parallel processing (MPP) data warehousing service that is designed to analyze large volumes of data online.", "language": "en", "changefreq": "weekly", "source": "https://python.langchain.com/docs/integrations/vectorstores/analyticdb/", "title": "AnalyticDB | \ud83e\udd9c\ufe0f\ud83d\udd17 LangChain", "content_type": null, "lastmod": null, "priority": "0.5", "loc": "https://python.langchain.com/docs/integrations/vectorstores/analyticdb/", "uuid": "602e584b-8d9f-574d-9391-97abe4a39b64"}, "page_content": "Tonight, I\u2019d like to honor someone who has dedicated his life to serve this country: Justice Stephen Breyer\u2014an Army veteran, Constitutional scholar, and retiring Justice of the United States Supreme Court. Justice Breyer, thank you for your service. \n\nOne of the most serious constitutional responsibilities a President has is nominating someone to serve on the United States Supreme Court. \n\nAnd I did that 4 days ago, when I nominated Circuit Court of Appeals Judge Ketanji Brown Jackson. One of our nation\u2019s top legal minds, who will continue Justice Breyer\u2019s legacy of excellence.\n```\n\n## Related\u200b\n\n- Vector store [conceptual guide](/docs/concepts/vectorstores/)\n\n- Vector store [how-to guides](/docs/how_to/#vector-stores)\n\n#### Was this page helpful?\n\n- [Related](#related)", "type": "Document"}, {"metadata": {"description": "Hologres is a unified real-time data warehousing service developed by Alibaba Cloud. You can use Hologres to write, update, process, and analyze large amounts of data in real time.", "language": "en", "changefreq": "weekly", "source": "https://python.langchain.com/docs/integrations/vectorstores/hologres/", "title": "Hologres | \ud83e\udd9c\ufe0f\ud83d\udd17 LangChain", "content_type": null, "lastmod": null, "priority": "0.5", "loc": "https://python.langchain.com/docs/integrations/vectorstores/hologres/", "uuid": "ab394f69-6b1c-5a06-8672-ad6c91feda6f"}, "page_content": "Tonight, I\u2019d like to honor someone who has dedicated his life to serve this country: Justice Stephen Breyer\u2014an Army veteran, Constitutional scholar, and retiring Justice of the United States Supreme Court. Justice Breyer, thank you for your service. \n\nOne of the most serious constitutional responsibilities a President has is nominating someone to serve on the United States Supreme Court. \n\nAnd I did that 4 days ago, when I nominated Circuit Court of Appeals Judge Ketanji Brown Jackson. One of our nation\u2019s top legal minds, who will continue Justice Breyer\u2019s legacy of excellence.\n```\n\n## Related\u200b\n\n- Vector store [conceptual guide](/docs/concepts/vectorstores/)\n\n- Vector store [how-to guides](/docs/how_to/#vector-stores)\n\n#### Was this page helpful?\n\n- [Related](#related)", "type": "Document"}, {"metadata": {"description": "One challenge with retrieval is that usually you don't know the specific queries your document storage system will face when you ingest data into the system. This means that the information most relevant to a query may be buried in a document with a lot of irrelevant text. Passing that full document through your application can lead to more expensive LLM calls and poorer responses.", "language": "en", "changefreq": "weekly", "source": "https://python.langchain.com/docs/how_to/contextual_compression/", "title": "How to do retrieval with contextual compression | \ud83e\udd9c\ufe0f\ud83d\udd17 LangChain", "lastmod": null, "content_type": null, "priority": "0.5", "loc": "https://python.langchain.com/docs/how_to/contextual_compression/", "uuid": "0e224cfa-3f17-580f-83cd-030c2df600c0"}, "page_content": "compressed_docs = compression_retriever.invoke(\n    \"What did the president say about Ketanji Jackson Brown\"\n)\npretty_print_docs(compressed_docs)\n```\n\n**API Reference:**[LLMListwiseRerank](https://python.langchain.com/api_reference/langchain/retrievers/langchain.retrievers.document_compressors.listwise_rerank.LLMListwiseRerank.html) | [ChatOpenAI](https://python.langchain.com/api_reference/openai/chat_models/langchain_openai.chat_models.base.ChatOpenAI.html)\n```output\nDocument 1:\n\nTonight. I call on the Senate to: Pass the Freedom to Vote Act. Pass the John Lewis Voting Rights Act. And while you\u2019re at it, pass the Disclose Act so Americans can know who is funding our elections. \n\nTonight, I\u2019d like to honor someone who has dedicated his life to serve this country: Justice Stephen Breyer\u2014an Army veteran, Constitutional scholar, and retiring Justice of the United States Supreme Court. Justice Breyer, thank you for your service. \n\nOne of the most serious constitutional responsibilities a President has is nominating someone to serve on the United States Supreme Court. \n\nAnd I did that 4 days ago, when I nominated Circuit Court of Appeals Judge Ketanji Brown Jackson. One of our nation\u2019s top legal minds, who will continue Justice Breyer\u2019s legacy of excellence.\n```\n\n### EmbeddingsFilter\u200b\n\nMaking an extra LLM call over each retrieved document is expensive and slow. The `EmbeddingsFilter` provides a cheaper and faster option by embedding the documents and query and only returning those documents which have sufficiently similar embeddings to the query.\n\n```python\nfrom langchain.retrievers.document_compressors import EmbeddingsFilter\nfrom langchain_openai import OpenAIEmbeddings\n\nembeddings = OpenAIEmbeddings()\nembeddings_filter = EmbeddingsFilter(embeddings=embeddings, similarity_threshold=0.76)\ncompression_retriever = ContextualCompressionRetriever(\n    base_compressor=embeddings_filter, base_retriever=retriever\n)\n\ncompressed_docs = compression_retriever.invoke(\n    \"What did the president say about Ketanji Jackson Brown\"\n)\npretty_print_docs(compressed_docs)\n```\n\n**API Reference:**[EmbeddingsFilter](https://python.langchain.com/api_reference/langchain/retrievers/langchain.retrievers.document_compressors.embeddings_filter.EmbeddingsFilter.html) | [OpenAIEmbeddings](https://python.langchain.com/api_reference/openai/embeddings/langchain_openai.embeddings.base.OpenAIEmbeddings.html)\n```output\nDocument 1:\n\nTonight. I call on the Senate to: Pass the Freedom to Vote Act. Pass the John Lewis Voting Rights Act. And while you\u2019re at it, pass the Disclose Act so Americans can know who is funding our elections. \n\nTonight, I\u2019d like to honor someone who has dedicated his life to serve this country: Justice Stephen Breyer\u2014an Army veteran, Constitutional scholar, and retiring Justice of the United States Supreme Court. Justice Breyer, thank you for your service. \n\nOne of the most serious constitutional responsibilities a President has is nominating someone to serve on the United States Supreme Court. \n\nAnd I did that 4 days ago, when I nominated Circuit Court of Appeals Judge Ketanji Brown Jackson. One of our nation\u2019s top legal minds, who will continue Justice Breyer\u2019s legacy of excellence.\n----------------------------------------------------------------------------------------------------\nDocument 2:\n\nA former top litigator in private practice. A former federal public defender. And from a family of public school educators and police officers. A consensus builder. Since she\u2019s been nominated, she\u2019s received a broad range of support\u2014from the Fraternal Order of Police to former judges appointed by Democrats and Republicans. \n\nAnd if we are to advance liberty and justice, we need to secure the Border and fix the immigration system. \n\nWe can do both. At our border, we\u2019ve installed new technology like cutting-edge scanners to better detect drug smuggling.  \n\nWe\u2019ve set up joint patrols with Mexico and Guatemala to catch more human traffickers.", "type": "Document"}, {"metadata": {"description": "This notebook shows how to use DashScope Reranker for document compression and retrieval. DashScope is the generative AI service from Alibaba Cloud (Aliyun).", "language": "en", "changefreq": "weekly", "source": "https://python.langchain.com/docs/integrations/document_transformers/dashscope_rerank/", "title": "DashScope Reranker | \ud83e\udd9c\ufe0f\ud83d\udd17 LangChain", "content_type": null, "lastmod": null, "priority": "0.5", "loc": "https://python.langchain.com/docs/integrations/document_transformers/dashscope_rerank/", "uuid": "a9da7658-305c-5a2e-8f60-e5c6cc7296c2"}, "page_content": "One of the most serious constitutional responsibilities a President has is nominating someone to serve on the United States Supreme Court. \n\nAnd I did that 4 days ago, when I nominated Circuit Court of Appeals Judge Ketanji Brown Jackson. One of our nation\u2019s top legal minds, who will continue Justice Breyer\u2019s legacy of excellence.\n----------------------------------------------------------------------------------------------------\nDocument 3:\n\nTo all Americans, I will be honest with you, as I\u2019ve always promised. A Russian dictator, invading a foreign country, has costs around the world. \n\nAnd I\u2019m taking robust action to make sure the pain of our sanctions  is targeted at Russia\u2019s economy. And I will use every tool at our disposal to protect American businesses and consumers. \n\nTonight, I can announce that the United States has worked with 30 other countries to release 60 Million barrels of oil from reserves around the world.\n----------------------------------------------------------------------------------------------------\nDocument 4:\n\nWe cannot let this happen. \n\nTonight. I call on the Senate to: Pass the Freedom to Vote Act. Pass the John Lewis Voting Rights Act. And while you\u2019re at it, pass the Disclose Act so Americans can know who is funding our elections. \n\nTonight, I\u2019d like to honor someone who has dedicated his life to serve this country: Justice Stephen Breyer\u2014an Army veteran, Constitutional scholar, and retiring Justice of the United States Supreme Court. Justice Breyer, thank you for your service.\n----------------------------------------------------------------------------------------------------\nDocument 5:\n\nTonight I say to the Russian oligarchs and corrupt leaders who have bilked billions of dollars off this violent regime no more. \n\nThe U.S. Department of Justice is assembling a dedicated task force to go after the crimes of Russian oligarchs.  \n\nWe are joining with our European allies to find and seize your yachts your luxury apartments your private jets. We are coming for your ill-begotten gains.\n----------------------------------------------------------------------------------------------------\nDocument 6:\n\nEvery Administration says they\u2019ll do it, but we are actually doing it. \n\nWe will buy American to make sure everything from the deck of an aircraft carrier to the steel on highway guardrails are made in America. \n\nBut to compete for the best jobs of the future, we also need to level the playing field with China and other competitors.\n----------------------------------------------------------------------------------------------------\nDocument 7:\n\nWhen we invest in our workers, when we build the economy from the bottom up and the middle out together, we can do something we haven\u2019t done in a long time: build a better America. \n\nFor more than two years, COVID-19 has impacted every decision in our lives and the life of the nation. \n\nAnd I know you\u2019re tired, frustrated, and exhausted. \n\nBut I also know this.\n----------------------------------------------------------------------------------------------------\nDocument 8:\n\nA former top litigator in private practice. A former federal public defender. And from a family of public school educators and police officers. A consensus builder. Since she\u2019s been nominated, she\u2019s received a broad range of support\u2014from the Fraternal Order of Police to former judges appointed by Democrats and Republicans. \n\nAnd if we are to advance liberty and justice, we need to secure the Border and fix the immigration system.\n----------------------------------------------------------------------------------------------------\nDocument 9:\n\nMy plan will not only lower costs to give families a fair shot, it will lower the deficit. \n\nThe previous Administration not only ballooned the deficit with tax cuts for the very wealthy and corporations, it undermined the watchdogs whose job was to keep pandemic relief funds from being wasted.", "type": "Document"}, {"metadata": {"description": "When splitting documents for retrieval, there are often conflicting desires:", "language": "en", "changefreq": "weekly", "source": "https://python.langchain.com/docs/how_to/parent_document_retriever/", "title": "How to use the Parent Document Retriever | \ud83e\udd9c\ufe0f\ud83d\udd17 LangChain", "lastmod": null, "content_type": null, "priority": "0.5", "loc": "https://python.langchain.com/docs/how_to/parent_document_retriever/", "uuid": "5c24f9cf-90e6-52f4-8da6-d8535cfad74d"}, "page_content": "```python\nretrieved_docs = retriever.invoke(\"justice breyer\")\n```\n\n```python\nlen(retrieved_docs[0].page_content)\n```\n\n```output\n38540\n```\n\n## Retrieving larger chunks\u200b\n\nSometimes, the full documents can be too big to want to retrieve them as is. In that case, what we really want to do is to first split the raw documents into larger chunks, and then split it into smaller chunks. We then index the smaller chunks, but on retrieval we retrieve the larger chunks (but still not the full documents).\n\n```python\n# This text splitter is used to create the parent documents\nparent_splitter = RecursiveCharacterTextSplitter(chunk_size=2000)\n# This text splitter is used to create the child documents\n# It should create documents smaller than the parent\nchild_splitter = RecursiveCharacterTextSplitter(chunk_size=400)\n# The vectorstore to use to index the child chunks\nvectorstore = Chroma(\n    collection_name=\"split_parents\", embedding_function=OpenAIEmbeddings()\n)\n# The storage layer for the parent documents\nstore = InMemoryStore()\n```\n\n```python\nretriever = ParentDocumentRetriever(\n    vectorstore=vectorstore,\n    docstore=store,\n    child_splitter=child_splitter,\n    parent_splitter=parent_splitter,\n)\n```\n\n```python\nretriever.add_documents(docs)\n```\n\nWe can see that there are much more than two documents now - these are the larger chunks.\n\n```python\nlen(list(store.yield_keys()))\n```\n\n```output\n66\n```\n\nLet's make sure the underlying vector store still retrieves the small chunks.\n\n```python\nsub_docs = vectorstore.similarity_search(\"justice breyer\")\n```\n\n```python\nprint(sub_docs[0].page_content)\n```\n\n```output\nTonight, I\u2019d like to honor someone who has dedicated his life to serve this country: Justice Stephen Breyer\u2014an Army veteran, Constitutional scholar, and retiring Justice of the United States Supreme Court. Justice Breyer, thank you for your service. \n\nOne of the most serious constitutional responsibilities a President has is nominating someone to serve on the United States Supreme Court.\n```\n\n```python\nretrieved_docs = retriever.invoke(\"justice breyer\")\n```\n\n```python\nlen(retrieved_docs[0].page_content)\n```\n\n```output\n1849\n```\n\n```python\nprint(retrieved_docs[0].page_content)\n```\n\n```output\nIn state after state, new laws have been passed, not only to suppress the vote, but to subvert entire elections. \n\nWe cannot let this happen. \n\nTonight. I call on the Senate to: Pass the Freedom to Vote Act. Pass the John Lewis Voting Rights Act. And while you\u2019re at it, pass the Disclose Act so Americans can know who is funding our elections. \n\nTonight, I\u2019d like to honor someone who has dedicated his life to serve this country: Justice Stephen Breyer\u2014an Army veteran, Constitutional scholar, and retiring Justice of the United States Supreme Court. Justice Breyer, thank you for your service. \n\nOne of the most serious constitutional responsibilities a President has is nominating someone to serve on the United States Supreme Court. \n\nAnd I did that 4 days ago, when I nominated Circuit Court of Appeals Judge Ketanji Brown Jackson. One of our nation\u2019s top legal minds, who will continue Justice Breyer\u2019s legacy of excellence. \n\nA former top litigator in private practice. A former federal public defender. And from a family of public school educators and police officers. A consensus builder. Since she\u2019s been nominated, she\u2019s received a broad range of support\u2014from the Fraternal Order of Police to former judges appointed by Democrats and Republicans. \n\nAnd if we are to advance liberty and justice, we need to secure the Border and fix the immigration system. \n\nWe can do both. At our border, we\u2019ve installed new technology like cutting-edge scanners to better detect drug smuggling.  \n\nWe\u2019ve set up joint patrols with Mexico and Guatemala to catch more human traffickers.  \n\nWe\u2019re putting in place dedicated immigration judges so families fleeing persecution and violence can have their cases heard faster.", "type": "Document"}, {"metadata": {"description": "UpTrain [github || website || docs] is an open-source platform to evaluate and improve LLM applications. It provides grades for 20+ preconfigured checks (covering language, code, embedding use cases), performs root cause analyses on instances of failure cases and provides guidance for resolving them.", "language": "en", "changefreq": "weekly", "source": "https://python.langchain.com/docs/integrations/callbacks/uptrain/", "title": "uptrain | \ud83e\udd9c\ufe0f\ud83d\udd17 LangChain", "lastmod": null, "content_type": null, "priority": "0.5", "loc": "https://python.langchain.com/docs/integrations/callbacks/uptrain/", "uuid": "6c5602df-140a-5c31-b5f5-cc188744c2ee"}, "page_content": "Question: What did the president say about Ketanji Brown Jackson\nResponse: The president mentioned that he had nominated Ketanji Brown Jackson to serve on the United States Supreme Court 4 days ago. He described her as one of the nation's top legal minds who will continue Justice Breyer\u2019s legacy of excellence. He also mentioned that she is a former top litigator in private practice, a former federal public defender, and comes from a family of public school educators and police officers. He described her as a consensus builder and noted that since her nomination, she has received a broad range of support from various groups, including the Fraternal Order of Police and former judges appointed by both Democrats and Republicans.\n\nContext Relevance Score: 1.0\nFactual Accuracy Score: 1.0\nResponse Completeness Score: 1.0\n```\n\n# 2. Multi Query Generation\n\nThe **MultiQueryRetriever** is used to tackle the problem that the RAG pipeline might not return the best set of documents based on the query. It generates multiple queries that mean the same as the original query and then fetches documents for each.\n\nTo evluate this retriever, UpTrain will run the following evaluation:\n\n- **Multi Query Accuracy**: Checks if the multi-queries generated mean the same as the original query.\n\n```python\n# Create the retriever\nmulti_query_retriever = MultiQueryRetriever.from_llm(retriever=retriever, llm=llm)\n\n# Create the uptrain callback\nuptrain_callback = UpTrainCallbackHandler(key_type=KEY_TYPE, api_key=API_KEY)\nconfig = {\"callbacks\": [uptrain_callback]}\n\n# Create the RAG prompt\ntemplate = \"\"\"Answer the question based only on the following context, which can include text and tables:\n{context}\nQuestion: {question}\n\"\"\"\nrag_prompt_text = ChatPromptTemplate.from_template(template)\n\nchain = (\n    {\"context\": multi_query_retriever, \"question\": RunnablePassthrough()}\n    | rag_prompt_text\n    | llm\n    | StrOutputParser()\n)\n\n# Invoke the chain with a query\nquestion = \"What did the president say about Ketanji Brown Jackson\"\ndocs = chain.invoke(question, config=config)\n```\n\n```output\n[32m2024-04-17 17:04:10.675[0m | [1mINFO    [0m | [36muptrain.framework.evalllm[0m:[36mevaluate_on_server[0m:[36m378[0m - [1mSending evaluation request for rows 0 to <50 to the Uptrain[0m\n[32m2024-04-17 17:04:16.804[0m | [1mINFO    [0m | [36muptrain.framework.evalllm[0m:[36mevaluate[0m:[36m367[0m - [1mLocal server not running, start the server to log data and visualize in the dashboard![0m\n``````output\n\nQuestion: What did the president say about Ketanji Brown Jackson\nMulti Queries:\n  - How did the president comment on Ketanji Brown Jackson?\n  - What were the president's remarks regarding Ketanji Brown Jackson?\n  - What statements has the president made about Ketanji Brown Jackson?\n\nMulti Query Accuracy Score: 0.5\n``````output\n[32m2024-04-17 17:04:22.027[0m | [1mINFO    [0m | [36muptrain.framework.evalllm[0m:[36mevaluate_on_server[0m:[36m378[0m - [1mSending evaluation request for rows 0 to <50 to the Uptrain[0m\n[32m2024-04-17 17:04:44.033[0m | [1mINFO    [0m | [36muptrain.framework.evalllm[0m:[36mevaluate[0m:[36m367[0m - [1mLocal server not running, start the server to log data and visualize in the dashboard![0m\n``````output\n\nQuestion: What did the president say about Ketanji Brown Jackson\nResponse: The president mentioned that he had nominated Circuit Court of Appeals Judge Ketanji Brown Jackson to serve on the United States Supreme Court 4 days ago. He described her as one of the nation's top legal minds who will continue Justice Breyer\u2019s legacy of excellence. He also mentioned that since her nomination, she has received a broad range of support\u2014from the Fraternal Order of Police to former judges appointed by Democrats and Republicans.\n\nContext Relevance Score: 1.0\nFactual Accuracy Score: 1.0\nResponse Completeness Score: 1.0\n```\n\n# 3. Context Compression and Reranking", "type": "Document"}, {"metadata": {"language": "en", "description": "Timescale Vector is PostgreSQL++ vector database for AI applications.", "changefreq": "weekly", "source": "https://python.langchain.com/docs/integrations/vectorstores/timescalevector/", "title": "Timescale Vector (Postgres) | \ud83e\udd9c\ufe0f\ud83d\udd17 LangChain", "content_type": null, "lastmod": null, "priority": "0.5", "loc": "https://python.langchain.com/docs/integrations/vectorstores/timescalevector/", "uuid": "97b75c76-ec70-52a3-a5bc-f34f7df23687"}, "page_content": "Tonight, I\u2019d like to honor someone who has dedicated his life to serve this country: Justice Stephen Breyer\u2014an Army veteran, Constitutional scholar, and retiring Justice of the United States Supreme Court. Justice Breyer, thank you for your service. \n\nOne of the most serious constitutional responsibilities a President has is nominating someone to serve on the United States Supreme Court. \n\nAnd I did that 4 days ago, when I nominated Circuit Court of Appeals Judge Ketanji Brown Jackson. One of our nation\u2019s top legal minds, who will continue Justice Breyer\u2019s legacy of excellence.\n--------------------------------------------------------------------------------\n--------------------------------------------------------------------------------\nScore:  0.18452197313308139\nTonight. I call on the Senate to: Pass the Freedom to Vote Act. Pass the John Lewis Voting Rights Act. And while you\u2019re at it, pass the Disclose Act so Americans can know who is funding our elections. \n\nTonight, I\u2019d like to honor someone who has dedicated his life to serve this country: Justice Stephen Breyer\u2014an Army veteran, Constitutional scholar, and retiring Justice of the United States Supreme Court. Justice Breyer, thank you for your service. \n\nOne of the most serious constitutional responsibilities a President has is nominating someone to serve on the United States Supreme Court. \n\nAnd I did that 4 days ago, when I nominated Circuit Court of Appeals Judge Ketanji Brown Jackson. One of our nation\u2019s top legal minds, who will continue Justice Breyer\u2019s legacy of excellence.\n--------------------------------------------------------------------------------\n--------------------------------------------------------------------------------\nScore:  0.21720781018594182\nA former top litigator in private practice. A former federal public defender. And from a family of public school educators and police officers. A consensus builder. Since she\u2019s been nominated, she\u2019s received a broad range of support\u2014from the Fraternal Order of Police to former judges appointed by Democrats and Republicans. \n\nAnd if we are to advance liberty and justice, we need to secure the Border and fix the immigration system. \n\nWe can do both. At our border, we\u2019ve installed new technology like cutting-edge scanners to better detect drug smuggling.  \n\nWe\u2019ve set up joint patrols with Mexico and Guatemala to catch more human traffickers.  \n\nWe\u2019re putting in place dedicated immigration judges so families fleeing persecution and violence can have their cases heard faster. \n\nWe\u2019re securing commitments and supporting partners in South and Central America to host more refugees and secure their own borders.\n--------------------------------------------------------------------------------\n--------------------------------------------------------------------------------\nScore:  0.21724902288621384\nA former top litigator in private practice. A former federal public defender. And from a family of public school educators and police officers. A consensus builder. Since she\u2019s been nominated, she\u2019s received a broad range of support\u2014from the Fraternal Order of Police to former judges appointed by Democrats and Republicans. \n\nAnd if we are to advance liberty and justice, we need to secure the Border and fix the immigration system. \n\nWe can do both. At our border, we\u2019ve installed new technology like cutting-edge scanners to better detect drug smuggling.  \n\nWe\u2019ve set up joint patrols with Mexico and Guatemala to catch more human traffickers.  \n\nWe\u2019re putting in place dedicated immigration judges so families fleeing persecution and violence can have their cases heard faster. \n\nWe\u2019re securing commitments and supporting partners in South and Central America to host more refugees and secure their own borders.\n--------------------------------------------------------------------------------\n```\n\n### Using a Timescale Vector as a Retriever\u200b", "type": "Document"}, {"metadata": {"description": "Intel's VDMS is a storage solution for efficient access of big-\u201dvisual\u201d-data that aims to achieve cloud scale by searching for relevant visual data via visual metadata stored as a graph and enabling machine friendly enhancements to visual data for faster access. VDMS is licensed under MIT.", "language": "en", "changefreq": "weekly", "source": "https://python.langchain.com/docs/integrations/vectorstores/vdms/", "title": "Intel's Visual Data Management System (VDMS) | \ud83e\udd9c\ufe0f\ud83d\udd17 LangChain", "lastmod": null, "content_type": null, "priority": "0.5", "loc": "https://python.langchain.com/docs/integrations/vectorstores/vdms/", "uuid": "4f15705d-8620-58e1-9dfd-0218bc8b858c"}, "page_content": "Metadata:\n\tid:\t32\n\tpage_number:\t32\n\tpresident_included:\tTrue\n\tsource:\t../../how_to/state_of_the_union.txt\n--------------------------------------------------\n\nContent:\n\tAs Frances Haugen, who is here with us tonight, has shown, we must hold social media platforms accountable for the national experiment they\u2019re conducting on our children for profit. \n\nIt\u2019s time to strengthen privacy protections, ban targeted advertising to children, demand tech companies stop collecting personal data on our children. \n\nAnd let\u2019s get all Americans the mental health services they need. More people they can turn to for help, and full parity between physical and mental health care. \n\nThird, support our veterans. \n\nVeterans are the best of us. \n\nI\u2019ve always believed that we have a sacred obligation to equip all those we send to war and care for them and their families when they come home. \n\nMy administration is providing assistance with job training and housing, and now helping lower-income veterans get VA care debt-free.  \n\nOur troops in Iraq and Afghanistan faced many dangers.\n\nMetadata:\n\tid:\t37\n\tpage_number:\t37\n\tpresident_included:\tFalse\n\tsource:\t../../how_to/state_of_the_union.txt\n--------------------------------------------------\n\nContent:\n\tA former top litigator in private practice. A former federal public defender. And from a family of public school educators and police officers. A consensus builder. Since she\u2019s been nominated, she\u2019s received a broad range of support\u2014from the Fraternal Order of Police to former judges appointed by Democrats and Republicans. \n\nAnd if we are to advance liberty and justice, we need to secure the Border and fix the immigration system. \n\nWe can do both. At our border, we\u2019ve installed new technology like cutting-edge scanners to better detect drug smuggling.  \n\nWe\u2019ve set up joint patrols with Mexico and Guatemala to catch more human traffickers.  \n\nWe\u2019re putting in place dedicated immigration judges so families fleeing persecution and violence can have their cases heard faster. \n\nWe\u2019re securing commitments and supporting partners in South and Central America to host more refugees and secure their own borders.\n\nMetadata:\n\tid:\t33\n\tpage_number:\t33\n\tpresident_included:\tFalse\n\tsource:\t../../how_to/state_of_the_union.txt\n--------------------------------------------------\n```\n\n```python\n# Query (with filtering)\nk = 3\nconstraints = {\"page_number\": [\">\", 30], \"president_included\": [\"==\", True]}\nquery = \"What did the president say about Ketanji Brown Jackson\"\nreturned_docs = db_FaissFlat.similarity_search(query, k=k, filter=constraints)\nprint_results(returned_docs, score=False)\n```\n\n```output\n--------------------------------------------------\n\nContent:\n\tTonight. I call on the Senate to: Pass the Freedom to Vote Act. Pass the John Lewis Voting Rights Act. And while you\u2019re at it, pass the Disclose Act so Americans can know who is funding our elections. \n\nTonight, I\u2019d like to honor someone who has dedicated his life to serve this country: Justice Stephen Breyer\u2014an Army veteran, Constitutional scholar, and retiring Justice of the United States Supreme Court. Justice Breyer, thank you for your service. \n\nOne of the most serious constitutional responsibilities a President has is nominating someone to serve on the United States Supreme Court. \n\nAnd I did that 4 days ago, when I nominated Circuit Court of Appeals Judge Ketanji Brown Jackson. One of our nation\u2019s top legal minds, who will continue Justice Breyer\u2019s legacy of excellence.\n\nMetadata:\n\tid:\t32\n\tpage_number:\t32\n\tpresident_included:\tTrue\n\tsource:\t../../how_to/state_of_the_union.txt\n--------------------------------------------------\n\nContent:\n\tAnd for our LGBTQ+ Americans, let\u2019s finally get the bipartisan Equality Act to my desk. The onslaught of state laws targeting transgender Americans and their families is wrong.", "type": "Document"}, {"metadata": {"description": "When working with files, like PDFs, you're likely to encounter text that exceeds your language model's context window. To process this text, consider these strategies:", "language": "en", "changefreq": "weekly", "source": "https://python.langchain.com/docs/how_to/extraction_long_text/", "title": "How to handle long text when doing extraction | \ud83e\udd9c\ufe0f\ud83d\udd17 LangChain", "content_type": null, "lastmod": null, "priority": "0.5", "loc": "https://python.langchain.com/docs/how_to/extraction_long_text/", "uuid": "7dfd32a5-8904-50c5-b15c-624f51caf4e1"}, "page_content": "We suggest experimenting with your use case and determining whether this approach works or not.\n\nTo implement the RAG based approach:\n\n1. Chunk up your document(s) and index them (e.g., in a vectorstore);\n\n2. Prepend the `extractor` chain with a retrieval step using the vectorstore.\n\nHere's a simple example that relies on the `FAISS` vectorstore.\n\n```python\nfrom langchain_community.vectorstores import FAISS\nfrom langchain_core.documents import Document\nfrom langchain_core.runnables import RunnableLambda\nfrom langchain_openai import OpenAIEmbeddings\nfrom langchain_text_splitters import CharacterTextSplitter\n\ntexts = text_splitter.split_text(document.page_content)\nvectorstore = FAISS.from_texts(texts, embedding=OpenAIEmbeddings())\n\nretriever = vectorstore.as_retriever(\n    search_kwargs={\"k\": 1}\n)  # Only extract from first document\n```\n\n**API Reference:**[FAISS](https://python.langchain.com/api_reference/community/vectorstores/langchain_community.vectorstores.faiss.FAISS.html) | [Document](https://python.langchain.com/api_reference/core/documents/langchain_core.documents.base.Document.html) | [RunnableLambda](https://python.langchain.com/api_reference/core/runnables/langchain_core.runnables.base.RunnableLambda.html) | [OpenAIEmbeddings](https://python.langchain.com/api_reference/openai/embeddings/langchain_openai.embeddings.base.OpenAIEmbeddings.html) | [CharacterTextSplitter](https://python.langchain.com/api_reference/text_splitters/character/langchain_text_splitters.character.CharacterTextSplitter.html)\nIn this case the RAG extractor is only looking at the top document.\n\n```python\nrag_extractor = {\n    \"text\": retriever | (lambda docs: docs[0].page_content)  # fetch content of top doc\n} | extractor\n```\n\n```python\nresults = rag_extractor.invoke(\"Key developments associated with cars\")\n```\n\n```python\nfor key_development in results.key_developments:\n    print(key_development)\n```\n\n```output\nyear=2006 description='Car-sharing services in the US experienced double-digit growth in revenue and membership.' evidence='in the US, some car-sharing services have experienced double-digit growth in revenue and membership growth between 2006 and 2007.'\nyear=2020 description='56 million cars were manufactured worldwide, with China producing the most.' evidence='In 2020, there were 56 million cars manufactured worldwide, down from 67 million the previous year. The automotive industry in China produces by far the most (20 million in 2020).'\n```\n\n## Common issues\u200b\n\nDifferent methods have their own pros and cons related to cost, speed, and accuracy.\n\nWatch out for these issues:\n\n- Chunking content means that the LLM can fail to extract information if the information is spread across multiple chunks.\n\n- Large chunk overlap may cause the same information to be extracted twice, so be prepared to de-duplicate!\n\n- LLMs can make up data. If looking for a single fact across a large text and using a brute force approach, you may end up getting more made up data.\n\n#### Was this page helpful?\n\n- [Setup](#setup)\n\n- [Define the schema](#define-the-schema)\n\n- [Create an extractor](#create-an-extractor)\n\n- [Brute force approach](#brute-force-approach)- [Merge results](#merge-results)\n\n- [RAG based approach](#rag-based-approach)\n\n- [Common issues](#common-issues)", "type": "Document"}, {"metadata": {"description": "When working with files, like PDFs, you're likely to encounter text that exceeds your language model's context window. To process this text, consider these strategies:", "language": "en", "changefreq": "weekly", "source": "https://python.langchain.com/docs/how_to/extraction_long_text/", "title": "How to handle long text when doing extraction | \ud83e\udd9c\ufe0f\ud83d\udd17 LangChain", "lastmod": null, "content_type": null, "priority": "0.5", "loc": "https://python.langchain.com/docs/how_to/extraction_long_text/", "uuid": "5c687db0-8502-5dc9-8617-22f2d5ecf7f1"}, "page_content": "```python\nkey_developments = []\n\nfor extraction in extractions:\n    key_developments.extend(extraction.key_developments)\n\nkey_developments[:10]\n```\n\n```output\n[KeyDevelopment(year=1769, description='Nicolas-Joseph Cugnot built the first full-scale, self-propelled mechanical vehicle, a steam-powered tricycle.', evidence='Nicolas-Joseph Cugnot is widely credited with building the first full-scale, self-propelled mechanical vehicle in about 1769; he created a steam-powered tricycle.'),\n KeyDevelopment(year=1807, description=\"Nic\u00e9phore Ni\u00e9pce and his brother Claude created what was probably the world's first internal combustion engine.\", evidence=\"In 1807, Nic\u00e9phore Ni\u00e9pce and his brother Claude created what was probably the world's first internal combustion engine (which they called a Pyr\u00e9olophore), but installed it in a boat on the river Saone in France.\"),\n KeyDevelopment(year=1886, description='Carl Benz patented the Benz Patent-Motorwagen, marking the birth of the modern car.', evidence='In November 1881, French inventor Gustave Trouv\u00e9 demonstrated a three-wheeled car powered by electricity at the International Exposition of Electricity. Although several other German engineers (including Gottlieb Daimler, Wilhelm Maybach, and Siegfried Marcus) were working on cars at about the same time, the year 1886 is regarded as the birth year of the modern car\u2014a practical, marketable automobile for everyday use\u2014when the German Carl Benz patented his Benz Patent-Motorwagen; he is generally acknowledged as the inventor of the car.'),\n KeyDevelopment(year=1886, description='Carl Benz began promotion of his vehicle, marking the introduction of the first commercially available automobile.', evidence='Benz began promotion of the vehicle on 3 July 1886.'),\n KeyDevelopment(year=1888, description=\"Bertha Benz undertook the first road trip by car to prove the road-worthiness of her husband's invention.\", evidence=\"In August 1888, Bertha Benz, the wife and business partner of Carl Benz, undertook the first road trip by car, to prove the road-worthiness of her husband's invention.\"),\n KeyDevelopment(year=1896, description='Benz designed and patented the first internal-combustion flat engine, called boxermotor.', evidence='In 1896, Benz designed and patented the first internal-combustion flat engine, called boxermotor.'),\n KeyDevelopment(year=1897, description='The first motor car in central Europe and one of the first factory-made cars in the world, the Pr\u00e4sident automobil, was produced by Nesselsdorfer Wagenbau.', evidence='The first motor car in central Europe and one of the first factory-made cars in the world, was produced by Czech company Nesselsdorfer Wagenbau (later renamed to Tatra) in 1897, the Pr\u00e4sident automobil.'),\n KeyDevelopment(year=1901, description='Ransom Olds started large-scale, production-line manufacturing of affordable cars at his Oldsmobile factory in Lansing, Michigan.', evidence='Large-scale, production-line manufacturing of affordable cars was started by Ransom Olds in 1901 at his Oldsmobile factory in Lansing, Michigan.'),\n KeyDevelopment(year=1913, description=\"Henry Ford introduced the world's first moving assembly line for cars at the Highland Park Ford Plant.\", evidence=\"This concept was greatly expanded by Henry Ford, beginning in 1913 with the world's first moving assembly line for cars at the Highland Park Ford Plant.\")]\n```\n\n## RAG based approach\u200b\n\nAnother simple idea is to chunk up the text, but instead of extracting information from every chunk, just focus on the the most relevant chunks.\n\ncautionIt can be difficult to identify which chunks are relevant.\n\nFor example, in the `car` article we're using here, most of the article contains key development information. So by using\n**RAG**, we'll likely be throwing out a lot of relevant information.\n\nWe suggest experimenting with your use case and determining whether this approach works or not.\n\nTo implement the RAG based approach:", "type": "Document"}, {"metadata": {"description": "This guide assumes familiarity with the following concepts:", "language": "en", "changefreq": "weekly", "source": "https://python.langchain.com/docs/tutorials/extraction/", "title": "Build an Extraction Chain | \ud83e\udd9c\ufe0f\ud83d\udd17 LangChain", "lastmod": null, "content_type": null, "priority": "0.5", "loc": "https://python.langchain.com/docs/tutorials/extraction/", "uuid": "f4b59370-e4c5-529d-9adc-b2a6eb8d4eef"}, "page_content": "class Data(BaseModel):\n    \"\"\"Extracted data about people.\"\"\"\n\n    # Creates a model so that we can extract multiple entities.\n    people: List[Person]\n```\n\nimportantExtraction might not be perfect here. Please continue to see how to use **Reference Examples** to improve the quality of extraction, and see the **guidelines** section!\n\n```python\nrunnable = prompt | llm.with_structured_output(schema=Data)\ntext = \"My name is Jeff, my hair is black and i am 6 feet tall. Anna has the same color hair as me.\"\nrunnable.invoke({\"text\": text})\n```\n\n```output\nData(people=[Person(name='Jeff', hair_color=None, height_in_meters=None), Person(name='Anna', hair_color=None, height_in_meters=None)])\n```\n\ntipWhen the schema accommodates the extraction of **multiple entities**, it also allows the model to extract **no entities** if no relevant information\nis in the text by providing an empty list.\n\nThis is usually a **good** thing! It allows specifying **required** attributes on an entity without necessarily forcing the model to detect this entity.\n\nWe can see the LangSmith trace here: [https://smith.langchain.com/public/7173764d-5e76-45fe-8496-84460bd9cdef/r](https://smith.langchain.com/public/7173764d-5e76-45fe-8496-84460bd9cdef/r)\n\n## Next steps\u200b\n\nNow that you understand the basics of extraction with LangChain, you're ready to proceed to the rest of the how-to guides:\n\n- [Add Examples](/docs/how_to/extraction_examples/): Learn how to use **reference examples** to improve performance.\n\n- [Handle Long Text](/docs/how_to/extraction_long_text/): What should you do if the text does not fit into the context window of the LLM?\n\n- [Use a Parsing Approach](/docs/how_to/extraction_parse/): Use a prompt based approach to extract with models that do not support **tool/function calling**.\n\n#### Was this page helpful?\n\n- [Setup](#setup)- [Jupyter Notebook](#jupyter-notebook)\n\n- [Installation](#installation)\n\n- [LangSmith](#langsmith)\n\n- [The Schema](#the-schema)\n\n- [The Extractor](#the-extractor)\n\n- [Multiple Entities](#multiple-entities)\n\n- [Next steps](#next-steps)", "type": "Document"}, {"metadata": {"language": "en", "description": "This Jupyter Notebook demonstrates how to use Eden AI tools with an Agent.", "changefreq": "weekly", "source": "https://python.langchain.com/docs/integrations/tools/edenai_tools/", "title": "Eden AI | \ud83e\udd9c\ufe0f\ud83d\udd17 LangChain", "lastmod": null, "content_type": null, "priority": "0.5", "loc": "https://python.langchain.com/docs/integrations/tools/edenai_tools/", "uuid": "c2b59f24-a6ed-5923-b04e-763734df2c8f"}, "page_content": "you can have more details of the execution by printing the result\n\n```python\nresult\n```\n\n```output\n{'input': ' i have this url of an image : \"https://static.javatpoint.com/images/objects.jpg\"\\n                   first : i want to know if the image contain objects .\\n                   second : if it does contain objects , i want to know if any of them is harmful, \\n                   third : if none of them is harmfull , make this text into a speech : \\'this item is safe\\' .\\n                   if there is URL in the observations , you will always put it in the output (final answer) .\\n                   ',\n 'output': \"The image contains objects such as Apple, Backpack, Luggage & bags, and Container. None of them are harmful. The text 'this item is safe' can be found in the audio file at https://d14uq1pz7dzsdq.cloudfront.net/0546db8b-528e-4b63-9a69-d14d43ad1566_.mp3?Expires=1693316753&Signature=N0KZeK9I-1s7wTgiQOAwH7LFlltwyonSJcDnkdnr8JIJmbgSw6fo6RTxWl~VvD2Hg6igJqxtJFFWyrBmmx-f9wWLw3bZSnuMxkhTRqLX9aUA9N-vPJGiRZV5BFredaOm8pwfo8TcXhVjw08iSxv8GSuyZEIwZkiq4PzdiyVTnKKji6eyt\",\n 'intermediate_steps': [(AgentAction(tool='edenai_object_detection', tool_input='https://static.javatpoint.com/images/objects.jpg', log=' I need to determine if the image contains objects, if any of them are harmful, and then convert the text to speech.\\nAction: edenai_object_detection\\nAction Input: https://static.javatpoint.com/images/objects.jpg'),\n   'Apple - Confidence 0.94003654\\nApple - Confidence 0.94003654\\nApple - Confidence 0.94003654\\nBackpack - Confidence 0.7481894\\nBackpack - Confidence 0.7481894\\nBackpack - Confidence 0.7481894\\nLuggage & bags - Confidence 0.70691586\\nLuggage & bags - Confidence 0.70691586\\nLuggage & bags - Confidence 0.70691586\\nContainer - Confidence 0.654727\\nContainer - Confidence 0.654727\\nContainer - Confidence 0.654727\\nLuggage & bags - Confidence 0.5871518\\nLuggage & bags - Confidence 0.5871518\\nLuggage & bags - Confidence 0.5871518'),\n  (AgentAction(tool='edenai_explicit_content_detection_text', tool_input='Apple, Backpack, Luggage & bags, Container', log=' I need to check if any of the objects are harmful.\\nAction: edenai_explicit_content_detection_text\\nAction Input: Apple, Backpack, Luggage & bags, Container'),\n   'nsfw_likelihood: 2\\n\"sexually explicit\": 1\\n\"sexually suggestive\": 2\\n\"offensive\": 1\\nnsfw_likelihood: 1\\n\"sexual\": 1\\n\"hate\": 1\\n\"harassment\": 1\\n\"self-harm\": 1\\n\"sexual/minors\": 1\\n\"hate/threatening\": 1\\n\"violence/graphic\": 1\\n\"self-harm/intent\": 1\\n\"self-harm/instructions\": 1\\n\"harassment/threatening\": 1\\n\"violence\": 1'),\n  (AgentAction(tool='edenai_text_to_speech', tool_input=\"'this item is safe'\", log=\" None of the objects are harmful.\\nAction: edenai_text_to_speech\\nAction Input: 'this item is safe'\"),\n   'https://d14uq1pz7dzsdq.cloudfront.net/0546db8b-528e-4b63-9a69-d14d43ad1566_.mp3?Expires=1693316753&Signature=N0KZeK9I-1s7wTgiQOAwH7LFlltwyonSJcDnkdnr8JIJmbgSw6fo6RTxWl~VvD2Hg6igJqxtJFFWyrBmmx-f9wWLw3bZSnuMxkhTRqLX9aUA9N-vPJGiRZV5BFredaOm8pwfo8TcXhVjw08iSxv8GSuyZEIwZkiq4PzdiyVTnKKji6eytV0CrnHrTs~eXZkSnOdD2Fu0ECaKvFHlsF4IDLI8efRvituSk0X3ygdec4HQojl5vmBXJzi1TuhKWOX8UxeQle8pdjjqUPSJ9thTHpucdPy6UbhZOH0C9rbtLrCfvK5rzrT4D~gKy9woICzG34tKRxNxHYVVUPqx2BiInA__&Key-Pair-Id=K1F55BTI9AHGIK')]}\n```\n\n## Example with OCR images\u200b\n\n```python\ninput_ = \"\"\"i have this url of an id: \"https://www.citizencard.com/images/citizencard-uk-id-card-2023.jpg\"\ni want to extract the information in it.\ncreate a text welcoming the person by his name and make it into speech .\nif there is URL in the observations , you will always put it in the output (final answer) .\n\"\"\"\nresult = agent_chain(input_)\n```\n\n```output", "type": "Document"}, {"metadata": {"language": "en", "description": "Transwarp Hippo is an enterprise-level cloud-native distributed vector database that supports storage, retrieval, and management of massive vector-based datasets. It efficiently solves problems such as vector similarity search and high-density vector clustering. Hippo features high availability, high performance, and easy scalability. It has many functions, such as multiple vector search indexes, data partitioning and sharding, data persistence, incremental data ingestion, vector scalar field filtering, and mixed queries. It can effectively meet the high real-time search demands of enterprises for massive vector data", "changefreq": "weekly", "source": "https://python.langchain.com/docs/integrations/vectorstores/hippo/", "title": "Hippo | \ud83e\udd9c\ufe0f\ud83d\udd17 LangChain", "content_type": null, "lastmod": null, "priority": "0.5", "loc": "https://python.langchain.com/docs/integrations/vectorstores/hippo/", "uuid": "a3c305b4-cd08-56c7-bccd-612617eadbdb"}, "page_content": "- [Storing the Document](#storing-the-document)\n\n- [Conducting Knowledge-based Question and Answer](#conducting-knowledge-based-question-and-answer)\n\n- [Acquiring Related Knowledge Based on the Question\uff1a](#acquiring-related-knowledge-based-on-the-question)\n\n- [Constructing a Prompt Template](#constructing-a-prompt-template)\n\n- [Waiting for the Large Language Model to Generate an Answer](#waiting-for-the-large-language-model-to-generate-an-answer)\n\n- [Related](#related)", "type": "Document"}, {"metadata": {"language": "en", "description": "PebbloRetrievalQA is a Retrieval chain with Identity & Semantic Enforcement for question-answering", "changefreq": "weekly", "source": "https://python.langchain.com/docs/integrations/providers/pebblo/pebblo_retrieval_qa/", "title": "Identity-enabled RAG using PebbloRetrievalQA | \ud83e\udd9c\ufe0f\ud83d\udd17 LangChain", "content_type": null, "lastmod": null, "priority": "0.5", "loc": "https://python.langchain.com/docs/integrations/providers/pebblo/pebblo_retrieval_qa/", "uuid": "bdd2d371-9dd6-5cac-8806-1a2d4df78db5"}, "page_content": "- [Retrieval with Identity Enforcement](#retrieval-with-identity-enforcement)- [1. Questions by Authorized User](#1-questions-by-authorized-user)\n\n- [2. Questions by Unauthorized User](#2-questions-by-unauthorized-user)\n\n- [3. Using PromptTemplate to provide additional instructions](#3-using-prompttemplate-to-provide-additional-instructions)\n\n- [Retrieval with Semantic Enforcement](#retrieval-with-semantic-enforcement)- [1. Without semantic enforcement](#1-without-semantic-enforcement)\n\n- [2. Deny financial-report topic](#2-deny-financial-report-topic)\n\n- [3. Deny us-bank-account-number entity](#3-deny-us-bank-account-number-entity)", "type": "Document"}, {"metadata": {"language": "en", "description": "Retrieval is a common technique chatbots use to augment their responses with data outside a chat model's training data. This section will cover how to implement retrieval in the context of chatbots, but it's worth noting that retrieval is a very subtle and deep topic - we encourage you to explore other parts of the documentation that go into greater depth!", "changefreq": "weekly", "source": "https://python.langchain.com/docs/how_to/chatbots_retrieval/", "title": "How to add retrieval to chatbots | \ud83e\udd9c\ufe0f\ud83d\udd17 LangChain", "content_type": null, "lastmod": null, "priority": "0.5", "loc": "https://python.langchain.com/docs/how_to/chatbots_retrieval/", "uuid": "faea8c1d-2464-555e-b5bb-761ddfcaee53"}, "page_content": "{'answer': ''}\n{'answer': 'Lang'}\n{'answer': 'Smith'}\n{'answer': ' simpl'}\n{'answer': 'ifies'}\n{'answer': ' the'}\n{'answer': ' initial'}\n{'answer': ' setup'}\n{'answer': ' for'}\n{'answer': ' building'}\n{'answer': ' reliable'}\n{'answer': ' L'}\n{'answer': 'LM'}\n{'answer': ' applications'}\n{'answer': '.'}\n{'answer': ' It'}\n{'answer': ' provides'}\n{'answer': ' features'}\n{'answer': ' for'}\n{'answer': ' manually'}\n{'answer': ' reviewing'}\n{'answer': ' and'}\n{'answer': ' annot'}\n{'answer': 'ating'}\n{'answer': ' runs'}\n{'answer': ' through'}\n{'answer': ' annotation'}\n{'answer': ' queues'}\n{'answer': ','}\n{'answer': ' allowing'}\n{'answer': ' you'}\n{'answer': ' to'}\n{'answer': ' select'}\n{'answer': ' runs'}\n{'answer': ' based'}\n{'answer': ' on'}\n{'answer': ' criteria'}\n{'answer': ' like'}\n{'answer': ' model'}\n{'answer': ' type'}\n{'answer': ' or'}\n{'answer': ' automatic'}\n{'answer': ' evaluation'}\n{'answer': ' scores'}\n{'answer': ','}\n{'answer': ' and'}\n{'answer': ' queue'}\n{'answer': ' them'}\n{'answer': ' up'}\n{'answer': ' for'}\n{'answer': ' human'}\n{'answer': ' review'}\n{'answer': '.'}\n{'answer': ' As'}\n{'answer': ' a'}\n{'answer': ' reviewer'}\n{'answer': ','}\n{'answer': ' you'}\n{'answer': ' can'}\n{'answer': ' quickly'}\n{'answer': ' step'}\n{'answer': ' through'}\n{'answer': ' the'}\n{'answer': ' runs'}\n{'answer': ','}\n{'answer': ' view'}\n{'answer': ' the'}\n{'answer': ' input'}\n{'answer': ','}\n{'answer': ' output'}\n{'answer': ','}\n{'answer': ' and'}\n{'answer': ' any'}\n{'answer': ' existing'}\n{'answer': ' tags'}\n{'answer': ' before'}\n{'answer': ' adding'}\n{'answer': ' your'}\n{'answer': ' own'}\n{'answer': ' feedback'}\n{'answer': '.'}\n{'answer': ' This'}\n{'answer': ' can'}\n{'answer': ' be'}\n{'answer': ' particularly'}\n{'answer': ' useful'}\n{'answer': ' for'}\n{'answer': ' assessing'}\n{'answer': ' subjective'}\n{'answer': ' qualities'}\n{'answer': ' that'}\n{'answer': ' automatic'}\n{'answer': ' evalu'}\n{'answer': 'ators'}\n{'answer': ' struggle'}\n{'answer': ' with'}\n{'answer': '.'}\n{'answer': ''}\n```", "type": "Document"}, {"metadata": {"description": "PebbloRetrievalQA is a Retrieval chain with Identity & Semantic Enforcement for question-answering", "language": "en", "changefreq": "weekly", "source": "https://python.langchain.com/docs/integrations/providers/pebblo/pebblo_retrieval_qa/", "title": "Identity-enabled RAG using PebbloRetrievalQA | \ud83e\udd9c\ufe0f\ud83d\udd17 LangChain", "content_type": null, "lastmod": null, "priority": "0.5", "loc": "https://python.langchain.com/docs/integrations/providers/pebblo/pebblo_retrieval_qa/", "uuid": "9483e59b-08e4-5369-98dd-4706cd919703"}, "page_content": "def ask(\n    question: str,\n    topics_to_deny: Optional[List[str]] = None,\n    entities_to_deny: Optional[List[str]] = None,\n):\n    \"\"\"\n    Ask a question to the PebbloRetrievalQA chain\n    \"\"\"\n    semantic_context = dict()\n    if topics_to_deny:\n        semantic_context[\"pebblo_semantic_topics\"] = {\"deny\": topics_to_deny}\n    if entities_to_deny:\n        semantic_context[\"pebblo_semantic_entities\"] = {\"deny\": entities_to_deny}\n\n    semantic_context_obj = (\n        SemanticContext(**semantic_context) if semantic_context else None\n    )\n    chain_input_obj = ChainInput(query=question, semantic_context=semantic_context_obj)\n    return qa_chain.invoke(chain_input_obj.dict())\n```\n\n**API Reference:**[PebbloRetrievalQA](https://python.langchain.com/api_reference/community/chains/langchain_community.chains.pebblo_retrieval.base.PebbloRetrievalQA.html) | [ChainInput](https://python.langchain.com/api_reference/community/chains/langchain_community.chains.pebblo_retrieval.models.ChainInput.html) | [SemanticContext](https://python.langchain.com/api_reference/community/chains/langchain_community.chains.pebblo_retrieval.models.SemanticContext.html)\n### 1. Without semantic enforcement\u200b\n\nSince no semantic enforcement is applied, the system should return the answer without excluding any context due to the semantic labels associated with the context.\n\n```python\ntopic_to_deny = []\nentities_to_deny = []\nquestion = \"Share the financial performance of ACME Corp for the year 2020\"\nresp = ask(question, topics_to_deny=topic_to_deny, entities_to_deny=entities_to_deny)\nprint(\n    f\"Topics to deny: {topic_to_deny}\\nEntities to deny: {entities_to_deny}\\n\"\n    f\"Question: {question}\\nAnswer: {resp['result']}\"\n)\n```\n\n```output\nTopics to deny: []\nEntities to deny: []\nQuestion: Share the financial performance of ACME Corp for the year 2020\nAnswer: \nRevenue for ACME Corp increased by 15% to $50 million in 2020, with a net profit of $12 million and a strong asset base of $80 million. The company also maintained a conservative debt-to-equity ratio of 0.5.\n```\n\n### 2. Deny financial-report topic\u200b\n\nData has been ingested with the topics: `[\"financial-report\"]`.\nTherefore, an app that denies the `financial-report` topic should not receive an answer.\n\n```python\ntopic_to_deny = [\"financial-report\"]\nentities_to_deny = []\nquestion = \"Share the financial performance of ACME Corp for the year 2020\"\nresp = ask(question, topics_to_deny=topic_to_deny, entities_to_deny=entities_to_deny)\nprint(\n    f\"Topics to deny: {topic_to_deny}\\nEntities to deny: {entities_to_deny}\\n\"\n    f\"Question: {question}\\nAnswer: {resp['result']}\"\n)\n```\n\n```output\nTopics to deny: ['financial-report']\nEntities to deny: []\nQuestion: Share the financial performance of ACME Corp for the year 2020\nAnswer: \n\nUnfortunately, I do not have access to the financial performance of ACME Corp for the year 2020.\n```\n\n### 3. Deny us-bank-account-number entity\u200b\n\nSince the entity `us-bank-account-number` is denied, the system should not return the answer.\n\n```python\ntopic_to_deny = []\nentities_to_deny = [\"us-bank-account-number\"]\nquestion = \"Share the financial performance of ACME Corp for the year 2020\"\nresp = ask(question, topics_to_deny=topic_to_deny, entities_to_deny=entities_to_deny)\nprint(\n    f\"Topics to deny: {topic_to_deny}\\nEntities to deny: {entities_to_deny}\\n\"\n    f\"Question: {question}\\nAnswer: {resp['result']}\"\n)\n```\n\n```output\nTopics to deny: []\nEntities to deny: ['us-bank-account-number']\nQuestion: Share the financial performance of ACME Corp for the year 2020\nAnswer:  I don't have information about ACME Corp's financial performance for 2020.\n```\n\n#### Was this page helpful?\n\n- [Steps:](#steps)\n\n- [Setup](#setup)- [Dependencies](#dependencies)\n\n- [Identity-aware Data Ingestion](#identity-aware-data-ingestion)\n\n- [Retrieval with Identity Enforcement](#retrieval-with-identity-enforcement)- [1. Questions by Authorized User](#1-questions-by-authorized-user)", "type": "Document"}, {"metadata": {"description": "LLMs can summarize and otherwise distill desired information from text, including large volumes of text. In many cases, especially when the amount of text is large compared to the size of the model's context window, it can be helpful (or necessary) to break up the summarization task into smaller components.", "language": "en", "changefreq": "weekly", "source": "https://python.langchain.com/docs/how_to/summarize_map_reduce/", "title": "How to summarize text through parallelization | \ud83e\udd9c\ufe0f\ud83d\udd17 LangChain", "lastmod": null, "content_type": null, "priority": "0.5", "loc": "https://python.langchain.com/docs/how_to/summarize_map_reduce/", "uuid": "fc14a57d-1f4d-506f-b648-9835640f017c"}, "page_content": "See also [this tutorial](/docs/tutorials/summarization/) for more detail on summarization.\n\n#### Was this page helpful?\n\n- [Load chat model](#load-chat-model)\n\n- [Load documents](#load-documents)\n\n- [Create graph](#create-graph)- [Map step](#map-step)\n\n- [Reduce step](#reduce-step)\n\n- [Orchestration via LangGraph](#orchestration-via-langgraph)\n\n- [Invoke graph](#invoke-graph)\n\n- [Next steps](#next-steps)", "type": "Document"}, {"metadata": {"language": "en", "description": "This tutorial demonstrates text summarization using built-in chains and LangGraph.", "changefreq": "weekly", "source": "https://python.langchain.com/docs/tutorials/summarization/", "title": "Summarize Text | \ud83e\udd9c\ufe0f\ud83d\udd17 LangChain", "content_type": null, "lastmod": null, "priority": "0.5", "loc": "https://python.langchain.com/docs/tutorials/summarization/", "uuid": "bbeae299-a2fb-5af1-ad12-bf62bdcbba80"}, "page_content": "Summarize Text | \ud83e\udd9c\ufe0f\ud83d\udd17 LangChain\n\n[Skip to main content](#__docusaurus_skipToContent_fallback)# Summarize Text\n\ninfoThis tutorial demonstrates text summarization using built-in chains and [LangGraph](https://langchain-ai.github.io/langgraph/).\n\nA [previous version](https://python.langchain.com/v0.1/docs/use_cases/summarization/) of this page showcased the legacy chains [StuffDocumentsChain](/docs/versions/migrating_chains/stuff_docs_chain/), [MapReduceDocumentsChain](/docs/versions/migrating_chains/map_reduce_chain/), and [RefineDocumentsChain](https://python.langchain.com/docs/versions/migrating_chains/refine_docs_chain/). See [here](/docs/versions/migrating_chains/) for information on using those abstractions and a comparison with the methods demonstrated in this tutorial.\n\nSuppose you have a set of documents (PDFs, Notion pages, customer questions, etc.) and you want to summarize the content.\n\nLLMs are a great tool for this given their proficiency in understanding and synthesizing text.\n\nIn the context of [retrieval-augmented generation](/docs/tutorials/rag/), summarizing text can help distill the information in a large number of retrieved documents to provide context for a LLM.\n\nIn this walkthrough we'll go over how to summarize content from multiple documents using LLMs.\n\n![Image description](/assets/images/summarization_use_case_1-874f7b2c94f64216f1f967fb5aca7bc1.png)\n\n## Concepts\u200b\n\nConcepts we will cover are:\n\n- \nUsing [language models](/docs/concepts/chat_models/).\n\n- \nUsing [document loaders](/docs/concepts/document_loaders/), specifically the [WebBaseLoader](https://python.langchain.com/api_reference/community/document_loaders/langchain_community.document_loaders.web_base.WebBaseLoader.html) to load content from an HTML webpage.\n\n- \nTwo ways to summarize or otherwise combine documents.\n\n1. [Stuff](/docs/tutorials/summarization/#stuff), which simply concatenates documents into a prompt;\n\n2. [Map-reduce](/docs/tutorials/summarization/#map-reduce), for larger sets of documents. This splits documents into batches, summarizes those, and then summarizes the summaries.\n\nShorter, targeted guides on these strategies and others, including [iterative refinement](/docs/how_to/summarize_refine/), can be found in the [how-to guides](/docs/how_to/#summarization).\n\n## Setup\u200b\n\n### Jupyter Notebook\u200b\n\nThis guide (and most of the other guides in the documentation) uses [Jupyter notebooks](https://jupyter.org/) and assumes the reader is as well. Jupyter notebooks are perfect for learning how to work with LLM systems because oftentimes things can go wrong (unexpected output, API down, etc) and going through guides in an interactive environment is a great way to better understand them.\n\nThis and other tutorials are perhaps most conveniently run in a Jupyter notebook. See [here](https://jupyter.org/install) for instructions on how to install.\n\n### Installation\u200b\n\nTo install LangChain run:\n\n \nPip\n```bash\npip install langchain\n```\n\nConda\n```bash\nconda install langchain -c conda-forge\n```\n\nFor more details, see our [Installation guide](/docs/how_to/installation/).\n\n### LangSmith\u200b\n\nMany of the applications you build with LangChain will contain multiple steps with multiple invocations of LLM calls.\nAs these applications get more and more complex, it becomes crucial to be able to inspect what exactly is going on inside your chain or agent.\nThe best way to do this is with [LangSmith](https://smith.langchain.com).\n\nAfter you sign up at the link above, make sure to set your environment variables to start logging traces:\n\n```shell\nexport LANGCHAIN_TRACING_V2=\"true\"\nexport LANGCHAIN_API_KEY=\"...\"\n```\n\nOr, if in a notebook, you can set them with:\n\n```python\nimport getpass\nimport os\n\nos.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\nos.environ[\"LANGCHAIN_API_KEY\"] = getpass.getpass()\n```\n\n## Overview\u200b\n\nA central question for building a summarizer is how to pass your documents into the LLM's context window. Two common approaches for this are:", "type": "Document"}, {"metadata": {"description": "Vectara is the trusted AI Assistant and Agent platform which focuses on enterprise readiness for mission-critical applications.", "language": "en", "changefreq": "weekly", "source": "https://python.langchain.com/docs/integrations/vectorstores/vectara/", "title": "Vectara | \ud83e\udd9c\ufe0f\ud83d\udd17 LangChain", "content_type": null, "lastmod": null, "priority": "0.5", "loc": "https://python.langchain.com/docs/integrations/vectorstores/vectara/", "uuid": "31d78e5d-5fc7-5a56-baf6-6b8ead6ad6fb"}, "page_content": "```python\nconfig.summary_config.is_enabled = False\nconfig.k = 3\nretriever = vectara.as_retriever(config=config)\nretriever.invoke(query_str)\n```\n\n```output\n[Document(page_content='He thought the West and NATO wouldn\u2019t respond. And he thought he could divide us at home. We were ready.  Here is what we did. We prepared extensively and carefully. We spent months building a coalition of other freedom-loving nations from Europe and the Americas to Asia and Africa to confront Putin.', metadata={'lang': 'eng', 'section': '1', 'offset': '2160', 'len': '36', 'X-TIKA:Parsed-By': 'org.apache.tika.parser.csv.TextAndCSVParser', 'Content-Encoding': 'UTF-8', 'Content-Type': 'text/plain; charset=UTF-8', 'source': 'vectara'}),\n Document(page_content='When they came home, many of the world\u2019s fittest and best trained warriors were never the same. Dizziness. \\n\\nA cancer that would put them in a flag-draped coffin. I know. \\n\\nOne of those soldiers was my son Major Beau Biden. We don\u2019t know for sure if a burn pit was the cause of his brain cancer, or the diseases of so many of our troops. But I\u2019m committed to finding out everything we can.', metadata={'lang': 'eng', 'section': '1', 'offset': '34652', 'len': '60', 'X-TIKA:Parsed-By': 'org.apache.tika.parser.csv.TextAndCSVParser', 'Content-Encoding': 'UTF-8', 'Content-Type': 'text/plain; charset=UTF-8', 'source': 'vectara'}),\n Document(page_content='But cancer from prolonged exposure to burn pits ravaged Heath\u2019s lungs and body. Danielle says Heath was a fighter to the very end. He didn\u2019t know how to stop fighting, and neither did she. Through her pain she found purpose to demand we do better. Tonight, Danielle\u2014we are.', metadata={'lang': 'eng', 'section': '1', 'offset': '35442', 'len': '57', 'X-TIKA:Parsed-By': 'org.apache.tika.parser.csv.TextAndCSVParser', 'Content-Encoding': 'UTF-8', 'Content-Type': 'text/plain; charset=UTF-8', 'source': 'vectara'})]\n```\n\nFor backwards compatibility, you can also enable summarization with a retriever, in which case the summary is added as an additional Document object:\n\n```python\nconfig.summary_config.is_enabled = True\nconfig.k = 3\nretriever = vectara.as_retriever(config=config)\nretriever.invoke(query_str)\n```", "type": "Document"}], "answer": "I'm unable to access external URLs or open documents directly. However, you can download the PDF from the provided link and then use LangChain to load it into your environment. Once you have the PDF loaded, you can ask questions based on its content.\n\nIf you need help with loading the PDF using LangChain, please let me know!", "query": "https://www.cambridge.org/core/services/aop-cambridge-core/content/view/0D4357A9A6150E706CC261B86BA47733/S0008423923000793a.pdf/ascent_of_the_canadian_judicial_council_bill_c9_and_the_move_towards_judicialized_governance.pdf  can you open this to answer questions for me "}
{"messages": [{"role": "user", "content": "https://www.cambridge.org/core/services/aop-cambridge-core/content/view/0D4357A9A6150E706CC261B86BA47733/S0008423923000793a.pdf/ascent_of_the_canadian_judicial_council_bill_c9_and_the_move_towards_judicialized_governance.pdf  can you open this to answer questions for me "}]}
{"steps": ["Access the provided PDF link to review its content.", "Extract key information and insights relevant to potential questions about the Canadian Judicial Council and Bill C-9.", "Prepare to answer specific questions based on the extracted information."], "documents": "delete", "query": "https://www.cambridge.org/core/services/aop-cambridge-core/content/view/0D4357A9A6150E706CC261B86BA47733/S0008423923000793a.pdf/ascent_of_the_canadian_judicial_council_bill_c9_and_the_move_towards_judicialized_governance.pdf  can you open this to answer questions for me "}
{"generations": [{"text": "", "generation_info": {"finish_reason": "stop", "model_name": "gpt-4o-mini-2024-07-18", "system_fingerprint": "fp_0705bf87c0"}, "type": "ChatGeneration", "message": {"lc": 1, "type": "constructor", "id": ["langchain", "schema", "messages", "AIMessage"], "kwargs": {"content": "", "additional_kwargs": {"tool_calls": [{"index": 0, "id": "call_RbGhWvcsf8xOrRAmAiVi8GdW", "function": {"arguments": "{\"steps\":[\"Access the provided PDF link to review its content.\",\"Extract key information and insights relevant to potential questions about the Canadian Judicial Council and Bill C-9.\",\"Prepare to answer specific questions based on the extracted information.\"]}", "name": "Plan"}, "type": "function"}]}, "response_metadata": {"finish_reason": "stop", "model_name": "gpt-4o-mini-2024-07-18", "system_fingerprint": "fp_0705bf87c0"}, "type": "ai", "id": "run-cc4af028-3686-4558-a942-796091a3d8a9", "tool_calls": [{"name": "Plan", "args": {"steps": ["Access the provided PDF link to review its content.", "Extract key information and insights relevant to potential questions about the Canadian Judicial Council and Bill C-9.", "Prepare to answer specific questions based on the extracted information."]}, "id": "call_RbGhWvcsf8xOrRAmAiVi8GdW", "type": "tool_call"}], "invalid_tool_calls": []}}}], "llm_output": null, "run": null, "type": "LLMResult"}
{"documents": [{"metadata": {"language": "en", "description": "Portable Document Format (PDF), standardized as ISO 32000, is a file format developed by Adobe in 1992 to present documents, including text formatting and images, in a manner independent of application software, hardware, and operating systems.", "changefreq": "weekly", "source": "https://python.langchain.com/docs/how_to/document_loader_pdf/", "title": "How to load PDFs | \ud83e\udd9c\ufe0f\ud83d\udd17 LangChain", "lastmod": null, "content_type": null, "priority": "0.5", "loc": "https://python.langchain.com/docs/how_to/document_loader_pdf/", "uuid": "a3f9bbc3-306a-5a26-94ac-f0fe755afbb7"}, "page_content": "How to load PDFs | \ud83e\udd9c\ufe0f\ud83d\udd17 LangChain\n\n[Skip to main content](#__docusaurus_skipToContent_fallback)# How to load PDFs\n\n[Portable Document Format (PDF)](https://en.wikipedia.org/wiki/PDF), standardized as ISO 32000, is a file format developed by Adobe in 1992 to present documents, including text formatting and images, in a manner independent of application software, hardware, and operating systems.\n\nThis guide covers how to [load](/docs/concepts/document_loaders/) `PDF` documents into the LangChain [Document](https://python.langchain.com/api_reference/core/documents/langchain_core.documents.base.Document.html) format that we use downstream.\n\nText in PDFs is typically represented via text boxes. They may also contain images. A PDF parser might do some combination of the following:\n\n- Agglomerate text boxes into lines, paragraphs, and other structures via heuristics or ML inference;\n\n- Run [OCR](https://en.wikipedia.org/wiki/Optical_character_recognition) on images to detect text therein;\n\n- Classify text as belonging to paragraphs, lists, tables, or other structures;\n\n- Structure text into table rows and columns, or key-value pairs.\n\nLangChain integrates with a host of PDF parsers. Some are simple and relatively low-level; others will support OCR and image-processing, or perform advanced document layout analysis. The right choice will depend on your needs. Below we enumerate the possibilities.\n\nWe will demonstrate these approaches on a [sample file](https://github.com/langchain-ai/langchain/blob/master/libs/community/tests/integration_tests/examples/layout-parser-paper.pdf):\n\n```python\nfile_path = (\n    \"../../docs/integrations/document_loaders/example_data/layout-parser-paper.pdf\"\n)\n```\n\nA note on multimodal modelsMany modern LLMs support inference over multimodal inputs (e.g., images). In some applications -- such as question-answering over PDFs with complex layouts, diagrams, or scans -- it may be advantageous to skip the PDF parsing, instead casting a PDF page to an image and passing it to a model directly. We demonstrate an example of this in the [Use of multimodal models](/docs/how_to/document_loader_pdf/#use-of-multimodal-models) section below.\n\n## Simple and fast text extraction\u200b\n\nIf you are looking for a simple string representation of text that is embedded in a PDF, the method below is appropriate. It will return a list of [Document](https://python.langchain.com/api_reference/core/documents/langchain_core.documents.base.Document.html) objects-- one per page-- containing a single string of the page's text in the Document's `page_content` attribute. It will not parse text in images or scanned PDF pages. Under the hood it uses the [pypdf](https://pypdf.readthedocs.io/en/stable/) Python library.\n\nLangChain [document loaders](/docs/concepts/document_loaders/) implement `lazy_load` and its async variant, `alazy_load`, which return iterators of `Document` objects. We will use these below.\n\n```python\n%pip install -qU pypdf\n```\n\n```python\nfrom langchain_community.document_loaders import PyPDFLoader\n\nloader = PyPDFLoader(file_path)\npages = []\nasync for page in loader.alazy_load():\n    pages.append(page)\n```\n\n**API Reference:**[PyPDFLoader](https://python.langchain.com/api_reference/community/document_loaders/langchain_community.document_loaders.pdf.PyPDFLoader.html)\n```python\nprint(f\"{pages[0].metadata}\\n\")\nprint(pages[0].page_content)\n```\n\n```output\n{'source': '../../docs/integrations/document_loaders/example_data/layout-parser-paper.pdf', 'page': 0}", "type": "Document"}, {"metadata": {"description": "Overview", "language": "en", "changefreq": "weekly", "source": "https://python.langchain.com/docs/integrations/document_loaders/unstructured_pdfloader/", "title": "UnstructuredPDFLoader | \ud83e\udd9c\ufe0f\ud83d\udd17 LangChain", "lastmod": null, "content_type": null, "priority": "0.5", "loc": "https://python.langchain.com/docs/integrations/document_loaders/unstructured_pdfloader/", "uuid": "8e7d3de8-e7e7-5cc2-bee5-618901e9e15f"}, "page_content": "**API Reference:**[OnlinePDFLoader](https://python.langchain.com/api_reference/community/document_loaders/langchain_community.document_loaders.pdf.OnlinePDFLoader.html)\n```output", "type": "Document"}, {"metadata": {"description": "Overview", "language": "en", "changefreq": "weekly", "source": "https://python.langchain.com/docs/integrations/document_loaders/unstructured_pdfloader/", "title": "UnstructuredPDFLoader | \ud83e\udd9c\ufe0f\ud83d\udd17 LangChain", "lastmod": null, "content_type": null, "priority": "0.5", "loc": "https://python.langchain.com/docs/integrations/document_loaders/unstructured_pdfloader/", "uuid": "f896de9c-6074-587c-8ebd-21697b8fcf4e"}, "page_content": "```python\nprint(docs[0].metadata)\n```\n\n```output\n{'source': './example_data/layout-parser-paper.pdf'}\n```\n\n### Retain Elements\u200b\n\nUnder the hood, Unstructured creates different \"elements\" for different chunks of text. By default we combine those together, but you can easily keep that separation by specifying `mode=\"elements\"`.\n\n```python\nfile_path = \"./example_data/layout-parser-paper.pdf\"\nloader = UnstructuredPDFLoader(file_path, mode=\"elements\")\n\ndata = loader.load()\ndata[0]\n```\n\n```output\nDocument(metadata={'source': './example_data/layout-parser-paper.pdf', 'coordinates': {'points': ((16.34, 213.36), (16.34, 253.36), (36.34, 253.36), (36.34, 213.36)), 'system': 'PixelSpace', 'layout_width': 612, 'layout_height': 792}, 'file_directory': './example_data', 'filename': 'layout-parser-paper.pdf', 'languages': ['eng'], 'last_modified': '2024-07-25T21:28:58', 'page_number': 1, 'filetype': 'application/pdf', 'category': 'UncategorizedText', 'element_id': 'd3ce55f220dfb75891b4394a18bcb973'}, page_content='1 2 0 2')\n```\n\nSee the full set of element types for this particular document:\n\n```python\nset(doc.metadata[\"category\"] for doc in data)\n```\n\n```output\n{'ListItem', 'NarrativeText', 'Title', 'UncategorizedText'}\n```\n\n### Fetching remote PDFs using Unstructured\u200b\n\nThis covers how to load online PDFs into a document format that we can use downstream. This can be used for various online PDF sites such as [https://open.umn.edu/opentextbooks/textbooks/](https://open.umn.edu/opentextbooks/textbooks/) and [https://arxiv.org/archive/](https://arxiv.org/archive/)\n\nNote: all other PDF loaders can also be used to fetch remote PDFs, but `OnlinePDFLoader` is a legacy function, and works specifically with `UnstructuredPDFLoader`.\n\n```python\nfrom langchain_community.document_loaders import OnlinePDFLoader\n\nloader = OnlinePDFLoader(\"https://arxiv.org/pdf/2302.03803.pdf\")\ndata = loader.load()\ndata[0]\n```", "type": "Document"}, {"metadata": {"language": "en", "description": "DocumentLoaders load data into the standard LangChain Document format.", "changefreq": "weekly", "source": "https://python.langchain.com/docs/integrations/document_loaders/", "title": "Document loaders | \ud83e\udd9c\ufe0f\ud83d\udd17 LangChain", "content_type": null, "lastmod": null, "priority": "0.5", "loc": "https://python.langchain.com/docs/integrations/document_loaders/", "uuid": "cbcffc89-a3d2-5630-9fc5-b89ee88d3d68"}, "page_content": "#### Was this page helpful?\n\n- [Webpages](#webpages)\n\n- [PDFs](#pdfs)\n\n- [Cloud Providers](#cloud-providers)\n\n- [Social Platforms](#social-platforms)\n\n- [Messaging Services](#messaging-services)\n\n- [Productivity tools](#productivity-tools)\n\n- [Common File Types](#common-file-types)\n\n- [All document loaders](#all-document-loaders)", "type": "Document"}, {"metadata": {"description": "Overview", "language": "en", "changefreq": "weekly", "source": "https://python.langchain.com/docs/integrations/document_loaders/pdfminer/", "title": "PDFMiner | \ud83e\udd9c\ufe0f\ud83d\udd17 LangChain", "content_type": null, "lastmod": null, "priority": "0.5", "loc": "https://python.langchain.com/docs/integrations/document_loaders/pdfminer/", "uuid": "85d9d38c-a640-5f59-b00d-5ff43f93ac91"}, "page_content": "5 shows two examples of how\\n<br></span><span style=\"font-family: CMTT10; font-size:9px\">LayoutParser </span><span style=\"font-family: CMR10; font-size:9px\">can be used in practical DIA projects, and Section 6 concludes.\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:134px; top:1990px; width:102px; height:11px;\"><span style=\"font-family: CMBX12; font-size:11px\">2 Related Work\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:134px; top:2016px; width:347px; height:81px;\"><span style=\"font-family: CMR10; font-size:9px\">Recently, various DL models and datasets have been developed for layout analysis\\n<br>tasks. The dhSegment [22] utilizes fully convolutional networks [20] for segmen-\\n<br>tation tasks on historical documents. Object detection-based methods like Faster\\n<br>R-CNN [28] and Mask R-CNN [12] are used for identifying document elements [38]\\n<br>and detecting tables [30, 26]. Most recently, Graph Neural Networks [29] have also\\n<br>been used in table detection [27]. However, these models are usually implemented\\n<br>individually and there is no uni\ufb01ed framework to load and use such models.\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:134px; top:2100px; width:348px; height:189px;\"><span style=\"font-family: CMR10; font-size:9px\">There has been a surge of interest in creating open-source tools for document\\n<br>image processing: a search of </span><span style=\"font-family: CMTT10; font-size:9px\">document image analysis </span><span style=\"font-family: CMR10; font-size:9px\">in Github leads to 5M\\n<br>relevant code pieces </span><span style=\"font-family: CMR7; font-size:6px\">6</span><span style=\"font-family: CMR10; font-size:9px\">; yet most of them rely on traditional rule-based methods\\n<br>or provide limited functionalities. The closest prior research to our work is the\\n<br>OCR-D project</span><span style=\"font-family: CMR7; font-size:6px\">7</span><span style=\"font-family: CMR10; font-size:9px\">, which also tries to build a complete toolkit for DIA. However,\\n<br>similar to the platform developed by Neudecker et al. [21], it is designed for\\n<br>analyzing historical documents, and provides no supports for recent DL models.\\n<br>The </span><span style=\"font-family: CMTT10; font-size:9px\">DocumentLayoutAnalysis </span><span style=\"font-family: CMR10; font-size:9px\">project</span><span style=\"font-family: CMR7; font-size:6px\">8 </span><span style=\"font-family: CMR10; font-size:9px\">focuses on processing born-digital PDF\\n<br>documents via analyzing the stored PDF data. Repositories like </span><span style=\"font-family: CMTT10; font-size:9px\">DeepLayout</span><span style=\"font-family: CMR7; font-size:6px\">9\\n<br></span><span style=\"font-family: CMR10; font-size:9px\">and </span><span style=\"font-family: CMTT10; font-size:9px\">Detectron2-PubLayNet</span><span style=\"font-family: CMR7; font-size:6px\">10 </span><span style=\"font-family: CMR10; font-size:9px\">are individual deep learning models trained on\\n<br>layout analysis datasets without support for the full DIA pipeline. The Document\\n<br>Analysis and Exploitation (DAE) platform [15] and the DeepDIVA project [2]\\n<br>aim to improve the reproducibility of DIA methods (or DL models), yet they\\n<br>are not actively maintained. OCR engines like </span><span style=\"font-family: CMTT10; font-size:9px\">Tesseract </span><span style=\"font-family: CMR10; font-size:9px\">[14], </span><span style=\"font-family: CMTT10; font-size:9px\">easyOCR</span><span style=\"font-family: CMR7; font-size:6px\">11 </span><span style=\"font-family: CMR10; font-size:9px\">and\\n<br></span><span style=\"font-family: CMTT10; font-size:9px\">paddleOCR</span><span style=\"font-family: CMR7; font-size:6px\">12 </span><span style=\"font-family: CMR10; font-size:9px\">usually do not come with comprehensive functionalities for other\\n<br>DIA tasks like layout", "type": "Document"}, {"metadata": {"description": "Overview", "language": "en", "changefreq": "weekly", "source": "https://python.langchain.com/docs/integrations/document_loaders/pdfminer/", "title": "PDFMiner | \ud83e\udd9c\ufe0f\ud83d\udd17 LangChain", "lastmod": null, "content_type": null, "priority": "0.5", "loc": "https://python.langchain.com/docs/integrations/document_loaders/pdfminer/", "uuid": "c86c93ad-5ca1-59e1-8dfe-832cf69ffa35"}, "page_content": "CMR9; font-size:8px\">the maximum is 1.\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:133px; top:9955px; width:348px; height:10px;\"><span style=\"font-family: CMR6; font-size:5px\">17 </span><span style=\"font-family: CMR9; font-size:8px\">This measures the number of edits from the ground-truth text to the predicted text,\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:144px; top:9967px; width:78px; height:8px;\"><span style=\"font-family: CMR9; font-size:8px\">and lower is better.\\n<br></span></div><span style=\"position:absolute; border: black 1px solid; left:134px; top:9931px; width:56px; height:0px;\"></span>\\n<span style=\"position:absolute; border: gray 1px solid; left:0px; top:10154px; width:612px; height:792px;\"></span>\\n<div style=\"position:absolute; top:10154px;\"><a name=\"13\">Page 13</a></div>\\n<div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:237px; top:10246px; width:210px; height:9px;\"><span style=\"font-family: CMTT9; font-size:8px\">LayoutParser</span><span style=\"font-family: CMR9; font-size:8px\">: A Uni\ufb01ed Toolkit for DL-Based DIA\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:471px; top:10246px; width:9px; height:8px;\"><span style=\"font-family: CMR9; font-size:8px\">13\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:134px; top:10398px; width:346px; height:45px;\"><span style=\"font-family: CMR10; font-size:9px\">Fig. 6: This lightweight table detector can identify tables (outlined in red) and\\n<br>cells (shaded in blue) in di\ufb00erent locations on a page. In very few cases (d), it\\n<br>might generate minor error predictions, e.g, failing to capture the top text line of\\n<br></span><span style=\"font-family: CMR10; font-size:9px\">a table.\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:134px; top:10478px; width:216px; height:9px;\"><span style=\"font-family: CMBX10; font-size:9px\">5.2 A light-weight Visual Table Extractor\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:134px; top:10518px; width:347px; height:81px;\"><span style=\"font-family: CMR10; font-size:9px\">Detecting tables and parsing their structures (table extraction) are of central im-\\n<br>portance for many document digitization tasks. Many previous works [26, 30, 27]\\n<br>and tools </span><span style=\"font-family: CMR7; font-size:6px\">18 </span><span style=\"font-family: CMR10; font-size:9px\">have been developed to identify and parse table structures. Yet they\\n<br>might require training complicated models from scratch, or are only applicable\\n<br>for born-digital PDF documents. In this section, we show how </span><span style=\"font-family: CMTT10; font-size:9px\">LayoutParser </span><span style=\"font-family: CMR10; font-size:9px\">can\\n<br>help build a light-weight accurate visual table extractor for legal docket tables\\n<br>using the existing resources with minimal e\ufb00ort.\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:134px; top:10606px; width:347px; height:177px;\"><span style=\"font-family: CMR10; font-size:9px\">The extractor uses a pre-trained layout detection model for identifying the\\n<br>table regions and some simple rules for pairing the rows and the columns in the\\n<br>PDF image. Mask R-CNN [12] trained on the PubLayNet dataset [38] from the\\n<br></span><span style=\"font-family: CMTT10; font-size:9px\">LayoutParser </span><span style=\"font-family: CMR10; font-size:9px\">Model Zoo can be used for detecting table regions. By \ufb01ltering\\n<br>out model predictions of low con\ufb01dence and removing overlapping predictions,\\n<br></span><span style=\"font-family: CMTT10; font-size:9px\">LayoutParser </span><span style=\"font-family: CMR10; font-size:9px\">can identify the tabular", "type": "Document"}, {"metadata": {"description": "Portable Document Format (PDF), standardized as ISO 32000, is a file format developed by Adobe in 1992 to present documents, including text formatting and images, in a manner independent of application software, hardware, and operating systems.", "language": "en", "changefreq": "weekly", "source": "https://python.langchain.com/docs/how_to/document_loader_pdf/", "title": "How to load PDFs | \ud83e\udd9c\ufe0f\ud83d\udd17 LangChain", "content_type": null, "lastmod": null, "priority": "0.5", "loc": "https://python.langchain.com/docs/how_to/document_loader_pdf/", "uuid": "5a2a91d5-0d47-5a95-8791-d9a4adade490"}, "page_content": "```output\n{'source': '../../docs/integrations/document_loaders/example_data/layout-parser-paper.pdf', 'page': 0}\n\nLayoutParser : A Uni\ufb01ed Toolkit for Deep\nLearning Based Document Image Analysis\nZejiang Shen1( \ufffd), Ruochen Zhang2, Melissa Dell3, Benjamin Charles Germain\nLee4, Jacob Carlson3, and Weining Li5\n1Allen Institute for AI\nshannons@allenai.org\n2Brown University\nruochen zhang@brown.edu\n3Harvard University\n{melissadell,jacob carlson }@fas.harvard.edu\n4University of Washington\nbcgl@cs.washington.edu\n5University of Waterloo\nw422li@uwaterloo.ca\nAbstract. Recent advances in document image analysis (DIA) have been\nprimarily driven by the application of neural networks. Ideally, research\noutcomes could be easily deployed in production and extended for further\ninvestigation. However, various factors like loosely organized codebases\nand sophisticated model con\ufb01gurations complicate the easy reuse of im-\nportant innovations by a wide audience. Though there have been on-going\ne\ufb00orts to improve reusability and simplify deep learning (DL) model\ndevelopment in disciplines like natural language processing and computer\nvision, none of them are optimized for challenges in the domain of DIA.\nThis represents a major gap in the existing toolkit, as DIA is central to\nacademic research across a wide range of disciplines in the social sciences\nand humanities. This paper introduces LayoutParser , an open-source\nlibrary for streamlining the usage of DL in DIA research and applica-\ntions. The core LayoutParser library comes with a set of simple and\nintuitive interfaces for applying and customizing DL models for layout de-\ntection, character recognition, and many other document processing tasks.\nTo promote extensibility, LayoutParser also incorporates a community\nplatform for sharing both pre-trained models and full document digiti-\nzation pipelines. We demonstrate that LayoutParser is helpful for both\nlightweight and large-scale digitization pipelines in real-word use cases.\nThe library is publicly available at https://layout-parser.github.io .\nKeywords: Document Image Analysis \u00b7Deep Learning \u00b7Layout Analysis\n\u00b7Character Recognition \u00b7Open Source library \u00b7Toolkit.\n1 Introduction\nDeep Learning(DL)-based approaches are the state-of-the-art for a wide range of\ndocument image analysis (DIA) tasks including document image classi\ufb01cation [ 11,arXiv:2103.15348v2  [cs.CV]  21 Jun 2021\n```\n\nNote that the metadata of each document stores the corresponding page number.\n\n### Vector search over PDFs\u200b\n\nOnce we have loaded PDFs into LangChain `Document` objects, we can index them (e.g., a RAG application) in the usual way. Below we use OpenAI embeddings, although any LangChain [embeddings](https://python.langchain.com/docs/concepts/embedding_models) model will suffice.\n\n```python\n%pip install -qU langchain-openai\n```\n\n```python\nimport getpass\nimport os\n\nif \"OPENAI_API_KEY\" not in os.environ:\n    os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"OpenAI API Key:\")\n```\n\n```python\nfrom langchain_core.vectorstores import InMemoryVectorStore\nfrom langchain_openai import OpenAIEmbeddings\n\nvector_store = InMemoryVectorStore.from_documents(pages, OpenAIEmbeddings())\ndocs = vector_store.similarity_search(\"What is LayoutParser?\", k=2)\nfor doc in docs:\n    print(f'Page {doc.metadata[\"page\"]}: {doc.page_content[:300]}\\n')\n```\n\n**API Reference:**[InMemoryVectorStore](https://python.langchain.com/api_reference/core/vectorstores/langchain_core.vectorstores.in_memory.InMemoryVectorStore.html) | [OpenAIEmbeddings](https://python.langchain.com/api_reference/openai/embeddings/langchain_openai.embeddings.base.OpenAIEmbeddings.html)\n```output\nPage 13: 14 Z. Shen et al.\n6 Conclusion\nLayoutParser provides a comprehensive toolkit for deep learning-based document\nimage analysis. The o\ufb00-the-shelf library is easy to install, and can be used to\nbuild \ufb02exible and accurate pipelines for processing documents with complicated\nstructures. It also supports hi", "type": "Document"}], "steps": ["Extract key information and insights relevant to potential questions about the Canadian Judicial Council and Bill C-9.", "Prepare to answer specific questions based on the extracted information."]}
{"generations": [{"text": "", "generation_info": {"finish_reason": "stop", "model_name": "gpt-4o-mini-2024-07-18", "system_fingerprint": "fp_0705bf87c0"}, "type": "ChatGeneration", "message": {"lc": 1, "type": "constructor", "id": ["langchain", "schema", "messages", "AIMessage"], "kwargs": {"content": "", "additional_kwargs": {"tool_calls": [{"index": 0, "id": "call_guQhRK2idKJvJmho609MT0f5", "function": {"arguments": "{\"queries\":[\"how to access and review PDF files online\",\"best practices for reviewing PDF documents\",\"tools for analyzing PDF content\"]}", "name": "Response"}, "type": "function"}]}, "response_metadata": {"finish_reason": "stop", "model_name": "gpt-4o-mini-2024-07-18", "system_fingerprint": "fp_0705bf87c0"}, "type": "ai", "id": "run-fa0450a8-366a-4264-96c9-b8c53487380b", "tool_calls": [{"name": "Response", "args": {"queries": ["how to access and review PDF files online", "best practices for reviewing PDF documents", "tools for analyzing PDF content"]}, "id": "call_guQhRK2idKJvJmho609MT0f5", "type": "tool_call"}], "invalid_tool_calls": []}}}], "llm_output": null, "run": null, "type": "LLMResult"}
{"documents": [{"metadata": {"language": "en", "description": "The pace of AI application development is often rate-limited by high-quality evaluations because there is a paradox of choice. Developers often wonder how to engineer their prompt or which LLM best balances accuracy, latency, and cost. High quality evaluations can help you rapidly answer these types of questions with confidence.", "changefreq": null, "source": "https://docs.smith.langchain.com/evaluation/concepts", "title": "Concepts | \ud83e\udd9c\ufe0f\ud83d\udee0\ufe0f LangSmith", "content_type": "text/html; charset=utf-8", "lastmod": null, "priority": null, "loc": null, "uuid": "e07006e1-3edd-5630-8851-49f0e2518263"}, "page_content": "Use CaseDetailReference-free?LLM-as-judge?Pairwise relevantCriteriaTag if specific criteria is metYesYes - promptNoAccuracyStandard definitionNo (ground truth class)NoNoPrecisionStandard definitionNo (ground truth class)NoNoRecallStandard definitionNo (ground truth class)NoNoWas this page helpful?You can leave detailed feedback on GitHub.PreviousQuick StartNextEvaluation how-to guidesDatasetsCreating datasetsPartitioning datasetsEvaluatorsHumanHeuristicLLM-as-judgePairwiseApplying evaluationsUnit TestsRegression TestingBack-testingPairwise-testingOnline EvaluationExperiment ConfigurationsAgentsEvaluating an agent's final responseEvaluating a single step of an agentEvaluating an agent's trajectoryBest practicesRetrieval Augmented Generation (RAG)DatasetEvaluatorApplying RAG EvaluationRAG evaluation summaryCommon use-casesSummarizationClassification / TaggingCommunityDiscordTwitterGitHubDocs CodeLangSmith SDKPythonJS/TSMoreHomepageBlogLangChain Python DocsLangChain JS/TS DocsCopyright \u00a9 2024 LangChain, Inc.", "type": "Document"}, {"metadata": {"description": "AnalyticDB for PostgreSQL is a massively parallel processing (MPP) data warehousing service that is designed to analyze large volumes of data online.", "language": "en", "changefreq": "weekly", "source": "https://python.langchain.com/docs/integrations/vectorstores/analyticdb/", "title": "AnalyticDB | \ud83e\udd9c\ufe0f\ud83d\udd17 LangChain", "content_type": null, "lastmod": null, "priority": "0.5", "loc": "https://python.langchain.com/docs/integrations/vectorstores/analyticdb/", "uuid": "602e584b-8d9f-574d-9391-97abe4a39b64"}, "page_content": "Tonight, I\u2019d like to honor someone who has dedicated his life to serve this country: Justice Stephen Breyer\u2014an Army veteran, Constitutional scholar, and retiring Justice of the United States Supreme Court. Justice Breyer, thank you for your service. \n\nOne of the most serious constitutional responsibilities a President has is nominating someone to serve on the United States Supreme Court. \n\nAnd I did that 4 days ago, when I nominated Circuit Court of Appeals Judge Ketanji Brown Jackson. One of our nation\u2019s top legal minds, who will continue Justice Breyer\u2019s legacy of excellence.\n```\n\n## Related\u200b\n\n- Vector store [conceptual guide](/docs/concepts/vectorstores/)\n\n- Vector store [how-to guides](/docs/how_to/#vector-stores)\n\n#### Was this page helpful?\n\n- [Related](#related)", "type": "Document"}, {"metadata": {"description": "Hologres is a unified real-time data warehousing service developed by Alibaba Cloud. You can use Hologres to write, update, process, and analyze large amounts of data in real time.", "language": "en", "changefreq": "weekly", "source": "https://python.langchain.com/docs/integrations/vectorstores/hologres/", "title": "Hologres | \ud83e\udd9c\ufe0f\ud83d\udd17 LangChain", "content_type": null, "lastmod": null, "priority": "0.5", "loc": "https://python.langchain.com/docs/integrations/vectorstores/hologres/", "uuid": "ab394f69-6b1c-5a06-8672-ad6c91feda6f"}, "page_content": "Tonight, I\u2019d like to honor someone who has dedicated his life to serve this country: Justice Stephen Breyer\u2014an Army veteran, Constitutional scholar, and retiring Justice of the United States Supreme Court. Justice Breyer, thank you for your service. \n\nOne of the most serious constitutional responsibilities a President has is nominating someone to serve on the United States Supreme Court. \n\nAnd I did that 4 days ago, when I nominated Circuit Court of Appeals Judge Ketanji Brown Jackson. One of our nation\u2019s top legal minds, who will continue Justice Breyer\u2019s legacy of excellence.\n```\n\n## Related\u200b\n\n- Vector store [conceptual guide](/docs/concepts/vectorstores/)\n\n- Vector store [how-to guides](/docs/how_to/#vector-stores)\n\n#### Was this page helpful?\n\n- [Related](#related)", "type": "Document"}, {"metadata": {"description": "One challenge with retrieval is that usually you don't know the specific queries your document storage system will face when you ingest data into the system. This means that the information most relevant to a query may be buried in a document with a lot of irrelevant text. Passing that full document through your application can lead to more expensive LLM calls and poorer responses.", "language": "en", "changefreq": "weekly", "source": "https://python.langchain.com/docs/how_to/contextual_compression/", "title": "How to do retrieval with contextual compression | \ud83e\udd9c\ufe0f\ud83d\udd17 LangChain", "lastmod": null, "content_type": null, "priority": "0.5", "loc": "https://python.langchain.com/docs/how_to/contextual_compression/", "uuid": "0e224cfa-3f17-580f-83cd-030c2df600c0"}, "page_content": "compressed_docs = compression_retriever.invoke(\n    \"What did the president say about Ketanji Jackson Brown\"\n)\npretty_print_docs(compressed_docs)\n```\n\n**API Reference:**[LLMListwiseRerank](https://python.langchain.com/api_reference/langchain/retrievers/langchain.retrievers.document_compressors.listwise_rerank.LLMListwiseRerank.html) | [ChatOpenAI](https://python.langchain.com/api_reference/openai/chat_models/langchain_openai.chat_models.base.ChatOpenAI.html)\n```output\nDocument 1:\n\nTonight. I call on the Senate to: Pass the Freedom to Vote Act. Pass the John Lewis Voting Rights Act. And while you\u2019re at it, pass the Disclose Act so Americans can know who is funding our elections. \n\nTonight, I\u2019d like to honor someone who has dedicated his life to serve this country: Justice Stephen Breyer\u2014an Army veteran, Constitutional scholar, and retiring Justice of the United States Supreme Court. Justice Breyer, thank you for your service. \n\nOne of the most serious constitutional responsibilities a President has is nominating someone to serve on the United States Supreme Court. \n\nAnd I did that 4 days ago, when I nominated Circuit Court of Appeals Judge Ketanji Brown Jackson. One of our nation\u2019s top legal minds, who will continue Justice Breyer\u2019s legacy of excellence.\n```\n\n### EmbeddingsFilter\u200b\n\nMaking an extra LLM call over each retrieved document is expensive and slow. The `EmbeddingsFilter` provides a cheaper and faster option by embedding the documents and query and only returning those documents which have sufficiently similar embeddings to the query.\n\n```python\nfrom langchain.retrievers.document_compressors import EmbeddingsFilter\nfrom langchain_openai import OpenAIEmbeddings\n\nembeddings = OpenAIEmbeddings()\nembeddings_filter = EmbeddingsFilter(embeddings=embeddings, similarity_threshold=0.76)\ncompression_retriever = ContextualCompressionRetriever(\n    base_compressor=embeddings_filter, base_retriever=retriever\n)\n\ncompressed_docs = compression_retriever.invoke(\n    \"What did the president say about Ketanji Jackson Brown\"\n)\npretty_print_docs(compressed_docs)\n```\n\n**API Reference:**[EmbeddingsFilter](https://python.langchain.com/api_reference/langchain/retrievers/langchain.retrievers.document_compressors.embeddings_filter.EmbeddingsFilter.html) | [OpenAIEmbeddings](https://python.langchain.com/api_reference/openai/embeddings/langchain_openai.embeddings.base.OpenAIEmbeddings.html)\n```output\nDocument 1:\n\nTonight. I call on the Senate to: Pass the Freedom to Vote Act. Pass the John Lewis Voting Rights Act. And while you\u2019re at it, pass the Disclose Act so Americans can know who is funding our elections. \n\nTonight, I\u2019d like to honor someone who has dedicated his life to serve this country: Justice Stephen Breyer\u2014an Army veteran, Constitutional scholar, and retiring Justice of the United States Supreme Court. Justice Breyer, thank you for your service. \n\nOne of the most serious constitutional responsibilities a President has is nominating someone to serve on the United States Supreme Court. \n\nAnd I did that 4 days ago, when I nominated Circuit Court of Appeals Judge Ketanji Brown Jackson. One of our nation\u2019s top legal minds, who will continue Justice Breyer\u2019s legacy of excellence.\n----------------------------------------------------------------------------------------------------\nDocument 2:\n\nA former top litigator in private practice. A former federal public defender. And from a family of public school educators and police officers. A consensus builder. Since she\u2019s been nominated, she\u2019s received a broad range of support\u2014from the Fraternal Order of Police to former judges appointed by Democrats and Republicans. \n\nAnd if we are to advance liberty and justice, we need to secure the Border and fix the immigration system. \n\nWe can do both. At our border, we\u2019ve installed new technology like cutting-edge scanners to better detect drug smuggling.  \n\nWe\u2019ve set up joint patrols with Mexico and Guatemala to catch more human traffickers.", "type": "Document"}, {"metadata": {"description": "This notebook shows how to use DashScope Reranker for document compression and retrieval. DashScope is the generative AI service from Alibaba Cloud (Aliyun).", "language": "en", "changefreq": "weekly", "source": "https://python.langchain.com/docs/integrations/document_transformers/dashscope_rerank/", "title": "DashScope Reranker | \ud83e\udd9c\ufe0f\ud83d\udd17 LangChain", "content_type": null, "lastmod": null, "priority": "0.5", "loc": "https://python.langchain.com/docs/integrations/document_transformers/dashscope_rerank/", "uuid": "a9da7658-305c-5a2e-8f60-e5c6cc7296c2"}, "page_content": "One of the most serious constitutional responsibilities a President has is nominating someone to serve on the United States Supreme Court. \n\nAnd I did that 4 days ago, when I nominated Circuit Court of Appeals Judge Ketanji Brown Jackson. One of our nation\u2019s top legal minds, who will continue Justice Breyer\u2019s legacy of excellence.\n----------------------------------------------------------------------------------------------------\nDocument 3:\n\nTo all Americans, I will be honest with you, as I\u2019ve always promised. A Russian dictator, invading a foreign country, has costs around the world. \n\nAnd I\u2019m taking robust action to make sure the pain of our sanctions  is targeted at Russia\u2019s economy. And I will use every tool at our disposal to protect American businesses and consumers. \n\nTonight, I can announce that the United States has worked with 30 other countries to release 60 Million barrels of oil from reserves around the world.\n----------------------------------------------------------------------------------------------------\nDocument 4:\n\nWe cannot let this happen. \n\nTonight. I call on the Senate to: Pass the Freedom to Vote Act. Pass the John Lewis Voting Rights Act. And while you\u2019re at it, pass the Disclose Act so Americans can know who is funding our elections. \n\nTonight, I\u2019d like to honor someone who has dedicated his life to serve this country: Justice Stephen Breyer\u2014an Army veteran, Constitutional scholar, and retiring Justice of the United States Supreme Court. Justice Breyer, thank you for your service.\n----------------------------------------------------------------------------------------------------\nDocument 5:\n\nTonight I say to the Russian oligarchs and corrupt leaders who have bilked billions of dollars off this violent regime no more. \n\nThe U.S. Department of Justice is assembling a dedicated task force to go after the crimes of Russian oligarchs.  \n\nWe are joining with our European allies to find and seize your yachts your luxury apartments your private jets. We are coming for your ill-begotten gains.\n----------------------------------------------------------------------------------------------------\nDocument 6:\n\nEvery Administration says they\u2019ll do it, but we are actually doing it. \n\nWe will buy American to make sure everything from the deck of an aircraft carrier to the steel on highway guardrails are made in America. \n\nBut to compete for the best jobs of the future, we also need to level the playing field with China and other competitors.\n----------------------------------------------------------------------------------------------------\nDocument 7:\n\nWhen we invest in our workers, when we build the economy from the bottom up and the middle out together, we can do something we haven\u2019t done in a long time: build a better America. \n\nFor more than two years, COVID-19 has impacted every decision in our lives and the life of the nation. \n\nAnd I know you\u2019re tired, frustrated, and exhausted. \n\nBut I also know this.\n----------------------------------------------------------------------------------------------------\nDocument 8:\n\nA former top litigator in private practice. A former federal public defender. And from a family of public school educators and police officers. A consensus builder. Since she\u2019s been nominated, she\u2019s received a broad range of support\u2014from the Fraternal Order of Police to former judges appointed by Democrats and Republicans. \n\nAnd if we are to advance liberty and justice, we need to secure the Border and fix the immigration system.\n----------------------------------------------------------------------------------------------------\nDocument 9:\n\nMy plan will not only lower costs to give families a fair shot, it will lower the deficit. \n\nThe previous Administration not only ballooned the deficit with tax cuts for the very wealthy and corporations, it undermined the watchdogs whose job was to keep pandemic relief funds from being wasted.", "type": "Document"}, {"metadata": {"description": "When splitting documents for retrieval, there are often conflicting desires:", "language": "en", "changefreq": "weekly", "source": "https://python.langchain.com/docs/how_to/parent_document_retriever/", "title": "How to use the Parent Document Retriever | \ud83e\udd9c\ufe0f\ud83d\udd17 LangChain", "lastmod": null, "content_type": null, "priority": "0.5", "loc": "https://python.langchain.com/docs/how_to/parent_document_retriever/", "uuid": "5c24f9cf-90e6-52f4-8da6-d8535cfad74d"}, "page_content": "```python\nretrieved_docs = retriever.invoke(\"justice breyer\")\n```\n\n```python\nlen(retrieved_docs[0].page_content)\n```\n\n```output\n38540\n```\n\n## Retrieving larger chunks\u200b\n\nSometimes, the full documents can be too big to want to retrieve them as is. In that case, what we really want to do is to first split the raw documents into larger chunks, and then split it into smaller chunks. We then index the smaller chunks, but on retrieval we retrieve the larger chunks (but still not the full documents).\n\n```python\n# This text splitter is used to create the parent documents\nparent_splitter = RecursiveCharacterTextSplitter(chunk_size=2000)\n# This text splitter is used to create the child documents\n# It should create documents smaller than the parent\nchild_splitter = RecursiveCharacterTextSplitter(chunk_size=400)\n# The vectorstore to use to index the child chunks\nvectorstore = Chroma(\n    collection_name=\"split_parents\", embedding_function=OpenAIEmbeddings()\n)\n# The storage layer for the parent documents\nstore = InMemoryStore()\n```\n\n```python\nretriever = ParentDocumentRetriever(\n    vectorstore=vectorstore,\n    docstore=store,\n    child_splitter=child_splitter,\n    parent_splitter=parent_splitter,\n)\n```\n\n```python\nretriever.add_documents(docs)\n```\n\nWe can see that there are much more than two documents now - these are the larger chunks.\n\n```python\nlen(list(store.yield_keys()))\n```\n\n```output\n66\n```\n\nLet's make sure the underlying vector store still retrieves the small chunks.\n\n```python\nsub_docs = vectorstore.similarity_search(\"justice breyer\")\n```\n\n```python\nprint(sub_docs[0].page_content)\n```\n\n```output\nTonight, I\u2019d like to honor someone who has dedicated his life to serve this country: Justice Stephen Breyer\u2014an Army veteran, Constitutional scholar, and retiring Justice of the United States Supreme Court. Justice Breyer, thank you for your service. \n\nOne of the most serious constitutional responsibilities a President has is nominating someone to serve on the United States Supreme Court.\n```\n\n```python\nretrieved_docs = retriever.invoke(\"justice breyer\")\n```\n\n```python\nlen(retrieved_docs[0].page_content)\n```\n\n```output\n1849\n```\n\n```python\nprint(retrieved_docs[0].page_content)\n```\n\n```output\nIn state after state, new laws have been passed, not only to suppress the vote, but to subvert entire elections. \n\nWe cannot let this happen. \n\nTonight. I call on the Senate to: Pass the Freedom to Vote Act. Pass the John Lewis Voting Rights Act. And while you\u2019re at it, pass the Disclose Act so Americans can know who is funding our elections. \n\nTonight, I\u2019d like to honor someone who has dedicated his life to serve this country: Justice Stephen Breyer\u2014an Army veteran, Constitutional scholar, and retiring Justice of the United States Supreme Court. Justice Breyer, thank you for your service. \n\nOne of the most serious constitutional responsibilities a President has is nominating someone to serve on the United States Supreme Court. \n\nAnd I did that 4 days ago, when I nominated Circuit Court of Appeals Judge Ketanji Brown Jackson. One of our nation\u2019s top legal minds, who will continue Justice Breyer\u2019s legacy of excellence. \n\nA former top litigator in private practice. A former federal public defender. And from a family of public school educators and police officers. A consensus builder. Since she\u2019s been nominated, she\u2019s received a broad range of support\u2014from the Fraternal Order of Police to former judges appointed by Democrats and Republicans. \n\nAnd if we are to advance liberty and justice, we need to secure the Border and fix the immigration system. \n\nWe can do both. At our border, we\u2019ve installed new technology like cutting-edge scanners to better detect drug smuggling.  \n\nWe\u2019ve set up joint patrols with Mexico and Guatemala to catch more human traffickers.  \n\nWe\u2019re putting in place dedicated immigration judges so families fleeing persecution and violence can have their cases heard faster.", "type": "Document"}, {"metadata": {"description": "UpTrain [github || website || docs] is an open-source platform to evaluate and improve LLM applications. It provides grades for 20+ preconfigured checks (covering language, code, embedding use cases), performs root cause analyses on instances of failure cases and provides guidance for resolving them.", "language": "en", "changefreq": "weekly", "source": "https://python.langchain.com/docs/integrations/callbacks/uptrain/", "title": "uptrain | \ud83e\udd9c\ufe0f\ud83d\udd17 LangChain", "lastmod": null, "content_type": null, "priority": "0.5", "loc": "https://python.langchain.com/docs/integrations/callbacks/uptrain/", "uuid": "6c5602df-140a-5c31-b5f5-cc188744c2ee"}, "page_content": "Question: What did the president say about Ketanji Brown Jackson\nResponse: The president mentioned that he had nominated Ketanji Brown Jackson to serve on the United States Supreme Court 4 days ago. He described her as one of the nation's top legal minds who will continue Justice Breyer\u2019s legacy of excellence. He also mentioned that she is a former top litigator in private practice, a former federal public defender, and comes from a family of public school educators and police officers. He described her as a consensus builder and noted that since her nomination, she has received a broad range of support from various groups, including the Fraternal Order of Police and former judges appointed by both Democrats and Republicans.\n\nContext Relevance Score: 1.0\nFactual Accuracy Score: 1.0\nResponse Completeness Score: 1.0\n```\n\n# 2. Multi Query Generation\n\nThe **MultiQueryRetriever** is used to tackle the problem that the RAG pipeline might not return the best set of documents based on the query. It generates multiple queries that mean the same as the original query and then fetches documents for each.\n\nTo evluate this retriever, UpTrain will run the following evaluation:\n\n- **Multi Query Accuracy**: Checks if the multi-queries generated mean the same as the original query.\n\n```python\n# Create the retriever\nmulti_query_retriever = MultiQueryRetriever.from_llm(retriever=retriever, llm=llm)\n\n# Create the uptrain callback\nuptrain_callback = UpTrainCallbackHandler(key_type=KEY_TYPE, api_key=API_KEY)\nconfig = {\"callbacks\": [uptrain_callback]}\n\n# Create the RAG prompt\ntemplate = \"\"\"Answer the question based only on the following context, which can include text and tables:\n{context}\nQuestion: {question}\n\"\"\"\nrag_prompt_text = ChatPromptTemplate.from_template(template)\n\nchain = (\n    {\"context\": multi_query_retriever, \"question\": RunnablePassthrough()}\n    | rag_prompt_text\n    | llm\n    | StrOutputParser()\n)\n\n# Invoke the chain with a query\nquestion = \"What did the president say about Ketanji Brown Jackson\"\ndocs = chain.invoke(question, config=config)\n```\n\n```output\n[32m2024-04-17 17:04:10.675[0m | [1mINFO    [0m | [36muptrain.framework.evalllm[0m:[36mevaluate_on_server[0m:[36m378[0m - [1mSending evaluation request for rows 0 to <50 to the Uptrain[0m\n[32m2024-04-17 17:04:16.804[0m | [1mINFO    [0m | [36muptrain.framework.evalllm[0m:[36mevaluate[0m:[36m367[0m - [1mLocal server not running, start the server to log data and visualize in the dashboard![0m\n``````output\n\nQuestion: What did the president say about Ketanji Brown Jackson\nMulti Queries:\n  - How did the president comment on Ketanji Brown Jackson?\n  - What were the president's remarks regarding Ketanji Brown Jackson?\n  - What statements has the president made about Ketanji Brown Jackson?\n\nMulti Query Accuracy Score: 0.5\n``````output\n[32m2024-04-17 17:04:22.027[0m | [1mINFO    [0m | [36muptrain.framework.evalllm[0m:[36mevaluate_on_server[0m:[36m378[0m - [1mSending evaluation request for rows 0 to <50 to the Uptrain[0m\n[32m2024-04-17 17:04:44.033[0m | [1mINFO    [0m | [36muptrain.framework.evalllm[0m:[36mevaluate[0m:[36m367[0m - [1mLocal server not running, start the server to log data and visualize in the dashboard![0m\n``````output\n\nQuestion: What did the president say about Ketanji Brown Jackson\nResponse: The president mentioned that he had nominated Circuit Court of Appeals Judge Ketanji Brown Jackson to serve on the United States Supreme Court 4 days ago. He described her as one of the nation's top legal minds who will continue Justice Breyer\u2019s legacy of excellence. He also mentioned that since her nomination, she has received a broad range of support\u2014from the Fraternal Order of Police to former judges appointed by Democrats and Republicans.\n\nContext Relevance Score: 1.0\nFactual Accuracy Score: 1.0\nResponse Completeness Score: 1.0\n```\n\n# 3. Context Compression and Reranking", "type": "Document"}, {"metadata": {"language": "en", "description": "Timescale Vector is PostgreSQL++ vector database for AI applications.", "changefreq": "weekly", "source": "https://python.langchain.com/docs/integrations/vectorstores/timescalevector/", "title": "Timescale Vector (Postgres) | \ud83e\udd9c\ufe0f\ud83d\udd17 LangChain", "content_type": null, "lastmod": null, "priority": "0.5", "loc": "https://python.langchain.com/docs/integrations/vectorstores/timescalevector/", "uuid": "97b75c76-ec70-52a3-a5bc-f34f7df23687"}, "page_content": "Tonight, I\u2019d like to honor someone who has dedicated his life to serve this country: Justice Stephen Breyer\u2014an Army veteran, Constitutional scholar, and retiring Justice of the United States Supreme Court. Justice Breyer, thank you for your service. \n\nOne of the most serious constitutional responsibilities a President has is nominating someone to serve on the United States Supreme Court. \n\nAnd I did that 4 days ago, when I nominated Circuit Court of Appeals Judge Ketanji Brown Jackson. One of our nation\u2019s top legal minds, who will continue Justice Breyer\u2019s legacy of excellence.\n--------------------------------------------------------------------------------\n--------------------------------------------------------------------------------\nScore:  0.18452197313308139\nTonight. I call on the Senate to: Pass the Freedom to Vote Act. Pass the John Lewis Voting Rights Act. And while you\u2019re at it, pass the Disclose Act so Americans can know who is funding our elections. \n\nTonight, I\u2019d like to honor someone who has dedicated his life to serve this country: Justice Stephen Breyer\u2014an Army veteran, Constitutional scholar, and retiring Justice of the United States Supreme Court. Justice Breyer, thank you for your service. \n\nOne of the most serious constitutional responsibilities a President has is nominating someone to serve on the United States Supreme Court. \n\nAnd I did that 4 days ago, when I nominated Circuit Court of Appeals Judge Ketanji Brown Jackson. One of our nation\u2019s top legal minds, who will continue Justice Breyer\u2019s legacy of excellence.\n--------------------------------------------------------------------------------\n--------------------------------------------------------------------------------\nScore:  0.21720781018594182\nA former top litigator in private practice. A former federal public defender. And from a family of public school educators and police officers. A consensus builder. Since she\u2019s been nominated, she\u2019s received a broad range of support\u2014from the Fraternal Order of Police to former judges appointed by Democrats and Republicans. \n\nAnd if we are to advance liberty and justice, we need to secure the Border and fix the immigration system. \n\nWe can do both. At our border, we\u2019ve installed new technology like cutting-edge scanners to better detect drug smuggling.  \n\nWe\u2019ve set up joint patrols with Mexico and Guatemala to catch more human traffickers.  \n\nWe\u2019re putting in place dedicated immigration judges so families fleeing persecution and violence can have their cases heard faster. \n\nWe\u2019re securing commitments and supporting partners in South and Central America to host more refugees and secure their own borders.\n--------------------------------------------------------------------------------\n--------------------------------------------------------------------------------\nScore:  0.21724902288621384\nA former top litigator in private practice. A former federal public defender. And from a family of public school educators and police officers. A consensus builder. Since she\u2019s been nominated, she\u2019s received a broad range of support\u2014from the Fraternal Order of Police to former judges appointed by Democrats and Republicans. \n\nAnd if we are to advance liberty and justice, we need to secure the Border and fix the immigration system. \n\nWe can do both. At our border, we\u2019ve installed new technology like cutting-edge scanners to better detect drug smuggling.  \n\nWe\u2019ve set up joint patrols with Mexico and Guatemala to catch more human traffickers.  \n\nWe\u2019re putting in place dedicated immigration judges so families fleeing persecution and violence can have their cases heard faster. \n\nWe\u2019re securing commitments and supporting partners in South and Central America to host more refugees and secure their own borders.\n--------------------------------------------------------------------------------\n```\n\n### Using a Timescale Vector as a Retriever\u200b", "type": "Document"}, {"metadata": {"description": "Intel's VDMS is a storage solution for efficient access of big-\u201dvisual\u201d-data that aims to achieve cloud scale by searching for relevant visual data via visual metadata stored as a graph and enabling machine friendly enhancements to visual data for faster access. VDMS is licensed under MIT.", "language": "en", "changefreq": "weekly", "source": "https://python.langchain.com/docs/integrations/vectorstores/vdms/", "title": "Intel's Visual Data Management System (VDMS) | \ud83e\udd9c\ufe0f\ud83d\udd17 LangChain", "lastmod": null, "content_type": null, "priority": "0.5", "loc": "https://python.langchain.com/docs/integrations/vectorstores/vdms/", "uuid": "4f15705d-8620-58e1-9dfd-0218bc8b858c"}, "page_content": "Metadata:\n\tid:\t32\n\tpage_number:\t32\n\tpresident_included:\tTrue\n\tsource:\t../../how_to/state_of_the_union.txt\n--------------------------------------------------\n\nContent:\n\tAs Frances Haugen, who is here with us tonight, has shown, we must hold social media platforms accountable for the national experiment they\u2019re conducting on our children for profit. \n\nIt\u2019s time to strengthen privacy protections, ban targeted advertising to children, demand tech companies stop collecting personal data on our children. \n\nAnd let\u2019s get all Americans the mental health services they need. More people they can turn to for help, and full parity between physical and mental health care. \n\nThird, support our veterans. \n\nVeterans are the best of us. \n\nI\u2019ve always believed that we have a sacred obligation to equip all those we send to war and care for them and their families when they come home. \n\nMy administration is providing assistance with job training and housing, and now helping lower-income veterans get VA care debt-free.  \n\nOur troops in Iraq and Afghanistan faced many dangers.\n\nMetadata:\n\tid:\t37\n\tpage_number:\t37\n\tpresident_included:\tFalse\n\tsource:\t../../how_to/state_of_the_union.txt\n--------------------------------------------------\n\nContent:\n\tA former top litigator in private practice. A former federal public defender. And from a family of public school educators and police officers. A consensus builder. Since she\u2019s been nominated, she\u2019s received a broad range of support\u2014from the Fraternal Order of Police to former judges appointed by Democrats and Republicans. \n\nAnd if we are to advance liberty and justice, we need to secure the Border and fix the immigration system. \n\nWe can do both. At our border, we\u2019ve installed new technology like cutting-edge scanners to better detect drug smuggling.  \n\nWe\u2019ve set up joint patrols with Mexico and Guatemala to catch more human traffickers.  \n\nWe\u2019re putting in place dedicated immigration judges so families fleeing persecution and violence can have their cases heard faster. \n\nWe\u2019re securing commitments and supporting partners in South and Central America to host more refugees and secure their own borders.\n\nMetadata:\n\tid:\t33\n\tpage_number:\t33\n\tpresident_included:\tFalse\n\tsource:\t../../how_to/state_of_the_union.txt\n--------------------------------------------------\n```\n\n```python\n# Query (with filtering)\nk = 3\nconstraints = {\"page_number\": [\">\", 30], \"president_included\": [\"==\", True]}\nquery = \"What did the president say about Ketanji Brown Jackson\"\nreturned_docs = db_FaissFlat.similarity_search(query, k=k, filter=constraints)\nprint_results(returned_docs, score=False)\n```\n\n```output\n--------------------------------------------------\n\nContent:\n\tTonight. I call on the Senate to: Pass the Freedom to Vote Act. Pass the John Lewis Voting Rights Act. And while you\u2019re at it, pass the Disclose Act so Americans can know who is funding our elections. \n\nTonight, I\u2019d like to honor someone who has dedicated his life to serve this country: Justice Stephen Breyer\u2014an Army veteran, Constitutional scholar, and retiring Justice of the United States Supreme Court. Justice Breyer, thank you for your service. \n\nOne of the most serious constitutional responsibilities a President has is nominating someone to serve on the United States Supreme Court. \n\nAnd I did that 4 days ago, when I nominated Circuit Court of Appeals Judge Ketanji Brown Jackson. One of our nation\u2019s top legal minds, who will continue Justice Breyer\u2019s legacy of excellence.\n\nMetadata:\n\tid:\t32\n\tpage_number:\t32\n\tpresident_included:\tTrue\n\tsource:\t../../how_to/state_of_the_union.txt\n--------------------------------------------------\n\nContent:\n\tAnd for our LGBTQ+ Americans, let\u2019s finally get the bipartisan Equality Act to my desk. The onslaught of state laws targeting transgender Americans and their families is wrong.", "type": "Document"}], "steps": ["Prepare to answer specific questions based on the extracted information."]}
{"generations": [{"text": "", "generation_info": {"finish_reason": "stop", "model_name": "gpt-4o-mini-2024-07-18", "system_fingerprint": "fp_0705bf87c0"}, "type": "ChatGeneration", "message": {"lc": 1, "type": "constructor", "id": ["langchain", "schema", "messages", "AIMessage"], "kwargs": {"content": "", "additional_kwargs": {"tool_calls": [{"index": 0, "id": "call_lGtmc9HhvQmQCqAuL7eB7Fu0", "function": {"arguments": "{\"queries\":[\"Canadian Judicial Council overview and functions\",\"Bill C-9 implications for the Canadian Judicial Council\",\"Recent developments regarding Bill C-9 and the Canadian Judicial Council\"]}", "name": "Response"}, "type": "function"}]}, "response_metadata": {"finish_reason": "stop", "model_name": "gpt-4o-mini-2024-07-18", "system_fingerprint": "fp_0705bf87c0"}, "type": "ai", "id": "run-1c27d384-aff8-4b44-8cdb-92515c20f451", "tool_calls": [{"name": "Response", "args": {"queries": ["Canadian Judicial Council overview and functions", "Bill C-9 implications for the Canadian Judicial Council", "Recent developments regarding Bill C-9 and the Canadian Judicial Council"]}, "id": "call_lGtmc9HhvQmQCqAuL7eB7Fu0", "type": "tool_call"}], "invalid_tool_calls": []}}}], "llm_output": null, "run": null, "type": "LLMResult"}
{"documents": [{"metadata": {"description": "When working with files, like PDFs, you're likely to encounter text that exceeds your language model's context window. To process this text, consider these strategies:", "language": "en", "changefreq": "weekly", "source": "https://python.langchain.com/docs/how_to/extraction_long_text/", "title": "How to handle long text when doing extraction | \ud83e\udd9c\ufe0f\ud83d\udd17 LangChain", "content_type": null, "lastmod": null, "priority": "0.5", "loc": "https://python.langchain.com/docs/how_to/extraction_long_text/", "uuid": "7dfd32a5-8904-50c5-b15c-624f51caf4e1"}, "page_content": "We suggest experimenting with your use case and determining whether this approach works or not.\n\nTo implement the RAG based approach:\n\n1. Chunk up your document(s) and index them (e.g., in a vectorstore);\n\n2. Prepend the `extractor` chain with a retrieval step using the vectorstore.\n\nHere's a simple example that relies on the `FAISS` vectorstore.\n\n```python\nfrom langchain_community.vectorstores import FAISS\nfrom langchain_core.documents import Document\nfrom langchain_core.runnables import RunnableLambda\nfrom langchain_openai import OpenAIEmbeddings\nfrom langchain_text_splitters import CharacterTextSplitter\n\ntexts = text_splitter.split_text(document.page_content)\nvectorstore = FAISS.from_texts(texts, embedding=OpenAIEmbeddings())\n\nretriever = vectorstore.as_retriever(\n    search_kwargs={\"k\": 1}\n)  # Only extract from first document\n```\n\n**API Reference:**[FAISS](https://python.langchain.com/api_reference/community/vectorstores/langchain_community.vectorstores.faiss.FAISS.html) | [Document](https://python.langchain.com/api_reference/core/documents/langchain_core.documents.base.Document.html) | [RunnableLambda](https://python.langchain.com/api_reference/core/runnables/langchain_core.runnables.base.RunnableLambda.html) | [OpenAIEmbeddings](https://python.langchain.com/api_reference/openai/embeddings/langchain_openai.embeddings.base.OpenAIEmbeddings.html) | [CharacterTextSplitter](https://python.langchain.com/api_reference/text_splitters/character/langchain_text_splitters.character.CharacterTextSplitter.html)\nIn this case the RAG extractor is only looking at the top document.\n\n```python\nrag_extractor = {\n    \"text\": retriever | (lambda docs: docs[0].page_content)  # fetch content of top doc\n} | extractor\n```\n\n```python\nresults = rag_extractor.invoke(\"Key developments associated with cars\")\n```\n\n```python\nfor key_development in results.key_developments:\n    print(key_development)\n```\n\n```output\nyear=2006 description='Car-sharing services in the US experienced double-digit growth in revenue and membership.' evidence='in the US, some car-sharing services have experienced double-digit growth in revenue and membership growth between 2006 and 2007.'\nyear=2020 description='56 million cars were manufactured worldwide, with China producing the most.' evidence='In 2020, there were 56 million cars manufactured worldwide, down from 67 million the previous year. The automotive industry in China produces by far the most (20 million in 2020).'\n```\n\n## Common issues\u200b\n\nDifferent methods have their own pros and cons related to cost, speed, and accuracy.\n\nWatch out for these issues:\n\n- Chunking content means that the LLM can fail to extract information if the information is spread across multiple chunks.\n\n- Large chunk overlap may cause the same information to be extracted twice, so be prepared to de-duplicate!\n\n- LLMs can make up data. If looking for a single fact across a large text and using a brute force approach, you may end up getting more made up data.\n\n#### Was this page helpful?\n\n- [Setup](#setup)\n\n- [Define the schema](#define-the-schema)\n\n- [Create an extractor](#create-an-extractor)\n\n- [Brute force approach](#brute-force-approach)- [Merge results](#merge-results)\n\n- [RAG based approach](#rag-based-approach)\n\n- [Common issues](#common-issues)", "type": "Document"}, {"metadata": {"description": "When working with files, like PDFs, you're likely to encounter text that exceeds your language model's context window. To process this text, consider these strategies:", "language": "en", "changefreq": "weekly", "source": "https://python.langchain.com/docs/how_to/extraction_long_text/", "title": "How to handle long text when doing extraction | \ud83e\udd9c\ufe0f\ud83d\udd17 LangChain", "lastmod": null, "content_type": null, "priority": "0.5", "loc": "https://python.langchain.com/docs/how_to/extraction_long_text/", "uuid": "5c687db0-8502-5dc9-8617-22f2d5ecf7f1"}, "page_content": "```python\nkey_developments = []\n\nfor extraction in extractions:\n    key_developments.extend(extraction.key_developments)\n\nkey_developments[:10]\n```\n\n```output\n[KeyDevelopment(year=1769, description='Nicolas-Joseph Cugnot built the first full-scale, self-propelled mechanical vehicle, a steam-powered tricycle.', evidence='Nicolas-Joseph Cugnot is widely credited with building the first full-scale, self-propelled mechanical vehicle in about 1769; he created a steam-powered tricycle.'),\n KeyDevelopment(year=1807, description=\"Nic\u00e9phore Ni\u00e9pce and his brother Claude created what was probably the world's first internal combustion engine.\", evidence=\"In 1807, Nic\u00e9phore Ni\u00e9pce and his brother Claude created what was probably the world's first internal combustion engine (which they called a Pyr\u00e9olophore), but installed it in a boat on the river Saone in France.\"),\n KeyDevelopment(year=1886, description='Carl Benz patented the Benz Patent-Motorwagen, marking the birth of the modern car.', evidence='In November 1881, French inventor Gustave Trouv\u00e9 demonstrated a three-wheeled car powered by electricity at the International Exposition of Electricity. Although several other German engineers (including Gottlieb Daimler, Wilhelm Maybach, and Siegfried Marcus) were working on cars at about the same time, the year 1886 is regarded as the birth year of the modern car\u2014a practical, marketable automobile for everyday use\u2014when the German Carl Benz patented his Benz Patent-Motorwagen; he is generally acknowledged as the inventor of the car.'),\n KeyDevelopment(year=1886, description='Carl Benz began promotion of his vehicle, marking the introduction of the first commercially available automobile.', evidence='Benz began promotion of the vehicle on 3 July 1886.'),\n KeyDevelopment(year=1888, description=\"Bertha Benz undertook the first road trip by car to prove the road-worthiness of her husband's invention.\", evidence=\"In August 1888, Bertha Benz, the wife and business partner of Carl Benz, undertook the first road trip by car, to prove the road-worthiness of her husband's invention.\"),\n KeyDevelopment(year=1896, description='Benz designed and patented the first internal-combustion flat engine, called boxermotor.', evidence='In 1896, Benz designed and patented the first internal-combustion flat engine, called boxermotor.'),\n KeyDevelopment(year=1897, description='The first motor car in central Europe and one of the first factory-made cars in the world, the Pr\u00e4sident automobil, was produced by Nesselsdorfer Wagenbau.', evidence='The first motor car in central Europe and one of the first factory-made cars in the world, was produced by Czech company Nesselsdorfer Wagenbau (later renamed to Tatra) in 1897, the Pr\u00e4sident automobil.'),\n KeyDevelopment(year=1901, description='Ransom Olds started large-scale, production-line manufacturing of affordable cars at his Oldsmobile factory in Lansing, Michigan.', evidence='Large-scale, production-line manufacturing of affordable cars was started by Ransom Olds in 1901 at his Oldsmobile factory in Lansing, Michigan.'),\n KeyDevelopment(year=1913, description=\"Henry Ford introduced the world's first moving assembly line for cars at the Highland Park Ford Plant.\", evidence=\"This concept was greatly expanded by Henry Ford, beginning in 1913 with the world's first moving assembly line for cars at the Highland Park Ford Plant.\")]\n```\n\n## RAG based approach\u200b\n\nAnother simple idea is to chunk up the text, but instead of extracting information from every chunk, just focus on the the most relevant chunks.\n\ncautionIt can be difficult to identify which chunks are relevant.\n\nFor example, in the `car` article we're using here, most of the article contains key development information. So by using\n**RAG**, we'll likely be throwing out a lot of relevant information.\n\nWe suggest experimenting with your use case and determining whether this approach works or not.\n\nTo implement the RAG based approach:", "type": "Document"}, {"metadata": {"description": "This guide assumes familiarity with the following concepts:", "language": "en", "changefreq": "weekly", "source": "https://python.langchain.com/docs/tutorials/extraction/", "title": "Build an Extraction Chain | \ud83e\udd9c\ufe0f\ud83d\udd17 LangChain", "lastmod": null, "content_type": null, "priority": "0.5", "loc": "https://python.langchain.com/docs/tutorials/extraction/", "uuid": "f4b59370-e4c5-529d-9adc-b2a6eb8d4eef"}, "page_content": "class Data(BaseModel):\n    \"\"\"Extracted data about people.\"\"\"\n\n    # Creates a model so that we can extract multiple entities.\n    people: List[Person]\n```\n\nimportantExtraction might not be perfect here. Please continue to see how to use **Reference Examples** to improve the quality of extraction, and see the **guidelines** section!\n\n```python\nrunnable = prompt | llm.with_structured_output(schema=Data)\ntext = \"My name is Jeff, my hair is black and i am 6 feet tall. Anna has the same color hair as me.\"\nrunnable.invoke({\"text\": text})\n```\n\n```output\nData(people=[Person(name='Jeff', hair_color=None, height_in_meters=None), Person(name='Anna', hair_color=None, height_in_meters=None)])\n```\n\ntipWhen the schema accommodates the extraction of **multiple entities**, it also allows the model to extract **no entities** if no relevant information\nis in the text by providing an empty list.\n\nThis is usually a **good** thing! It allows specifying **required** attributes on an entity without necessarily forcing the model to detect this entity.\n\nWe can see the LangSmith trace here: [https://smith.langchain.com/public/7173764d-5e76-45fe-8496-84460bd9cdef/r](https://smith.langchain.com/public/7173764d-5e76-45fe-8496-84460bd9cdef/r)\n\n## Next steps\u200b\n\nNow that you understand the basics of extraction with LangChain, you're ready to proceed to the rest of the how-to guides:\n\n- [Add Examples](/docs/how_to/extraction_examples/): Learn how to use **reference examples** to improve performance.\n\n- [Handle Long Text](/docs/how_to/extraction_long_text/): What should you do if the text does not fit into the context window of the LLM?\n\n- [Use a Parsing Approach](/docs/how_to/extraction_parse/): Use a prompt based approach to extract with models that do not support **tool/function calling**.\n\n#### Was this page helpful?\n\n- [Setup](#setup)- [Jupyter Notebook](#jupyter-notebook)\n\n- [Installation](#installation)\n\n- [LangSmith](#langsmith)\n\n- [The Schema](#the-schema)\n\n- [The Extractor](#the-extractor)\n\n- [Multiple Entities](#multiple-entities)\n\n- [Next steps](#next-steps)", "type": "Document"}, {"metadata": {"language": "en", "description": "This Jupyter Notebook demonstrates how to use Eden AI tools with an Agent.", "changefreq": "weekly", "source": "https://python.langchain.com/docs/integrations/tools/edenai_tools/", "title": "Eden AI | \ud83e\udd9c\ufe0f\ud83d\udd17 LangChain", "lastmod": null, "content_type": null, "priority": "0.5", "loc": "https://python.langchain.com/docs/integrations/tools/edenai_tools/", "uuid": "c2b59f24-a6ed-5923-b04e-763734df2c8f"}, "page_content": "you can have more details of the execution by printing the result\n\n```python\nresult\n```\n\n```output\n{'input': ' i have this url of an image : \"https://static.javatpoint.com/images/objects.jpg\"\\n                   first : i want to know if the image contain objects .\\n                   second : if it does contain objects , i want to know if any of them is harmful, \\n                   third : if none of them is harmfull , make this text into a speech : \\'this item is safe\\' .\\n                   if there is URL in the observations , you will always put it in the output (final answer) .\\n                   ',\n 'output': \"The image contains objects such as Apple, Backpack, Luggage & bags, and Container. None of them are harmful. The text 'this item is safe' can be found in the audio file at https://d14uq1pz7dzsdq.cloudfront.net/0546db8b-528e-4b63-9a69-d14d43ad1566_.mp3?Expires=1693316753&Signature=N0KZeK9I-1s7wTgiQOAwH7LFlltwyonSJcDnkdnr8JIJmbgSw6fo6RTxWl~VvD2Hg6igJqxtJFFWyrBmmx-f9wWLw3bZSnuMxkhTRqLX9aUA9N-vPJGiRZV5BFredaOm8pwfo8TcXhVjw08iSxv8GSuyZEIwZkiq4PzdiyVTnKKji6eyt\",\n 'intermediate_steps': [(AgentAction(tool='edenai_object_detection', tool_input='https://static.javatpoint.com/images/objects.jpg', log=' I need to determine if the image contains objects, if any of them are harmful, and then convert the text to speech.\\nAction: edenai_object_detection\\nAction Input: https://static.javatpoint.com/images/objects.jpg'),\n   'Apple - Confidence 0.94003654\\nApple - Confidence 0.94003654\\nApple - Confidence 0.94003654\\nBackpack - Confidence 0.7481894\\nBackpack - Confidence 0.7481894\\nBackpack - Confidence 0.7481894\\nLuggage & bags - Confidence 0.70691586\\nLuggage & bags - Confidence 0.70691586\\nLuggage & bags - Confidence 0.70691586\\nContainer - Confidence 0.654727\\nContainer - Confidence 0.654727\\nContainer - Confidence 0.654727\\nLuggage & bags - Confidence 0.5871518\\nLuggage & bags - Confidence 0.5871518\\nLuggage & bags - Confidence 0.5871518'),\n  (AgentAction(tool='edenai_explicit_content_detection_text', tool_input='Apple, Backpack, Luggage & bags, Container', log=' I need to check if any of the objects are harmful.\\nAction: edenai_explicit_content_detection_text\\nAction Input: Apple, Backpack, Luggage & bags, Container'),\n   'nsfw_likelihood: 2\\n\"sexually explicit\": 1\\n\"sexually suggestive\": 2\\n\"offensive\": 1\\nnsfw_likelihood: 1\\n\"sexual\": 1\\n\"hate\": 1\\n\"harassment\": 1\\n\"self-harm\": 1\\n\"sexual/minors\": 1\\n\"hate/threatening\": 1\\n\"violence/graphic\": 1\\n\"self-harm/intent\": 1\\n\"self-harm/instructions\": 1\\n\"harassment/threatening\": 1\\n\"violence\": 1'),\n  (AgentAction(tool='edenai_text_to_speech', tool_input=\"'this item is safe'\", log=\" None of the objects are harmful.\\nAction: edenai_text_to_speech\\nAction Input: 'this item is safe'\"),\n   'https://d14uq1pz7dzsdq.cloudfront.net/0546db8b-528e-4b63-9a69-d14d43ad1566_.mp3?Expires=1693316753&Signature=N0KZeK9I-1s7wTgiQOAwH7LFlltwyonSJcDnkdnr8JIJmbgSw6fo6RTxWl~VvD2Hg6igJqxtJFFWyrBmmx-f9wWLw3bZSnuMxkhTRqLX9aUA9N-vPJGiRZV5BFredaOm8pwfo8TcXhVjw08iSxv8GSuyZEIwZkiq4PzdiyVTnKKji6eytV0CrnHrTs~eXZkSnOdD2Fu0ECaKvFHlsF4IDLI8efRvituSk0X3ygdec4HQojl5vmBXJzi1TuhKWOX8UxeQle8pdjjqUPSJ9thTHpucdPy6UbhZOH0C9rbtLrCfvK5rzrT4D~gKy9woICzG34tKRxNxHYVVUPqx2BiInA__&Key-Pair-Id=K1F55BTI9AHGIK')]}\n```\n\n## Example with OCR images\u200b\n\n```python\ninput_ = \"\"\"i have this url of an id: \"https://www.citizencard.com/images/citizencard-uk-id-card-2023.jpg\"\ni want to extract the information in it.\ncreate a text welcoming the person by his name and make it into speech .\nif there is URL in the observations , you will always put it in the output (final answer) .\n\"\"\"\nresult = agent_chain(input_)\n```\n\n```output", "type": "Document"}, {"metadata": {"language": "en", "description": "Transwarp Hippo is an enterprise-level cloud-native distributed vector database that supports storage, retrieval, and management of massive vector-based datasets. It efficiently solves problems such as vector similarity search and high-density vector clustering. Hippo features high availability, high performance, and easy scalability. It has many functions, such as multiple vector search indexes, data partitioning and sharding, data persistence, incremental data ingestion, vector scalar field filtering, and mixed queries. It can effectively meet the high real-time search demands of enterprises for massive vector data", "changefreq": "weekly", "source": "https://python.langchain.com/docs/integrations/vectorstores/hippo/", "title": "Hippo | \ud83e\udd9c\ufe0f\ud83d\udd17 LangChain", "content_type": null, "lastmod": null, "priority": "0.5", "loc": "https://python.langchain.com/docs/integrations/vectorstores/hippo/", "uuid": "a3c305b4-cd08-56c7-bccd-612617eadbdb"}, "page_content": "- [Storing the Document](#storing-the-document)\n\n- [Conducting Knowledge-based Question and Answer](#conducting-knowledge-based-question-and-answer)\n\n- [Acquiring Related Knowledge Based on the Question\uff1a](#acquiring-related-knowledge-based-on-the-question)\n\n- [Constructing a Prompt Template](#constructing-a-prompt-template)\n\n- [Waiting for the Large Language Model to Generate an Answer](#waiting-for-the-large-language-model-to-generate-an-answer)\n\n- [Related](#related)", "type": "Document"}, {"metadata": {"language": "en", "description": "PebbloRetrievalQA is a Retrieval chain with Identity & Semantic Enforcement for question-answering", "changefreq": "weekly", "source": "https://python.langchain.com/docs/integrations/providers/pebblo/pebblo_retrieval_qa/", "title": "Identity-enabled RAG using PebbloRetrievalQA | \ud83e\udd9c\ufe0f\ud83d\udd17 LangChain", "content_type": null, "lastmod": null, "priority": "0.5", "loc": "https://python.langchain.com/docs/integrations/providers/pebblo/pebblo_retrieval_qa/", "uuid": "bdd2d371-9dd6-5cac-8806-1a2d4df78db5"}, "page_content": "- [Retrieval with Identity Enforcement](#retrieval-with-identity-enforcement)- [1. Questions by Authorized User](#1-questions-by-authorized-user)\n\n- [2. Questions by Unauthorized User](#2-questions-by-unauthorized-user)\n\n- [3. Using PromptTemplate to provide additional instructions](#3-using-prompttemplate-to-provide-additional-instructions)\n\n- [Retrieval with Semantic Enforcement](#retrieval-with-semantic-enforcement)- [1. Without semantic enforcement](#1-without-semantic-enforcement)\n\n- [2. Deny financial-report topic](#2-deny-financial-report-topic)\n\n- [3. Deny us-bank-account-number entity](#3-deny-us-bank-account-number-entity)", "type": "Document"}, {"metadata": {"language": "en", "description": "Retrieval is a common technique chatbots use to augment their responses with data outside a chat model's training data. This section will cover how to implement retrieval in the context of chatbots, but it's worth noting that retrieval is a very subtle and deep topic - we encourage you to explore other parts of the documentation that go into greater depth!", "changefreq": "weekly", "source": "https://python.langchain.com/docs/how_to/chatbots_retrieval/", "title": "How to add retrieval to chatbots | \ud83e\udd9c\ufe0f\ud83d\udd17 LangChain", "content_type": null, "lastmod": null, "priority": "0.5", "loc": "https://python.langchain.com/docs/how_to/chatbots_retrieval/", "uuid": "faea8c1d-2464-555e-b5bb-761ddfcaee53"}, "page_content": "{'answer': ''}\n{'answer': 'Lang'}\n{'answer': 'Smith'}\n{'answer': ' simpl'}\n{'answer': 'ifies'}\n{'answer': ' the'}\n{'answer': ' initial'}\n{'answer': ' setup'}\n{'answer': ' for'}\n{'answer': ' building'}\n{'answer': ' reliable'}\n{'answer': ' L'}\n{'answer': 'LM'}\n{'answer': ' applications'}\n{'answer': '.'}\n{'answer': ' It'}\n{'answer': ' provides'}\n{'answer': ' features'}\n{'answer': ' for'}\n{'answer': ' manually'}\n{'answer': ' reviewing'}\n{'answer': ' and'}\n{'answer': ' annot'}\n{'answer': 'ating'}\n{'answer': ' runs'}\n{'answer': ' through'}\n{'answer': ' annotation'}\n{'answer': ' queues'}\n{'answer': ','}\n{'answer': ' allowing'}\n{'answer': ' you'}\n{'answer': ' to'}\n{'answer': ' select'}\n{'answer': ' runs'}\n{'answer': ' based'}\n{'answer': ' on'}\n{'answer': ' criteria'}\n{'answer': ' like'}\n{'answer': ' model'}\n{'answer': ' type'}\n{'answer': ' or'}\n{'answer': ' automatic'}\n{'answer': ' evaluation'}\n{'answer': ' scores'}\n{'answer': ','}\n{'answer': ' and'}\n{'answer': ' queue'}\n{'answer': ' them'}\n{'answer': ' up'}\n{'answer': ' for'}\n{'answer': ' human'}\n{'answer': ' review'}\n{'answer': '.'}\n{'answer': ' As'}\n{'answer': ' a'}\n{'answer': ' reviewer'}\n{'answer': ','}\n{'answer': ' you'}\n{'answer': ' can'}\n{'answer': ' quickly'}\n{'answer': ' step'}\n{'answer': ' through'}\n{'answer': ' the'}\n{'answer': ' runs'}\n{'answer': ','}\n{'answer': ' view'}\n{'answer': ' the'}\n{'answer': ' input'}\n{'answer': ','}\n{'answer': ' output'}\n{'answer': ','}\n{'answer': ' and'}\n{'answer': ' any'}\n{'answer': ' existing'}\n{'answer': ' tags'}\n{'answer': ' before'}\n{'answer': ' adding'}\n{'answer': ' your'}\n{'answer': ' own'}\n{'answer': ' feedback'}\n{'answer': '.'}\n{'answer': ' This'}\n{'answer': ' can'}\n{'answer': ' be'}\n{'answer': ' particularly'}\n{'answer': ' useful'}\n{'answer': ' for'}\n{'answer': ' assessing'}\n{'answer': ' subjective'}\n{'answer': ' qualities'}\n{'answer': ' that'}\n{'answer': ' automatic'}\n{'answer': ' evalu'}\n{'answer': 'ators'}\n{'answer': ' struggle'}\n{'answer': ' with'}\n{'answer': '.'}\n{'answer': ''}\n```", "type": "Document"}, {"metadata": {"description": "PebbloRetrievalQA is a Retrieval chain with Identity & Semantic Enforcement for question-answering", "language": "en", "changefreq": "weekly", "source": "https://python.langchain.com/docs/integrations/providers/pebblo/pebblo_retrieval_qa/", "title": "Identity-enabled RAG using PebbloRetrievalQA | \ud83e\udd9c\ufe0f\ud83d\udd17 LangChain", "content_type": null, "lastmod": null, "priority": "0.5", "loc": "https://python.langchain.com/docs/integrations/providers/pebblo/pebblo_retrieval_qa/", "uuid": "9483e59b-08e4-5369-98dd-4706cd919703"}, "page_content": "def ask(\n    question: str,\n    topics_to_deny: Optional[List[str]] = None,\n    entities_to_deny: Optional[List[str]] = None,\n):\n    \"\"\"\n    Ask a question to the PebbloRetrievalQA chain\n    \"\"\"\n    semantic_context = dict()\n    if topics_to_deny:\n        semantic_context[\"pebblo_semantic_topics\"] = {\"deny\": topics_to_deny}\n    if entities_to_deny:\n        semantic_context[\"pebblo_semantic_entities\"] = {\"deny\": entities_to_deny}\n\n    semantic_context_obj = (\n        SemanticContext(**semantic_context) if semantic_context else None\n    )\n    chain_input_obj = ChainInput(query=question, semantic_context=semantic_context_obj)\n    return qa_chain.invoke(chain_input_obj.dict())\n```\n\n**API Reference:**[PebbloRetrievalQA](https://python.langchain.com/api_reference/community/chains/langchain_community.chains.pebblo_retrieval.base.PebbloRetrievalQA.html) | [ChainInput](https://python.langchain.com/api_reference/community/chains/langchain_community.chains.pebblo_retrieval.models.ChainInput.html) | [SemanticContext](https://python.langchain.com/api_reference/community/chains/langchain_community.chains.pebblo_retrieval.models.SemanticContext.html)\n### 1. Without semantic enforcement\u200b\n\nSince no semantic enforcement is applied, the system should return the answer without excluding any context due to the semantic labels associated with the context.\n\n```python\ntopic_to_deny = []\nentities_to_deny = []\nquestion = \"Share the financial performance of ACME Corp for the year 2020\"\nresp = ask(question, topics_to_deny=topic_to_deny, entities_to_deny=entities_to_deny)\nprint(\n    f\"Topics to deny: {topic_to_deny}\\nEntities to deny: {entities_to_deny}\\n\"\n    f\"Question: {question}\\nAnswer: {resp['result']}\"\n)\n```\n\n```output\nTopics to deny: []\nEntities to deny: []\nQuestion: Share the financial performance of ACME Corp for the year 2020\nAnswer: \nRevenue for ACME Corp increased by 15% to $50 million in 2020, with a net profit of $12 million and a strong asset base of $80 million. The company also maintained a conservative debt-to-equity ratio of 0.5.\n```\n\n### 2. Deny financial-report topic\u200b\n\nData has been ingested with the topics: `[\"financial-report\"]`.\nTherefore, an app that denies the `financial-report` topic should not receive an answer.\n\n```python\ntopic_to_deny = [\"financial-report\"]\nentities_to_deny = []\nquestion = \"Share the financial performance of ACME Corp for the year 2020\"\nresp = ask(question, topics_to_deny=topic_to_deny, entities_to_deny=entities_to_deny)\nprint(\n    f\"Topics to deny: {topic_to_deny}\\nEntities to deny: {entities_to_deny}\\n\"\n    f\"Question: {question}\\nAnswer: {resp['result']}\"\n)\n```\n\n```output\nTopics to deny: ['financial-report']\nEntities to deny: []\nQuestion: Share the financial performance of ACME Corp for the year 2020\nAnswer: \n\nUnfortunately, I do not have access to the financial performance of ACME Corp for the year 2020.\n```\n\n### 3. Deny us-bank-account-number entity\u200b\n\nSince the entity `us-bank-account-number` is denied, the system should not return the answer.\n\n```python\ntopic_to_deny = []\nentities_to_deny = [\"us-bank-account-number\"]\nquestion = \"Share the financial performance of ACME Corp for the year 2020\"\nresp = ask(question, topics_to_deny=topic_to_deny, entities_to_deny=entities_to_deny)\nprint(\n    f\"Topics to deny: {topic_to_deny}\\nEntities to deny: {entities_to_deny}\\n\"\n    f\"Question: {question}\\nAnswer: {resp['result']}\"\n)\n```\n\n```output\nTopics to deny: []\nEntities to deny: ['us-bank-account-number']\nQuestion: Share the financial performance of ACME Corp for the year 2020\nAnswer:  I don't have information about ACME Corp's financial performance for 2020.\n```\n\n#### Was this page helpful?\n\n- [Steps:](#steps)\n\n- [Setup](#setup)- [Dependencies](#dependencies)\n\n- [Identity-aware Data Ingestion](#identity-aware-data-ingestion)\n\n- [Retrieval with Identity Enforcement](#retrieval-with-identity-enforcement)- [1. Questions by Authorized User](#1-questions-by-authorized-user)", "type": "Document"}, {"metadata": {"description": "LLMs can summarize and otherwise distill desired information from text, including large volumes of text. In many cases, especially when the amount of text is large compared to the size of the model's context window, it can be helpful (or necessary) to break up the summarization task into smaller components.", "language": "en", "changefreq": "weekly", "source": "https://python.langchain.com/docs/how_to/summarize_map_reduce/", "title": "How to summarize text through parallelization | \ud83e\udd9c\ufe0f\ud83d\udd17 LangChain", "lastmod": null, "content_type": null, "priority": "0.5", "loc": "https://python.langchain.com/docs/how_to/summarize_map_reduce/", "uuid": "fc14a57d-1f4d-506f-b648-9835640f017c"}, "page_content": "See also [this tutorial](/docs/tutorials/summarization/) for more detail on summarization.\n\n#### Was this page helpful?\n\n- [Load chat model](#load-chat-model)\n\n- [Load documents](#load-documents)\n\n- [Create graph](#create-graph)- [Map step](#map-step)\n\n- [Reduce step](#reduce-step)\n\n- [Orchestration via LangGraph](#orchestration-via-langgraph)\n\n- [Invoke graph](#invoke-graph)\n\n- [Next steps](#next-steps)", "type": "Document"}, {"metadata": {"language": "en", "description": "This tutorial demonstrates text summarization using built-in chains and LangGraph.", "changefreq": "weekly", "source": "https://python.langchain.com/docs/tutorials/summarization/", "title": "Summarize Text | \ud83e\udd9c\ufe0f\ud83d\udd17 LangChain", "content_type": null, "lastmod": null, "priority": "0.5", "loc": "https://python.langchain.com/docs/tutorials/summarization/", "uuid": "bbeae299-a2fb-5af1-ad12-bf62bdcbba80"}, "page_content": "Summarize Text | \ud83e\udd9c\ufe0f\ud83d\udd17 LangChain\n\n[Skip to main content](#__docusaurus_skipToContent_fallback)# Summarize Text\n\ninfoThis tutorial demonstrates text summarization using built-in chains and [LangGraph](https://langchain-ai.github.io/langgraph/).\n\nA [previous version](https://python.langchain.com/v0.1/docs/use_cases/summarization/) of this page showcased the legacy chains [StuffDocumentsChain](/docs/versions/migrating_chains/stuff_docs_chain/), [MapReduceDocumentsChain](/docs/versions/migrating_chains/map_reduce_chain/), and [RefineDocumentsChain](https://python.langchain.com/docs/versions/migrating_chains/refine_docs_chain/). See [here](/docs/versions/migrating_chains/) for information on using those abstractions and a comparison with the methods demonstrated in this tutorial.\n\nSuppose you have a set of documents (PDFs, Notion pages, customer questions, etc.) and you want to summarize the content.\n\nLLMs are a great tool for this given their proficiency in understanding and synthesizing text.\n\nIn the context of [retrieval-augmented generation](/docs/tutorials/rag/), summarizing text can help distill the information in a large number of retrieved documents to provide context for a LLM.\n\nIn this walkthrough we'll go over how to summarize content from multiple documents using LLMs.\n\n![Image description](/assets/images/summarization_use_case_1-874f7b2c94f64216f1f967fb5aca7bc1.png)\n\n## Concepts\u200b\n\nConcepts we will cover are:\n\n- \nUsing [language models](/docs/concepts/chat_models/).\n\n- \nUsing [document loaders](/docs/concepts/document_loaders/), specifically the [WebBaseLoader](https://python.langchain.com/api_reference/community/document_loaders/langchain_community.document_loaders.web_base.WebBaseLoader.html) to load content from an HTML webpage.\n\n- \nTwo ways to summarize or otherwise combine documents.\n\n1. [Stuff](/docs/tutorials/summarization/#stuff), which simply concatenates documents into a prompt;\n\n2. [Map-reduce](/docs/tutorials/summarization/#map-reduce), for larger sets of documents. This splits documents into batches, summarizes those, and then summarizes the summaries.\n\nShorter, targeted guides on these strategies and others, including [iterative refinement](/docs/how_to/summarize_refine/), can be found in the [how-to guides](/docs/how_to/#summarization).\n\n## Setup\u200b\n\n### Jupyter Notebook\u200b\n\nThis guide (and most of the other guides in the documentation) uses [Jupyter notebooks](https://jupyter.org/) and assumes the reader is as well. Jupyter notebooks are perfect for learning how to work with LLM systems because oftentimes things can go wrong (unexpected output, API down, etc) and going through guides in an interactive environment is a great way to better understand them.\n\nThis and other tutorials are perhaps most conveniently run in a Jupyter notebook. See [here](https://jupyter.org/install) for instructions on how to install.\n\n### Installation\u200b\n\nTo install LangChain run:\n\n \nPip\n```bash\npip install langchain\n```\n\nConda\n```bash\nconda install langchain -c conda-forge\n```\n\nFor more details, see our [Installation guide](/docs/how_to/installation/).\n\n### LangSmith\u200b\n\nMany of the applications you build with LangChain will contain multiple steps with multiple invocations of LLM calls.\nAs these applications get more and more complex, it becomes crucial to be able to inspect what exactly is going on inside your chain or agent.\nThe best way to do this is with [LangSmith](https://smith.langchain.com).\n\nAfter you sign up at the link above, make sure to set your environment variables to start logging traces:\n\n```shell\nexport LANGCHAIN_TRACING_V2=\"true\"\nexport LANGCHAIN_API_KEY=\"...\"\n```\n\nOr, if in a notebook, you can set them with:\n\n```python\nimport getpass\nimport os\n\nos.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\nos.environ[\"LANGCHAIN_API_KEY\"] = getpass.getpass()\n```\n\n## Overview\u200b\n\nA central question for building a summarizer is how to pass your documents into the LLM's context window. Two common approaches for this are:", "type": "Document"}, {"metadata": {"description": "Vectara is the trusted AI Assistant and Agent platform which focuses on enterprise readiness for mission-critical applications.", "language": "en", "changefreq": "weekly", "source": "https://python.langchain.com/docs/integrations/vectorstores/vectara/", "title": "Vectara | \ud83e\udd9c\ufe0f\ud83d\udd17 LangChain", "content_type": null, "lastmod": null, "priority": "0.5", "loc": "https://python.langchain.com/docs/integrations/vectorstores/vectara/", "uuid": "31d78e5d-5fc7-5a56-baf6-6b8ead6ad6fb"}, "page_content": "```python\nconfig.summary_config.is_enabled = False\nconfig.k = 3\nretriever = vectara.as_retriever(config=config)\nretriever.invoke(query_str)\n```\n\n```output\n[Document(page_content='He thought the West and NATO wouldn\u2019t respond. And he thought he could divide us at home. We were ready.  Here is what we did. We prepared extensively and carefully. We spent months building a coalition of other freedom-loving nations from Europe and the Americas to Asia and Africa to confront Putin.', metadata={'lang': 'eng', 'section': '1', 'offset': '2160', 'len': '36', 'X-TIKA:Parsed-By': 'org.apache.tika.parser.csv.TextAndCSVParser', 'Content-Encoding': 'UTF-8', 'Content-Type': 'text/plain; charset=UTF-8', 'source': 'vectara'}),\n Document(page_content='When they came home, many of the world\u2019s fittest and best trained warriors were never the same. Dizziness. \\n\\nA cancer that would put them in a flag-draped coffin. I know. \\n\\nOne of those soldiers was my son Major Beau Biden. We don\u2019t know for sure if a burn pit was the cause of his brain cancer, or the diseases of so many of our troops. But I\u2019m committed to finding out everything we can.', metadata={'lang': 'eng', 'section': '1', 'offset': '34652', 'len': '60', 'X-TIKA:Parsed-By': 'org.apache.tika.parser.csv.TextAndCSVParser', 'Content-Encoding': 'UTF-8', 'Content-Type': 'text/plain; charset=UTF-8', 'source': 'vectara'}),\n Document(page_content='But cancer from prolonged exposure to burn pits ravaged Heath\u2019s lungs and body. Danielle says Heath was a fighter to the very end. He didn\u2019t know how to stop fighting, and neither did she. Through her pain she found purpose to demand we do better. Tonight, Danielle\u2014we are.', metadata={'lang': 'eng', 'section': '1', 'offset': '35442', 'len': '57', 'X-TIKA:Parsed-By': 'org.apache.tika.parser.csv.TextAndCSVParser', 'Content-Encoding': 'UTF-8', 'Content-Type': 'text/plain; charset=UTF-8', 'source': 'vectara'})]\n```\n\nFor backwards compatibility, you can also enable summarization with a retriever, in which case the summary is added as an additional Document object:\n\n```python\nconfig.summary_config.is_enabled = True\nconfig.k = 3\nretriever = vectara.as_retriever(config=config)\nretriever.invoke(query_str)\n```", "type": "Document"}], "steps": []}
{"generations": [{"text": "", "generation_info": {"finish_reason": "stop", "model_name": "gpt-4o-mini-2024-07-18", "system_fingerprint": "fp_0705bf87c0"}, "type": "ChatGeneration", "message": {"lc": 1, "type": "constructor", "id": ["langchain", "schema", "messages", "AIMessage"], "kwargs": {"content": "", "additional_kwargs": {"tool_calls": [{"index": 0, "id": "call_Z96K6195pJLdrXbUvsuWdSL0", "function": {"arguments": "{\"queries\":[\"how to extract information from a text\",\"best practices for answering specific questions\",\"techniques for summarizing extracted information\"]}", "name": "Response"}, "type": "function"}]}, "response_metadata": {"finish_reason": "stop", "model_name": "gpt-4o-mini-2024-07-18", "system_fingerprint": "fp_0705bf87c0"}, "type": "ai", "id": "run-77373f7d-5bfb-49ba-8e66-e91eaef05286", "tool_calls": [{"name": "Response", "args": {"queries": ["how to extract information from a text", "best practices for answering specific questions", "techniques for summarizing extracted information"]}, "id": "call_Z96K6195pJLdrXbUvsuWdSL0", "type": "tool_call"}], "invalid_tool_calls": []}}}], "llm_output": null, "run": null, "type": "LLMResult"}
{"messages": [{"content": "I'm unable to access external URLs or open documents directly. However, you can download the PDF from the provided link and then use LangChain to load it into your environment. Once you have the PDF loaded, you can ask questions based on its content.\n\nIf you need help with loading the PDF using LangChain, please let me know!", "additional_kwargs": {}, "response_metadata": {"finish_reason": "stop", "model_name": "gpt-4o-mini-2024-07-18", "system_fingerprint": "fp_0705bf87c0"}, "type": "ai", "id": "run-09e45f81-1165-41b1-82bd-faef49c1aa71", "example": false, "tool_calls": [], "invalid_tool_calls": []}], "answer": "I'm unable to access external URLs or open documents directly. However, you can download the PDF from the provided link and then use LangChain to load it into your environment. Once you have the PDF loaded, you can ask questions based on its content.\n\nIf you need help with loading the PDF using LangChain, please let me know!"}
{"generations": [{"text": "I'm unable to access external URLs or open documents directly. However, you can download the PDF from the provided link and then use LangChain to load it into your environment. Once you have the PDF loaded, you can ask questions based on its content.\n\nIf you need help with loading the PDF using LangChain, please let me know!", "generation_info": {"finish_reason": "stop", "model_name": "gpt-4o-mini-2024-07-18", "system_fingerprint": "fp_0705bf87c0"}, "type": "ChatGeneration", "message": {"lc": 1, "type": "constructor", "id": ["langchain", "schema", "messages", "AIMessage"], "kwargs": {"content": "I'm unable to access external URLs or open documents directly. However, you can download the PDF from the provided link and then use LangChain to load it into your environment. Once you have the PDF loaded, you can ask questions based on its content.\n\nIf you need help with loading the PDF using LangChain, please let me know!", "response_metadata": {"finish_reason": "stop", "model_name": "gpt-4o-mini-2024-07-18", "system_fingerprint": "fp_0705bf87c0"}, "type": "ai", "id": "run-09e45f81-1165-41b1-82bd-faef49c1aa71", "tool_calls": [], "invalid_tool_calls": []}}}], "llm_output": null, "run": null, "type": "LLMResult"}
