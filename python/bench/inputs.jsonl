{"messages": [{"role": "user", "content": "https://www.cambridge.org/core/services/aop-cambridge-core/content/view/0D4357A9A6150E706CC261B86BA47733/S0008423923000793a.pdf/ascent_of_the_canadian_judicial_council_bill_c9_and_the_move_towards_judicialized_governance.pdf  can you open this to answer questions for me "}]}
{"messages": [{"role": "user", "content": "https://www.cambridge.org/core/services/aop-cambridge-core/content/view/0D4357A9A6150E706CC261B86BA47733/S0008423923000793a.pdf/ascent_of_the_canadian_judicial_council_bill_c9_and_the_move_towards_judicialized_governance.pdf  can you open this to answer questions for me "}]}
{"input": {"messages": [{"content": "how do i upload a pdf", "additional_kwargs": {}, "response_metadata": {}, "type": "human", "id": "acdae6e0-4fa7-459f-8906-67b9372aba8f", "example": false}, {"content": "To upload a PDF using LangChain, you can utilize the `PDFMinerLoader` or `PDFPlumberLoader`. Here\u2019s a brief overview of how to do it with each loader:\n\n### Using PDFMinerLoader\n1. **Install the required package**:\n   ```bash\n   pip install langchain_community\n   ```\n\n2. **Load the PDF**:\n   ```python\n   from langchain_community.document_loaders import PDFMinerLoader\n\n   file_path = \"./path_to_your_pdf/document.pdf\"\n   loader = PDFMinerLoader(file_path)\n   docs = loader.load()\n   ```\n\n### Using PDFPlumberLoader\n1. **Install the required package**:\n   ```bash\n   pip install langchain_community\n   ```\n\n2. **Load the PDF**:\n   ```python\n   from langchain_community.document_loaders import PDFPlumberLoader\n\n   loader = PDFPlumberLoader(\"./path_to_your_pdf/document.pdf\")\n   docs = loader.load()\n   ```\n\n### Notes\n- Both loaders will return a list of documents, where each document corresponds to a page in the PDF.\n- No special credentials are needed to use these loaders.\n\nFor more detailed information, you can refer to the API references for [PDFMinerLoader](https://python.langchain.com/api_reference/community/document_loaders/langchain_community.document_loaders.pdf.PDFMinerLoader.html) and [PDFPlumberLoader](https://python.langchain.com/api_reference/community/document_loaders/langchain_community.document_loaders.pdf.PDFPlumberLoader.html).", "additional_kwargs": {}, "response_metadata": {"finish_reason": "stop", "model_name": "gpt-4o-mini-2024-07-18", "system_fingerprint": "fp_0705bf87c0"}, "type": "ai", "id": "run-646bc662-d299-4ff8-9700-03482e843756", "example": false, "tool_calls": [], "invalid_tool_calls": []}, {"content": "https://www.cambridge.org/core/services/aop-cambridge-core/content/view/0D4357A9A6150E706CC261B86BA47733/S0008423923000793a.pdf/ascent_of_the_canadian_judicial_council_bill_c9_and_the_move_towards_judicialized_governance.pdf  can you open this to answer questions for me ", "additional_kwargs": {}, "response_metadata": {}, "type": "human", "id": "97919fe7-0599-486c-90d0-7355c6c587d1", "example": false}], "router": {"type": "general", "logic": ""}, "steps": [], "documents": [{"metadata": {"description": "Recall, understand, and extract data from chat histories. Power personalized AI experiences.", "language": "en", "changefreq": "weekly", "source": "https://python.langchain.com/docs/integrations/vectorstores/zep_cloud/", "title": "Zep Cloud | \ud83e\udd9c\ufe0f\ud83d\udd17 LangChain", "lastmod": null, "content_type": null, "priority": "0.5", "loc": "https://python.langchain.com/docs/integrations/vectorstores/zep_cloud/", "uuid": "5954eaa7-fe16-5409-93bf-b07c9431810d"}, "page_content": "```output\nAdding documents\ngenerated documents 1290", "type": "Document"}, {"metadata": {"description": "Overview", "language": "en", "changefreq": "weekly", "source": "https://python.langchain.com/docs/integrations/document_loaders/pdfminer/", "title": "PDFMiner | \ud83e\udd9c\ufe0f\ud83d\udd17 LangChain", "content_type": null, "lastmod": null, "priority": "0.5", "loc": "https://python.langchain.com/docs/integrations/document_loaders/pdfminer/", "uuid": "deb16b77-1241-5e26-8577-e73eb5fc030b"}, "page_content": "## API reference\u200b\n\nFor detailed documentation of all PDFMinerLoader features and configurations head to the API reference: [https://python.langchain.com/api_reference/community/document_loaders/langchain_community.document_loaders.pdf.PDFMinerLoader.html](https://python.langchain.com/api_reference/community/document_loaders/langchain_community.document_loaders.pdf.PDFMinerLoader.html)\n\n## Related\u200b\n\n- Document loader [conceptual guide](/docs/concepts/document_loaders/)\n\n- Document loader [how-to guides](/docs/how_to/#document-loaders)\n\n#### Was this page helpful?\n\n- [Overview](#overview)- [Integration details](#integration-details)\n\n- [Loader features](#loader-features)\n\n- [Setup](#setup)- [Credentials](#credentials)\n\n- [Installation](#installation)\n\n- [Initialization](#initialization)\n\n- [Load](#load)\n\n- [Lazy Load](#lazy-load)\n\n- [Using PDFMiner to generate HTML text](#using-pdfminer-to-generate-html-text)\n\n- [API reference](#api-reference)\n\n- [Related](#related)", "type": "Document"}, {"metadata": {"description": "Note: This connector-specific loader is deprecated. Please use AirbyteLoader instead.", "language": "en", "changefreq": "weekly", "source": "https://python.langchain.com/docs/integrations/document_loaders/airbyte_gong/", "title": "Airbyte Gong (Deprecated) | \ud83e\udd9c\ufe0f\ud83d\udd17 LangChain", "content_type": null, "lastmod": null, "priority": "0.5", "loc": "https://python.langchain.com/docs/integrations/document_loaders/airbyte_gong/", "uuid": "303552cf-c14a-5615-b73b-6072a5ac090b"}, "page_content": "- Document loader [how-to guides](/docs/how_to/#document-loaders)\n\n#### Was this page helpful?\n\n- [Installation](#installation)\n\n- [Example](#example)\n\n- [Incremental loads](#incremental-loads)\n\n- [Related](#related)", "type": "Document"}, {"metadata": {"description": "Note: This connector-specific loader is deprecated. Please use AirbyteLoader instead.", "language": "en", "changefreq": "weekly", "source": "https://python.langchain.com/docs/integrations/document_loaders/airbyte_stripe/", "title": "Airbyte Stripe (Deprecated) | \ud83e\udd9c\ufe0f\ud83d\udd17 LangChain", "content_type": null, "lastmod": null, "priority": "0.5", "loc": "https://python.langchain.com/docs/integrations/document_loaders/airbyte_stripe/", "uuid": "18c586c3-45ab-59dd-964f-86a40222db59"}, "page_content": "- Document loader [how-to guides](/docs/how_to/#document-loaders)\n\n#### Was this page helpful?\n\n- [Installation](#installation)\n\n- [Example](#example)\n\n- [Incremental loads](#incremental-loads)\n\n- [Related](#related)", "type": "Document"}, {"metadata": {"language": "en", "description": "All functionality related to Microsoft Azure and other Microsoft products.", "changefreq": "weekly", "source": "https://python.langchain.com/docs/integrations/providers/microsoft/", "title": "Microsoft | \ud83e\udd9c\ufe0f\ud83d\udd17 LangChain", "content_type": null, "lastmod": null, "priority": "0.5", "loc": "https://python.langchain.com/docs/integrations/providers/microsoft/", "uuid": "2ecd20dc-6c8c-5096-b731-069d039952eb"}, "page_content": "Document Intelligence supports `PDF`, `JPEG/JPG`, `PNG`, `BMP`, `TIFF`, `HEIF`, `DOCX`, `XLSX`, `PPTX` and `HTML`.\n\nFirst, you need to install a python package.\n\n```bash\npip install azure-ai-documentintelligence\n```\n\nSee a [usage example](/docs/integrations/document_loaders/azure_document_intelligence/).\n\n```python\nfrom langchain.document_loaders import AzureAIDocumentIntelligenceLoader\n```\n\n### Azure Blob Storage\u200b\n\n[Azure Blob Storage](https://learn.microsoft.com/en-us/azure/storage/blobs/storage-blobs-introduction) is Microsoft's object storage solution for the cloud. Blob Storage is optimized for storing massive amounts of unstructured data. Unstructured data is data that doesn't adhere to a particular data model or definition, such as text or binary data.\n\n[Azure Files](https://learn.microsoft.com/en-us/azure/storage/files/storage-files-introduction) offers fully managed\nfile shares in the cloud that are accessible via the industry standard Server Message Block (`SMB`) protocol,\nNetwork File System (`NFS`) protocol, and `Azure Files REST API`. `Azure Files` are based on the `Azure Blob Storage`.\n\n`Azure Blob Storage` is designed for:\n\n- Serving images or documents directly to a browser.\n\n- Storing files for distributed access.\n\n- Streaming video and audio.\n\n- Writing to log files.\n\n- Storing data for backup and restore, disaster recovery, and archiving.\n\n- Storing data for analysis by an on-premises or Azure-hosted service.\n\n```bash\npip install azure-storage-blob\n```\n\nSee a [usage example for the Azure Blob Storage](/docs/integrations/document_loaders/azure_blob_storage_container/).\n\n```python\nfrom langchain_community.document_loaders import AzureBlobStorageContainerLoader\n```\n\n**API Reference:**[AzureBlobStorageContainerLoader](https://python.langchain.com/api_reference/community/document_loaders/langchain_community.document_loaders.azure_blob_storage_container.AzureBlobStorageContainerLoader.html)\nSee a [usage example for the Azure Files](/docs/integrations/document_loaders/azure_blob_storage_file/).\n\n```python\nfrom langchain_community.document_loaders import AzureBlobStorageFileLoader\n```\n\n**API Reference:**[AzureBlobStorageFileLoader](https://python.langchain.com/api_reference/community/document_loaders/langchain_community.document_loaders.azure_blob_storage_file.AzureBlobStorageFileLoader.html)\n### Microsoft OneDrive\u200b\n\n[Microsoft OneDrive](https://en.wikipedia.org/wiki/OneDrive) (formerly `SkyDrive`) is a file-hosting service operated by Microsoft.\n\nFirst, you need to install a python package.\n\n```bash\npip install o365\n```\n\nSee a [usage example](/docs/integrations/document_loaders/microsoft_onedrive/).\n\n```python\nfrom langchain_community.document_loaders import OneDriveLoader\n```\n\n**API Reference:**[OneDriveLoader](https://python.langchain.com/api_reference/community/document_loaders/langchain_community.document_loaders.onedrive.OneDriveLoader.html)\n### Microsoft OneDrive File\u200b\n\n[Microsoft OneDrive](https://en.wikipedia.org/wiki/OneDrive) (formerly `SkyDrive`) is a file-hosting service operated by Microsoft.\n\nFirst, you need to install a python package.\n\n```bash\npip install o365\n```\n\n```python\nfrom langchain_community.document_loaders import OneDriveFileLoader\n```\n\n**API Reference:**[OneDriveFileLoader](https://python.langchain.com/api_reference/community/document_loaders/langchain_community.document_loaders.onedrive_file.OneDriveFileLoader.html)\n### Microsoft Word\u200b\n\n[Microsoft Word](https://www.microsoft.com/en-us/microsoft-365/word) is a word processor developed by Microsoft.\n\nSee a [usage example](/docs/integrations/document_loaders/microsoft_word/).\n\n```python\nfrom langchain_community.document_loaders import UnstructuredWordDocumentLoader\n```\n\n**API Reference:**[UnstructuredWordDocumentLoader](https://python.langchain.com/api_reference/community/document_loaders/langchain_community.document_loaders.word_document.UnstructuredWordDocumentLoader.html)\n### Microsoft Excel\u200b", "type": "Document"}, {"metadata": {"description": "Like PyMuPDF, the output Documents contain detailed metadata about the PDF and its pages, and returns one document per page.", "language": "en", "changefreq": "weekly", "source": "https://python.langchain.com/docs/integrations/document_loaders/pdfplumber/", "title": "PDFPlumber | \ud83e\udd9c\ufe0f\ud83d\udd17 LangChain", "content_type": null, "lastmod": null, "priority": "0.5", "loc": "https://python.langchain.com/docs/integrations/document_loaders/pdfplumber/", "uuid": "5778737e-a970-5fb6-a9bd-14e76d3e7aa7"}, "page_content": "PDFPlumber | \ud83e\udd9c\ufe0f\ud83d\udd17 LangChain\n\n[Skip to main content](#__docusaurus_skipToContent_fallback)# PDFPlumber\n\nLike PyMuPDF, the output Documents contain detailed metadata about the PDF and its pages, and returns one document per page.\n\n## Overview\u200b\n\n### Integration details\u200b\n\n| Class | Package | Local | Serializable | JS support |\n| ---- | ---- | ---- | ---- | ---- |\n| PDFPlumberLoader | langchain_community | \u2705 | \u274c | \u274c |\n\n### Loader features\u200b\n\n| Source | Document Lazy Loading | Native Async Support |\n| ---- | ---- | ---- |\n| PDFPlumberLoader | \u2705 | \u274c |\n\n## Setup\u200b\n\n### Credentials\u200b\n\nNo credentials are needed to use this loader.\n\nIf you want to get automated best in-class tracing of your model calls you can also set your [LangSmith](https://docs.smith.langchain.com/) API key by uncommenting below:\n\n```python\n# os.environ[\"LANGSMITH_API_KEY\"] = getpass.getpass(\"Enter your LangSmith API key: \")\n# os.environ[\"LANGSMITH_TRACING\"] = \"true\"\n```\n\n### Installation\u200b\n\nInstall **langchain_community**.\n\n```python\n%pip install -qU langchain_community\n```\n\n## Initialization\u200b\n\nNow we can instantiate our model object and load documents:\n\n```python\nfrom langchain_community.document_loaders import PDFPlumberLoader\n\nloader = PDFPlumberLoader(\"./example_data/layout-parser-paper.pdf\")\n```\n\n**API Reference:**[PDFPlumberLoader](https://python.langchain.com/api_reference/community/document_loaders/langchain_community.document_loaders.pdf.PDFPlumberLoader.html)\n## Load\u200b\n\n```python\ndocs = loader.load()\ndocs[0]\n```", "type": "Document"}, {"metadata": {"language": "en", "description": "Overview", "changefreq": "weekly", "source": "https://python.langchain.com/docs/integrations/document_loaders/unstructured_pdfloader/", "title": "UnstructuredPDFLoader | \ud83e\udd9c\ufe0f\ud83d\udd17 LangChain", "lastmod": null, "content_type": null, "priority": "0.5", "loc": "https://python.langchain.com/docs/integrations/document_loaders/unstructured_pdfloader/", "uuid": "8e7d3de8-e7e7-5cc2-bee5-618901e9e15f"}, "page_content": "**API Reference:**[OnlinePDFLoader](https://python.langchain.com/api_reference/community/document_loaders/langchain_community.document_loaders.pdf.OnlinePDFLoader.html)\n```output", "type": "Document"}, {"metadata": {"description": "Overview", "language": "en", "changefreq": "weekly", "source": "https://python.langchain.com/docs/integrations/document_loaders/pdfminer/", "title": "PDFMiner | \ud83e\udd9c\ufe0f\ud83d\udd17 LangChain", "lastmod": null, "content_type": null, "priority": "0.5", "loc": "https://python.langchain.com/docs/integrations/document_loaders/pdfminer/", "uuid": "d3f93dba-1bbe-5c15-b95a-ac9883de2010"}, "page_content": "PDFMiner | \ud83e\udd9c\ufe0f\ud83d\udd17 LangChain\n\n[Skip to main content](#__docusaurus_skipToContent_fallback)# PDFMiner\n\n## Overview\u200b\n\n### Integration details\u200b\n\n| Class | Package | Local | Serializable | JS support |\n| ---- | ---- | ---- | ---- | ---- |\n| PDFMinerLoader | langchain_community | \u2705 | \u274c | \u274c |\n\n### Loader features\u200b\n\n| Source | Document Lazy Loading | Native Async Support |\n| ---- | ---- | ---- |\n| PDFMinerLoader | \u2705 | \u274c |\n\n## Setup\u200b\n\n### Credentials\u200b\n\nNo credentials are needed for this loader.\n\nIf you want to get automated best in-class tracing of your model calls you can also set your [LangSmith](https://docs.smith.langchain.com/) API key by uncommenting below:\n\n```python\n# os.environ[\"LANGSMITH_API_KEY\"] = getpass.getpass(\"Enter your LangSmith API key: \")\n# os.environ[\"LANGSMITH_TRACING\"] = \"true\"\n```\n\n### Installation\u200b\n\nInstall **langchain_community**.\n\n```python\n%pip install -qU langchain_community\n```\n\n## Initialization\u200b\n\nNow we can instantiate our model object and load documents:\n\n```python\nfrom langchain_community.document_loaders import PDFMinerLoader\n\nfile_path = \"./example_data/layout-parser-paper.pdf\"\nloader = PDFMinerLoader(file_path)\n```\n\n**API Reference:**[PDFMinerLoader](https://python.langchain.com/api_reference/community/document_loaders/langchain_community.document_loaders.pdf.PDFMinerLoader.html)\n## Load\u200b\n\n```python\ndocs = loader.load()\ndocs[0]\n```", "type": "Document"}, {"metadata": {"description": "Dropbox is a file hosting service that brings everything-traditional files, cloud content, and web shortcuts together in one place.", "language": "en", "changefreq": "weekly", "source": "https://python.langchain.com/docs/integrations/document_loaders/dropbox/", "title": "Dropbox | \ud83e\udd9c\ufe0f\ud83d\udd17 LangChain", "content_type": null, "lastmod": null, "priority": "0.5", "loc": "https://python.langchain.com/docs/integrations/document_loaders/dropbox/", "uuid": "1c838fb9-84fb-52c2-bd59-44f7364c131c"}, "page_content": "- Document loader [how-to guides](/docs/how_to/#document-loaders)\n\n#### Was this page helpful?\n\n- [Prerequisites](#prerequisites)\n\n- [Instructions](#instructions)\n\n- [Related](#related)", "type": "Document"}, {"metadata": {"description": "- Documentation: Help improve our docs, including this one!", "language": "en", "changefreq": "weekly", "source": "https://python.langchain.com/docs/contributing/how_to/", "title": "How-to Guides | \ud83e\udd9c\ufe0f\ud83d\udd17 LangChain", "content_type": null, "lastmod": null, "priority": "0.5", "loc": "https://python.langchain.com/docs/contributing/how_to/", "uuid": "d5775518-e873-527c-a335-763647e27045"}, "page_content": "How-to Guides | \ud83e\udd9c\ufe0f\ud83d\udd17 LangChain\n\n[Skip to main content](#__docusaurus_skipToContent_fallback)# How-to Guides\n\n- [Documentation](/docs/contributing/how_to/documentation/): Help improve our docs, including this one!\n\n- [Code](/docs/contributing/how_to/code/): Help us write code, fix bugs, or improve our infrastructure.\n\n## Integrations\u200b\n\n- [Start Here](/docs/contributing/how_to/integrations/): Help us integrate with your favorite vendors and tools.\n\n- [Package](/docs/contributing/how_to/integrations/package/): Publish an integration package to PyPi\n\n- [Standard Tests](/docs/contributing/how_to/integrations/standard_tests/): Ensure your integration passes an expected set of tests.\n\n#### Was this page helpful?\n\n- [Integrations](#integrations)", "type": "Document"}, {"metadata": {"description": "LangChain integrations are packages that provide access to language models, vector stores, and other components that can be used in LangChain.", "language": "en", "changefreq": "weekly", "source": "https://python.langchain.com/docs/contributing/how_to/integrations/", "title": "Contribute Integrations | \ud83e\udd9c\ufe0f\ud83d\udd17 LangChain", "content_type": null, "lastmod": null, "priority": "0.5", "loc": "https://python.langchain.com/docs/contributing/how_to/integrations/", "uuid": "d3713db9-d79b-532a-9779-d980f53a7883"}, "page_content": "Contribute Integrations | \ud83e\udd9c\ufe0f\ud83d\udd17 LangChain\n\n[Skip to main content](#__docusaurus_skipToContent_fallback)# Contribute Integrations\n\nLangChain integrations are packages that provide access to language models, vector stores, and other components that can be used in LangChain.\n\nThis guide will walk you through how to contribute new integrations to LangChain, by\npublishing an integration package to PyPi, and adding documentation for it\nto the LangChain Monorepo.\n\nThese instructions will evolve over the next few months as we improve our integration\nprocesses.\n\n## Components to Integrate\u200b\n\ninfoSee the [Conceptual Guide](/docs/concepts/) for an overview of all components\nsupported in LangChain\n\nWhile any component can be integrated into LangChain, at this time we are only accepting\nnew integrations in the docs of the following kinds:\n\n## How to contribute an integration\u200b\n\nThe only step necessary to \"be\" a LangChain integration is to add documentation\nthat will render on this site ([https://python.langchain.com/](https://python.langchain.com/)).\n\nAs a prerequisite to adding your integration to our documentation, you must:\n\n1. Confirm that your integration is in the [list of components](#components-to-integrate) we are currently accepting.\n\n2. [Implement your package](/docs/contributing/how_to/integrations/package/) and publish it to a public github repository.\n\n3. [Implement the standard tests](/docs/contributing/how_to/integrations/standard_tests/) for your integration and successfully run them.\n\n4. [Publish your integration](/docs/contributing/how_to/integrations/publish/) by publishing the package to PyPi and add docs in the `docs/docs/integrations` directory of the LangChain monorepo.\n\nOnce you have completed these steps, you can submit a PR to the LangChain monorepo to add your integration to the documentation.\n\n## Further Reading\u200b\n\nTo get started, let's learn [how to bootstrap a new integration package](/docs/contributing/how_to/integrations/package/) for LangChain.\n\n#### Was this page helpful?\n\n- [Components to Integrate](#components-to-integrate)\n\n- [How to contribute an integration](#how-to-contribute-an-integration)\n\n- [Further Reading](#further-reading)", "type": "Document"}, {"metadata": {"description": "Before diving into this content, it would be helpful to read the following guides:", "language": "en", "changefreq": null, "source": "https://docs.smith.langchain.com/observability/how_to_guides/tracing/upload_files_with_traces", "title": "Upload files with traces | \ud83e\udd9c\ufe0f\ud83d\udee0\ufe0f LangSmith", "content_type": "text/html; charset=utf-8", "lastmod": null, "priority": null, "loc": null, "uuid": "919d45c3-d0ff-5a0b-a04e-a98df40671ee"}, "page_content": "Upload files with traces | \ud83e\udd9c\ufe0f\ud83d\udee0\ufe0f LangSmith\n\nSkip to main contentGo to API DocsSearchRegionUSEUGo to AppQuick StartObservabilityConceptual GuideHow-to GuidesTracingAnnotate code for tracingToggle tracing on and offUpload files with tracesLog traces to specific projectSet a sampling rate for tracesAdd metadata and tags to tracesImplement distributed tracingAccess the current run (span) within a traced functionLog multimodal tracesLog retriever tracesLog custom LLM tracesPrevent logging of sensitive data in tracesQuery tracesShare or unshare a trace publiclyCompare tracesTrace generator functionsTrace with LangChain (Python and JS/TS)Trace with LangGraph (Python and JS/TS)Trace with Instructor (Python only)Trace with the Vercel AI SDK (JS/TS only)Trace without setting environment variablesTrace using the LangSmith REST APICalculate token-based costs for tracesTroubleshoot trace nesting[Beta] Bulk Exporting Trace DataTrace JS functions in serverless environmentsMonitoring and automationsTutorialsAdd observability to your LLM applicationEvaluationPrompt EngineeringDeployment (LangGraph Cloud)AdministrationSelf-hostingReferenceObservabilityHow-to GuidesTracingUpload files with tracesUpload files with traces\nRecommended ReadingBefore diving into this content, it would be helpful to read the following guides:\nTrace with LangSmith using the traceable decorator or wrapper\n\nMinimum SDK VersionsThe following features are available in the following SDK versions:\nPython SDK: >=0.1.141\nJS/TS SDK: >=0.2.5\n\nLangSmith supports uploading binary files (such as images, audio, videos, and PDFs) with your traces. This is particularly useful when working with LLM pipelines using multimodal inputs or outputs.\nIn both the Python and TypeScript SDKs, attachments can be added to your traces by specifying the MIME type and binary content of each file.\nThis guide explains how to define and trace attachments using the Attachment type in Python and Uint8Array / ArrayBuffer in TypeScript.\nPythonTypeScriptIn the Python SDK, you can use the Attachment type to add files to your traces.\nEach Attachment requires:\n\nmime_type (str): The MIME type of the file (e.g., \"image/png\").\ndata (bytes): The binary content of the file.\n\nSimply decorate a function with @traceable and include your Attachment instances as arguments.\nfrom langsmith import traceablefrom langsmith.schemas import Attachment@traceabledef trace_with_attachments(  val: int,  text: str,  image: Attachment,  audio: Attachment,  video: Attachment,  pdf: Attachment,):  return f\"Processed: {val}, {text}, {len(image.data)}, {len(audio.data)}, {len(video.data)}, {len(pdf.data)}\"# Helper function to load files as bytesdef load_file(file_path: str) -> bytes:  with open(file_path, \"rb\") as f:      return f.read()# Load files and create attachmentsimage_data = load_file(\"my_image.png\")audio_data = load_file(\"my_mp3.mp3\")video_data = load_file(\"my_video.mp4\")pdf_data = load_file(\"my_document.pdf\")image_attachment = Attachment(mime_type=\"image/png\", data=image_data)audio_attachment = Attachment(mime_type=\"audio/mpeg\", data=audio_data)video_attachment = Attachment(mime_type=\"video/mp4\", data=video_data)pdf_attachment = Attachment(mime_type=\"application/pdf\", data=pdf_data)# Define other parametersval = 42text = \"Hello, world!\"# Call the function with traced attachmentsresult = trace_with_attachments(  val=val,  text=text,  image=image_attachment,  audio=audio_attachment,  video=video_attachment,  pdf=pdf_attachment,)In the TypeScript SDK, you can add attachments to traces by using Uint8Array or ArrayBuffer as data types.\nEach attachment's MIME type is specified within extractAttachments:\n\nUint8Array: Useful for handling binary data directly.\nArrayBuffer: Represents fixed-length binary data, which can be converted to Uint8Array as needed.", "type": "Document"}, {"metadata": {"description": "This notebook shows how to load email (.eml) or Microsoft Outlook (.msg) files.", "language": "en", "changefreq": "weekly", "source": "https://python.langchain.com/docs/integrations/document_loaders/email/", "title": "Email | \ud83e\udd9c\ufe0f\ud83d\udd17 LangChain", "content_type": null, "lastmod": null, "priority": "0.5", "loc": "https://python.langchain.com/docs/integrations/document_loaders/email/", "uuid": "c5a8d3b6-385d-5afe-b840-54578fda06c7"}, "page_content": "- Document loader [how-to guides](/docs/how_to/#document-loaders)\n\n#### Was this page helpful?\n\n- [Using Unstructured](#using-unstructured)- [Retain Elements](#retain-elements)\n\n- [Processing Attachments](#processing-attachments)\n\n- [Using OutlookMessageLoader](#using-outlookmessageloader)\n\n- [Related](#related)", "type": "Document"}, {"metadata": {"description": "SWE-bench is one of the most popular (and difficult!) benchmarks for developers to test their coding agents against. In this walkthrough we will show you how to load the SWE-bench dataset into LangSmith and easily run evals on it, allowing you to have much better visibility into your agents behaviour then using the off-the-shelf SWE-bench eval suite. This allows you to pin specific problems quicker and iterate on your agent rapidly to improve performance!", "language": "en", "changefreq": null, "source": "https://docs.smith.langchain.com/evaluation/tutorials/swe-benchmark", "title": "Running SWE-bench with LangSmith | \ud83e\udd9c\ufe0f\ud83d\udee0\ufe0f LangSmith", "lastmod": null, "content_type": "text/html; charset=utf-8", "priority": null, "loc": null, "uuid": "778670cd-91bd-562b-971a-c5fd4f58fe0d"}, "page_content": "Upload CSV to LangSmith Programmatically\u200b\nAlternatively you can upload your csv to LangSmith using the sdk as shown in the code block below:\ndataset = client.upload_csv(    csv_file=\"./../SWE-bench-dev.csv\",    input_keys=list(df.columns),    output_keys=[],    name=\"swe-bench-programatic-upload\",    description=\"SWE-bench dataset\",    data_type=\"kv\")\nCreate dataset split for quicker testing\u200b\nSince running the SWE-bench evaluator takes a long time when run on all examples, you can create a \"test\" split for quickly testing the evaluator and your code. Read this guide to learn more about managing dataset splits, or watch this short video that shows how to do it (to get to the starting page of the video, just click on your dataset created above and go to the Examples tab):", "type": "Document"}, {"metadata": {"language": "en", "description": "Some users prefer to manage their datasets and run their experiments outside of LangSmith, but want to use the LangSmith UI to view the results. This is supported via our /datasets/upload-experiment endpoint.", "changefreq": null, "source": "https://docs.smith.langchain.com/evaluation/how_to_guides/evaluation/upload_existing_experiments", "title": "Upload experiments run outside of LangSmith with the REST API | \ud83e\udd9c\ufe0f\ud83d\udee0\ufe0f LangSmith", "lastmod": null, "content_type": "text/html; charset=utf-8", "priority": null, "loc": null, "uuid": "74e18da8-f297-55cd-805b-d622996575a4"}, "page_content": "Skip to main contentGo to API DocsSearchRegionUSEUGo to AppQuick StartObservabilityEvaluationQuick StartConceptual GuideHow-to GuidesDatasetsEvaluationEvaluate an LLM ApplicationBind an evaluator to a dataset in the UIRun an evaluation from the prompt playgroundEvaluate on intermediate stepsUse LangChain off-the-shelf evaluators (Python only)Compare experiment resultsEvaluate an existing experimentTest LLM applications (Python only)Run pairwise evaluationsAudit evaluator scoresCreate few-shot evaluatorsFetch performance metrics for an experimentRun evals with the REST APIUpload experiments run outside of LangSmith with the REST APIFilter experiments in the UIHuman feedbackTutorialsEvaluate your LLM applicationRAG EvaluationsBacktestingEvaluate an agentRunning SWE-bench with LangSmithPrompt EngineeringDeployment (LangGraph Cloud)AdministrationSelf-hostingReferenceEvaluationHow-to GuidesEvaluationUpload experiments run outside of LangSmith with the REST APIOn this pageUpload experiments run outside of LangSmith with the REST API\nSome users prefer to manage their datasets and run their experiments outside of LangSmith, but want to use the LangSmith UI to view the results. This is supported via our /datasets/upload-experiment endpoint.\nThis guide will show you how to upload evals using the REST API, using the requests library in Python as an example. However, the same principles apply to any language.\nRequest body schema\u200b\nUploading an experiment requires specifying the relevant high-level information for your experiment and dataset, along with the individual data for your examples and runs within\nthe experiment. Each object in the results represents a \"row\" in the experiment - a single dataset example, along with an associated run. Note that dataset_id and dataset_name\nrefer to your dataset identifier in your external system and will be used to group external experiments together in a single dataset. They should not refer to an existing dataset\nin LangSmith (unless that dataset was created via this endpoint).\nYou may use the following schema to upload experiments to the /datasets/upload-experiment endpoint:", "type": "Document"}, {"metadata": {"language": "en", "description": "DocumentLoaders load data into the standard LangChain Document format.", "changefreq": "weekly", "source": "https://python.langchain.com/docs/integrations/document_loaders/", "title": "Document loaders | \ud83e\udd9c\ufe0f\ud83d\udd17 LangChain", "content_type": null, "lastmod": null, "priority": "0.5", "loc": "https://python.langchain.com/docs/integrations/document_loaders/", "uuid": "cbcffc89-a3d2-5630-9fc5-b89ee88d3d68"}, "page_content": "#### Was this page helpful?\n\n- [Webpages](#webpages)\n\n- [PDFs](#pdfs)\n\n- [Cloud Providers](#cloud-providers)\n\n- [Social Platforms](#social-platforms)\n\n- [Messaging Services](#messaging-services)\n\n- [Productivity tools](#productivity-tools)\n\n- [Common File Types](#common-file-types)\n\n- [All document loaders](#all-document-loaders)", "type": "Document"}, {"metadata": {"description": "Cloud SQL is a fully managed relational database service that offers high performance, seamless integration, and impressive scalability. It offers MySQL, PostgreSQL, and SQL Server database engines. Extend your database application to build AI-powered experiences leveraging Cloud SQL's Langchain integrations.", "language": "en", "changefreq": "weekly", "source": "https://python.langchain.com/docs/integrations/document_loaders/google_cloud_sql_mysql/", "title": "Google Cloud SQL for MySQL | \ud83e\udd9c\ufe0f\ud83d\udd17 LangChain", "lastmod": null, "content_type": null, "priority": "0.5", "loc": "https://python.langchain.com/docs/integrations/document_loaders/google_cloud_sql_mysql/", "uuid": "8943ffe3-9b8d-5605-8c1c-8e0c2697943c"}, "page_content": "#### Was this page helpful?\n\n- [Before You Begin](#before-you-begin)- [\ud83e\udd9c\ud83d\udd17 Library Installation](#-library-installation)\n\n- [\u2601 Set Your Google Cloud Project](#-set-your-google-cloud-project)\n\n- [\ud83d\udd10 Authentication](#-authentication)\n\n- [Basic Usage](#basic-usage)- [MySQLEngine Connection Pool](#mysqlengine-connection-pool)\n\n- [Initialize a table](#initialize-a-table)\n\n- [Save documents](#save-documents)\n\n- [Load documents](#load-documents)\n\n- [Load documents via query](#load-documents-via-query)\n\n- [Delete documents](#delete-documents)\n\n- [Advanced Usage](#advanced-usage)- [Load documents with customized document page content & metadata](#load-documents-with-customized-document-page-content--metadata)\n\n- [Save document with customized page content & metadata](#save-document-with-customized-page-content--metadata)\n\n- [Delete documents with customized page content & metadata](#delete-documents-with-customized-page-content--metadata)\n\n- [Related](#related)", "type": "Document"}, {"metadata": {"language": "en", "description": "When you add a webhook URL on an automation action, we will make a POST request to your webhook endpoint any time the rules you defined match any new runs.", "changefreq": null, "source": "https://docs.smith.langchain.com/observability/how_to_guides/monitoring/webhooks", "title": "Set up webhook notifications for rules | \ud83e\udd9c\ufe0f\ud83d\udee0\ufe0f LangSmith", "lastmod": null, "content_type": "text/html; charset=utf-8", "priority": null, "loc": null, "uuid": "2c2e0edb-a49a-5bd7-bbfa-d298a6931dd0"}, "page_content": "\"feedback_stats\": {    \"about_langchain\": {        \"n\": 1,        \"avg\": 0.0,        \"show_feedback_arrow\": true,        \"values\": {}    },    \"category\": {        \"n\": 0,        \"avg\": null,        \"show_feedback_arrow\": true,        \"values\": {            \"CONCEPTUAL\": 1        }    },    \"user_score\": {        \"n\": 2,        \"avg\": 0.0,        \"show_feedback_arrow\": false,        \"values\": {}    },    \"vagueness\": {        \"n\": 1,        \"avg\": 0.0,        \"show_feedback_arrow\": true,        \"values\": {}    }},\nfetching from S3 URLsDepending on how recent your runs are, the inputs_s3_urls and outputs_s3_urls fields may contain S3 URLs to the actual data instead of the data itself.The inputs and outputs can be fetched by the ROOT.presigned_url provided in inputs_s3_urls and outputs_s3_urls respectively.\nThis is an example of the entire payload we send to your webhook endpoint:\n{  \"rule_id\": \"d75d7417-0c57-4655-88fe-1db3cda3a47a\",  \"start_time\": \"2024-04-05T01:28:54.734491+00:00\",  \"end_time\": \"2024-04-05T01:28:56.492563+00:00\",  \"runs\": [    {      \"status\": \"success\",      \"is_root\": true,      \"trace_id\": \"6ab80f10-d79c-4fa2-b441-922ed6feb630\",      \"dotted_order\": \"20230505T051324571809Z6ab80f10-d79c-4fa2-b441-922ed6feb630\",      \"run_type\": \"tool\",      \"modified_at\": \"2024-04-05T01:28:54.145062\",      \"tenant_id\": \"2ebda79f-2946-4491-a9ad-d642f49e0815\",      \"end_time\": \"2024-04-05T01:28:54.085649\",      \"name\": \"Search\",      \"start_time\": \"2024-04-05T01:28:54.085646\",      \"id\": \"6ab80f10-d79c-4fa2-b441-922ed6feb630\",      \"session_id\": \"6a3be6a2-9a8c-4fc8-b4c6-a8983b286cc5\",      \"parent_run_ids\": [],      \"child_run_ids\": null,      \"direct_child_run_ids\": null,      \"total_tokens\": 0,      \"completion_tokens\": 0,      \"prompt_tokens\": 0,      \"total_cost\": null,      \"completion_cost\": null,      \"prompt_cost\": null,      \"first_token_time\": null,      \"app_path\": \"/o/2ebda79f-2946-4491-a9ad-d642f49e0815/projects/p/6a3be6a2-9a8c-4fc8-b4c6-a8983b286cc5/r/6ab80f10-d79c-4fa2-b441-922ed6feb630?trace_id=6ab80f10-d79c-4fa2-b441-922ed6feb630&start_time=2023-05-05T05:13:24.571809\",      \"in_dataset\": false,      \"last_queued_at\": null,      \"inputs\": null,      \"inputs_s3_urls\": null,      \"outputs\": null,      \"outputs_s3_urls\": null,      \"extra\": null,      \"events\": null,      \"feedback_stats\": null,      \"serialized\": null,      \"share_token\": null    }  ]}\nWebhook Security\u200b\nWe strongly recommend you add a secret query string parameter to the webhook URL, and verify it on any incoming request. This ensures that if someone discovers your webhook URL you can distinguish those calls from authentic webhook notifications.\nAn example would be\nhttps://api.example.com/langsmith_webhook?secret=38ee77617c3a489ab6e871fbeb2ec87d\nWebhook custom HTTP headers\u200b\nIf you'd like to send any specific headers with your webhook, this can be configured per URL. To set this up, click on the Headers option next to the URL field and add your headers.\nnoteHeaders are stored in encrypted format.\n\nWebhook Delivery\u200b\nWhen delivering events to your webhook endpoint we follow these guidelines\n\nIf we fail to connect to your endpoint, we retry the transport connection up to 2 times, before declaring the delivery failed.\nIf your endpoint takes longer than 5 seconds to reply we declare the delivery failed and do not .\nIf your endpoint returns a 5xx status code in less than 5 seconds we retry up to 2 times with exponential backoff.\nIf your endpoint returns a 4xx status code, we declare the delivery failed and do not retry.\nAnything your endpoint returns in the body will be ignored", "type": "Document"}, {"metadata": {"description": "College Confidential gives information on 3,800+ colleges and universities.", "language": "en", "changefreq": "weekly", "source": "https://python.langchain.com/docs/integrations/document_loaders/college_confidential/", "title": "College Confidential | \ud83e\udd9c\ufe0f\ud83d\udd17 LangChain", "content_type": null, "lastmod": null, "priority": "0.5", "loc": "https://python.langchain.com/docs/integrations/document_loaders/college_confidential/", "uuid": "8f02ba83-688f-5277-a62a-ebf792703db7"}, "page_content": "## Related\u200b\n\n- Document loader [conceptual guide](/docs/concepts/document_loaders/)\n\n- Document loader [how-to guides](/docs/how_to/#document-loaders)\n\n#### Was this page helpful?\n\n- [Related](#related)", "type": "Document"}, {"metadata": {"language": "en", "description": "Twitter is an online social media and social networking service.", "changefreq": "weekly", "source": "https://python.langchain.com/docs/integrations/document_loaders/twitter/", "title": "Twitter | \ud83e\udd9c\ufe0f\ud83d\udd17 LangChain", "lastmod": null, "content_type": null, "priority": "0.5", "loc": "https://python.langchain.com/docs/integrations/document_loaders/twitter/", "uuid": "1b61a73f-cf2c-59d5-8e73-b4d5ee0577d0"}, "page_content": "## Related\u200b\n\n- Document loader [conceptual guide](/docs/concepts/document_loaders/)\n\n- Document loader [how-to guides](/docs/how_to/#document-loaders)\n\n#### Was this page helpful?\n\n- [Related](#related)", "type": "Document"}, {"metadata": {"description": "Bilibili is one of the most beloved long-form video sites in China.", "language": "en", "changefreq": "weekly", "source": "https://python.langchain.com/docs/integrations/document_loaders/bilibili/", "title": "BiliBili | \ud83e\udd9c\ufe0f\ud83d\udd17 LangChain", "lastmod": null, "content_type": null, "priority": "0.5", "loc": "https://python.langchain.com/docs/integrations/document_loaders/bilibili/", "uuid": "f4f02274-21de-51cf-aa7a-af952910183c"}, "page_content": "## Related\u200b\n\n- Document loader [conceptual guide](/docs/concepts/document_loaders/)\n\n- Document loader [how-to guides](/docs/how_to/#document-loaders)\n\n#### Was this page helpful?\n\n- [Related](#related)", "type": "Document"}, {"metadata": {"description": "The unstructured package from", "language": "en", "changefreq": "weekly", "source": "https://python.langchain.com/docs/integrations/providers/unstructured/", "title": "Unstructured | \ud83e\udd9c\ufe0f\ud83d\udd17 LangChain", "content_type": null, "lastmod": null, "priority": "0.5", "loc": "https://python.langchain.com/docs/integrations/providers/unstructured/", "uuid": "34ed8a8d-a1c6-5eb2-ae11-32ba7108fd15"}, "page_content": "See a [usage example](/docs/integrations/document_loaders/csv/#unstructuredcsvloader).\n\n```python\nfrom langchain_community.document_loaders import UnstructuredCSVLoader\n```\n\n**API Reference:**[UnstructuredCSVLoader](https://python.langchain.com/api_reference/community/document_loaders/langchain_community.document_loaders.csv_loader.UnstructuredCSVLoader.html)\n### UnstructuredEmailLoader\u200b\n\nSee a [usage example](/docs/integrations/document_loaders/email/).\n\n```python\nfrom langchain_community.document_loaders import UnstructuredEmailLoader\n```\n\n**API Reference:**[UnstructuredEmailLoader](https://python.langchain.com/api_reference/community/document_loaders/langchain_community.document_loaders.email.UnstructuredEmailLoader.html)\n### UnstructuredEPubLoader\u200b\n\n[EPUB](https://en.wikipedia.org/wiki/EPUB) is an `e-book file format` that uses\nthe \u201c.epub\u201d file extension. The term is short for electronic publication and\nis sometimes styled `ePub`. `EPUB` is supported by many e-readers, and compatible\nsoftware is available for most smartphones, tablets, and computers.\n\nSee a [usage example](/docs/integrations/document_loaders/epub/).\n\n```python\nfrom langchain_community.document_loaders import UnstructuredEPubLoader\n```\n\n**API Reference:**[UnstructuredEPubLoader](https://python.langchain.com/api_reference/community/document_loaders/langchain_community.document_loaders.epub.UnstructuredEPubLoader.html)\n### UnstructuredExcelLoader\u200b\n\nSee a [usage example](/docs/integrations/document_loaders/microsoft_excel/).\n\n```python\nfrom langchain_community.document_loaders import UnstructuredExcelLoader\n```\n\n**API Reference:**[UnstructuredExcelLoader](https://python.langchain.com/api_reference/community/document_loaders/langchain_community.document_loaders.excel.UnstructuredExcelLoader.html)\n### UnstructuredFileIOLoader\u200b\n\nSee a [usage example](/docs/integrations/document_loaders/google_drive/#passing-in-optional-file-loaders).\n\n```python\nfrom langchain_community.document_loaders import UnstructuredFileIOLoader\n```\n\n**API Reference:**[UnstructuredFileIOLoader](https://python.langchain.com/api_reference/community/document_loaders/langchain_community.document_loaders.unstructured.UnstructuredFileIOLoader.html)\n### UnstructuredHTMLLoader\u200b\n\nSee a [usage example](/docs/how_to/document_loader_html/).\n\n```python\nfrom langchain_community.document_loaders import UnstructuredHTMLLoader\n```\n\n**API Reference:**[UnstructuredHTMLLoader](https://python.langchain.com/api_reference/community/document_loaders/langchain_community.document_loaders.html.UnstructuredHTMLLoader.html)\n### UnstructuredImageLoader\u200b\n\nSee a [usage example](/docs/integrations/document_loaders/image/).\n\n```python\nfrom langchain_community.document_loaders import UnstructuredImageLoader\n```\n\n**API Reference:**[UnstructuredImageLoader](https://python.langchain.com/api_reference/community/document_loaders/langchain_community.document_loaders.image.UnstructuredImageLoader.html)\n### UnstructuredMarkdownLoader\u200b\n\nSee a [usage example](/docs/integrations/vectorstores/starrocks/).\n\n```python\nfrom langchain_community.document_loaders import UnstructuredMarkdownLoader\n```\n\n**API Reference:**[UnstructuredMarkdownLoader](https://python.langchain.com/api_reference/community/document_loaders/langchain_community.document_loaders.markdown.UnstructuredMarkdownLoader.html)\n### UnstructuredODTLoader\u200b\n\nThe `Open Document Format for Office Applications (ODF)`, also known as `OpenDocument`,\nis an open file format for word processing documents, spreadsheets, presentations\nand graphics and using ZIP-compressed XML files. It was developed with the aim of\nproviding an open, XML-based file format specification for office applications.\n\nSee a [usage example](/docs/integrations/document_loaders/odt/).\n\n```python\nfrom langchain_community.document_loaders import UnstructuredODTLoader\n```", "type": "Document"}, {"metadata": {"description": "This notebook covers how to use Unstructured document loader to load files of many types. Unstructured currently supports loading of text files, powerpoints, html, pdfs, images, and more.", "language": "en", "changefreq": "weekly", "source": "https://python.langchain.com/docs/integrations/document_loaders/unstructured_file/", "title": "Unstructured | \ud83e\udd9c\ufe0f\ud83d\udd17 LangChain", "lastmod": null, "content_type": null, "priority": "0.5", "loc": "https://python.langchain.com/docs/integrations/document_loaders/unstructured_file/", "uuid": "352d6045-10cf-5e5a-a9a3-9fda61268770"}, "page_content": "```output\n[Document(metadata={'source': './example_data/layout-parser-paper.pdf', 'coordinates': {'points': ((16.34, 393.9), (16.34, 560.0), (36.34, 560.0), (36.34, 393.9)), 'system': 'PixelSpace', 'layout_width': 612, 'layout_height': 792}, 'file_directory': './example_data', 'filename': 'layout-parser-paper.pdf', 'languages': ['eng'], 'last_modified': '2024-02-27T15:49:27', 'page_number': 1, 'parent_id': '89565df026a24279aaea20dc08cedbec', 'filetype': 'application/pdf', 'category': 'UncategorizedText', 'element_id': 'e9fa370aef7ee5c05744eb7bb7d9981b'}, page_content='2 v 8 4 3 5 1 . 3 0 1 2 : v i X r a'),\n Document(metadata={'source': './example_data/layout-parser-paper.pdf', 'coordinates': {'points': ((157.62199999999999, 114.23496279999995), (157.62199999999999, 146.5141628), (457.7358962799999, 146.5141628), (457.7358962799999, 114.23496279999995)), 'system': 'PixelSpace', 'layout_width': 612, 'layout_height': 792}, 'file_directory': './example_data', 'filename': 'layout-parser-paper.pdf', 'languages': ['eng'], 'last_modified': '2024-02-27T15:49:27', 'page_number': 1, 'filetype': 'application/pdf', 'category': 'Title', 'element_id': 'bde0b230a1aa488e3ce837d33015181b'}, page_content='LayoutParser: A Uni\ufb01ed Toolkit for Deep Learning Based Document Image Analysis'),\n Document(metadata={'source': './example_data/layout-parser-paper.pdf', 'coordinates': {'points': ((134.809, 168.64029940800003), (134.809, 192.2517444), (480.5464199080001, 192.2517444), (480.5464199080001, 168.64029940800003)), 'system': 'PixelSpace', 'layout_width': 612, 'layout_height': 792}, 'file_directory': './example_data', 'filename': 'layout-parser-paper.pdf', 'languages': ['eng'], 'last_modified': '2024-02-27T15:49:27', 'page_number': 1, 'parent_id': 'bde0b230a1aa488e3ce837d33015181b', 'filetype': 'application/pdf', 'category': 'UncategorizedText', 'element_id': '54700f902899f0c8c90488fa8d825bce'}, page_content='Zejiang Shen1 ((cid:0)), Ruochen Zhang2, Melissa Dell3, Benjamin Charles Germain Lee4, Jacob Carlson3, and Weining Li5'),\n Document(metadata={'source': './example_data/layout-parser-paper.pdf', 'coordinates': {'points': ((207.23000000000002, 202.57205439999996), (207.23000000000002, 311.8195408), (408.12676, 311.8195408), (408.12676, 202.57205439999996)), 'system': 'PixelSpace', 'layout_width': 612, 'layout_height': 792}, 'file_directory': './example_data', 'filename': 'layout-parser-paper.pdf', 'languages': ['eng'], 'last_modified': '2024-02-27T15:49:27', 'page_number': 1, 'parent_id': 'bde0b230a1aa488e3ce837d33015181b', 'filetype': 'application/pdf', 'category': 'UncategorizedText', 'element_id': 'b650f5867bad9bb4e30384282c79bcfe'}, page_content='1 Allen Institute for AI shannons@allenai.org 2 Brown University ruochen zhang@brown.edu 3 Harvard University {melissadell,jacob carlson}@fas.harvard.edu 4 University of Washington bcgl@cs.washington.edu 5 University of Waterloo w422li@uwaterloo.ca'),", "type": "Document"}, {"metadata": {"description": "MediaWiki XML Dumps contain the content of a wiki (wiki pages with all their revisions), without the site-related data. A XML dump does not create a full backup of the wiki database, the dump does not contain user accounts, images, edit logs, etc.", "language": "en", "changefreq": "weekly", "source": "https://python.langchain.com/docs/integrations/document_loaders/mediawikidump/", "title": "MediaWiki Dump | \ud83e\udd9c\ufe0f\ud83d\udd17 LangChain", "lastmod": null, "content_type": null, "priority": "0.5", "loc": "https://python.langchain.com/docs/integrations/document_loaders/mediawikidump/", "uuid": "23b91418-8c4e-5219-a721-1f1cc18ec4ec"}, "page_content": "```output\nYou have 177 document(s) in your data\n```\n\n```python\ndocuments[:5]\n```\n\n```output\n[Document(page_content='\\t\\n\\t\\n\\tArtist\\n\\tReleased\\n\\tRecorded\\n\\tLength\\n\\tLabel\\n\\tProducer', metadata={'source': 'Album'}),\n Document(page_content='{| class=\"article-table plainlinks\" style=\"width:100%;\"\\n|- style=\"font-size:18px;\"\\n! style=\"padding:0px;\" | Template documentation\\n|-\\n| Note: portions of the template sample may not be visible without values provided.\\n|-\\n| View or edit this documentation. (About template documentation)\\n|-\\n| Editors can experiment in this template\\'s [ sandbox] and [ test case] pages.\\n|}Category:Documentation templates', metadata={'source': 'Documentation'}),\n Document(page_content='Description\\nThis template is used to insert descriptions on template pages.\\n\\nSyntax\\nAdd <noinclude></noinclude> at the end of the template page.\\n\\nAdd <noinclude></noinclude> to transclude an alternative page from the /doc subpage.\\n\\nUsage\\n\\nOn the Template page\\nThis is the normal format when used:\\n\\nTEMPLATE CODE\\n<includeonly>Any categories to be inserted into articles by the template</includeonly>\\n<noinclude>{{Documentation}}</noinclude>\\n\\nIf your template is not a completed div or table, you may need to close the tags just before {{Documentation}} is inserted (within the noinclude tags).\\n\\nA line break right before {{Documentation}} can also be useful as it helps prevent the documentation template \"running into\" previous code.\\n\\nOn the documentation page\\nThe documentation page is usually located on the /doc subpage for a template, but a different page can be specified with the first parameter of the template (see Syntax).\\n\\nNormally, you will want to write something like the following on the documentation page:\\n\\n==Description==\\nThis template is used to do something.\\n\\n==Syntax==\\nType <code>{{t|templatename}}</code> somewhere.\\n\\n==Samples==\\n<code><nowiki>{{templatename|input}}</nowiki></code> \\n\\nresults in...\\n\\n{{templatename|input}}\\n\\n<includeonly>Any categories for the template itself</includeonly>\\n<noinclude>[[Category:Template documentation]]</noinclude>\\n\\nUse any or all of the above description/syntax/sample output sections. You may also want to add \"see also\" or other sections.\\n\\nNote that the above example also uses the Template:T template.\\n\\nCategory:Documentation templatesCategory:Template documentation', metadata={'source': 'Documentation/doc'}),\n Document(page_content='Description\\nA template link with a variable number of parameters (0-20).\\n\\nSyntax\\n \\n\\nSource\\nImproved version not needing t/piece subtemplate developed on Templates wiki see the list of authors. Copied here via CC-By-SA 3.0 license.\\n\\nExample\\n\\nCategory:General wiki templates\\nCategory:Template documentation', metadata={'source': 'T/doc'}),\n Document(page_content='\\t\\n\\t\\t    \\n\\t\\n\\t\\t    Aliases\\n\\t    Relatives\\n\\t    Affiliation\\n        Occupation\\n    \\n            Biographical information\\n        Marital status\\n    \\tDate of birth\\n        Place of birth\\n        Date of death\\n        Place of death\\n    \\n            Physical description\\n        Species\\n        Gender\\n        Height\\n        Weight\\n        Eye color\\n\\t\\n           Appearances\\n       Portrayed by\\n       Appears in\\n       Debut\\n    ', metadata={'source': 'Character'})]\n```\n\n## Related\u200b\n\n- Document loader [conceptual guide](/docs/concepts/document_loaders/)\n\n- Document loader [how-to guides](/docs/how_to/#document-loaders)\n\n#### Was this page helpful?\n\n- [Related](#related)", "type": "Document"}, {"metadata": {"description": "markdownify is a Python package that converts HTML documents to Markdown format with customizable options for handling tags (links, images, ...), heading styles and other.", "language": "en", "changefreq": "weekly", "source": "https://python.langchain.com/docs/integrations/document_transformers/markdownify/", "title": "Markdownify | \ud83e\udd9c\ufe0f\ud83d\udd17 LangChain", "lastmod": null, "content_type": null, "priority": "0.5", "loc": "https://python.langchain.com/docs/integrations/document_transformers/markdownify/", "uuid": "8af62e09-443d-5cc9-9c24-a8bd13563ed0"}, "page_content": "will write a very long answer. Make sure that every detail of the architecture is, in the end, implemented as code.\\\\\\\\nMake sure that every detail of the architecture is, in the end, implemented as code.\\\\\\\\n\\\\\\\\nThink step by step and reason yourself to the right decisions to make sure we get it right.\\\\\\\\nYou will first lay out the names of the core classes, functions, methods that will be necessary, as well as a quick comment on their purpose.\\\\\\\\n\\\\\\\\nThen you will output the content of each file including ALL code.\\\\\\\\nEach file must strictly follow a markdown code block format, where the following tokens must be replaced such that\\\\\\\\nFILENAME is the lowercase file name including the file extension,\\\\\\\\nLANG is the markup code block language for the code\\'s language, and CODE is the code:\\\\\\\\n\\\\\\\\nFILENAME\\\\\\\\n\\`\\`\\`LANG\\\\\\\\nCODE\\\\\\\\n\\`\\`\\`\\\\\\\\n\\\\\\\\nYou will start with the \\\\\\\\\\\\\"entrypoint\\\\\\\\\\\\\" file, then go to the ones that are imported by that file, and so on.\\\\\\\\nPlease note that the code should be fully functional. No placeholders.\\\\\\\\n\\\\\\\\nFollow a language and framework appropriate best practice file naming convention.\\\\\\\\nMake sure that files contain all imports, types etc. Make sure that code in different files are compatible with each other.\\\\\\\\nEnsure to implement all code, if you are unsure, write a plausible implementation.\\\\\\\\nInclude module dependency or package manager dependency definition file.\\\\\\\\nBefore you finish, double check that all parts of the architecture is present in the files.\\\\\\\\n\\\\\\\\nUseful to know:\\\\\\\\nYou almost always put different classes in different files.\\\\\\\\nFor Python, you always create an appropriate requirements.txt file.\\\\\\\\nFor NodeJS, you always create an appropriate package.json file.\\\\\\\\nYou always add a comment briefly describing the purpose of the function definition.\\\\\\\\nYou try to add comments explaining very complex bits of logic.\\\\\\\\nYou always follow the best practices for the requested languages in terms of describing the code written as a defined\\\\\\\\npackage/project.\\\\\\\\n\\\\\\\\n\\\\\\\\nPython toolbelt preferences:\\\\\\\\n- pytest\\\\\\\\n- dataclasses\\\\\\\\n\\\\\" }, # \u2026 same conversation as earlier, ended with \\\\\"Make your own assumptions and state them explicitly before starting\\\\\". { \\\\\"role\\\\\": \\\\\"assistant\\\\\", \\\\\"content\\\\\": \\\\\"Assumptions:\\\\\\\\n1. Model: The model will contain the game\\'s data, such as level information, character states, and enemy positions.\\\\\\\\n2. View: The view will handle the game\\'s visuals, including rendering the game objects, backgrounds, and updating the display.\\\\\\\\n3. Controller: The controller will manage user input, such as keyboard controls, and update the model accordingly.\\\\\\\\n\\\\\\\\nWith these assumptions in mind, is there any specific aspect of the keyboard control implementation you would like me to clarify?\\\\\" }, { \\\\\"role\\\\\": \\\\\"user\\\\\", \\\\\"content\\\\\": \\\\\"Please now remember the steps:\\\\\\\\n\\\\\\\\nThink step by step and reason yourself to the right decisions to make sure we get it right.\\\\\\\\nFirst lay out the names of the core classes, functions, methods that will be necessary, As well as a quick comment on their purpose.\\\\\\\\n\\\\\\\\nThen you will output the content of each file including ALL code.\\\\\\\\nEach file must strictly follow a markdown code block format, where the following tokens must be replaced such that\\\\\\\\nFILENAME is the lowercase file name including the file extension,\\\\\\\\nLANG is the markup code block language for the code\\'s language, and CODE is the code:\\\\\\\\n\\\\\\\\nFILENAME\\\\\\\\n\\`\\`\\`LANG\\\\\\\\nCODE\\\\\\\\n\\`\\`\\`\\\\\\\\n\\\\\\\\nPlease note that the code should be fully functional. No placeholders.\\\\\\\\n\\\\\\\\nYou will start with the \\\\\\\\\\\\\"entrypoint\\\\\\\\\\\\\" file, then go to the ones that are imported by that file, and so on.\\\\\\\\nFollow a language and framework appropriate best practice file naming convention.\\\\\\\\nMake sure that files contain all imports, types etc. The code should be fully functional. Make sure that code in different files", "type": "Document"}, {"metadata": {"description": "markdownify is a Python package that converts HTML documents to Markdown format with customizable options for handling tags (links, images, ...), heading styles and other.", "language": "en", "changefreq": "weekly", "source": "https://python.langchain.com/docs/integrations/document_transformers/markdownify/", "title": "Markdownify | \ud83e\udd9c\ufe0f\ud83d\udd17 LangChain", "lastmod": null, "content_type": null, "priority": "0.5", "loc": "https://python.langchain.com/docs/integrations/document_transformers/markdownify/", "uuid": "7b547e20-3a35-5cb0-881c-341c25231f06"}, "page_content": "of the architecture is, in the end, implemented as code.\\\\nMake sure that every detail of the architecture is, in the end, implemented as code.\\\\n\\\\nThink step by step and reason yourself to the right decisions to make sure we get it right.\\\\nYou will first lay out the names of the core classes, functions, methods that will be necessary, as well as a quick comment on their purpose.\\\\n\\\\nThen you will output the content of each file including ALL code.\\\\nEach file must strictly follow a markdown code block format, where the following tokens must be replaced such that\\\\nFILENAME is the lowercase file name including the file extension,\\\\nLANG is the markup code block language for the code&#39;s language, and CODE is the code:\\\\n\\\\nFILENAME\\\\n\\`\\`\\`LANG\\\\nCODE\\\\n\\`\\`\\`\\\\n\\\\nYou will start with the \\\\&#34;entrypoint\\\\&#34; file, then go to the ones that are imported by that file, and so on.\\\\nPlease note that the code should be fully functional. No placeholders.\\\\n\\\\nFollow a language and framework appropriate best practice file naming convention.\\\\nMake sure that files contain all imports, types etc. Make sure that code in different files are compatible with each other.\\\\nEnsure to implement all code, if you are unsure, write a plausible implementation.\\\\nInclude module dependency or package manager dependency definition file.\\\\nBefore you finish, double check that all parts of the architecture is present in the files.\\\\n\\\\nUseful to know:\\\\nYou almost always put different classes in different files.\\\\nFor Python, you always create an appropriate requirements.txt file.\\\\nFor NodeJS, you always create an appropriate package.json file.\\\\nYou always add a comment briefly describing the purpose of the function definition.\\\\nYou try to add comments explaining very complex bits of logic.\\\\nYou always follow the best practices for the requested languages in terms of describing the code written as a defined\\\\npackage/project.\\\\n\\\\n\\\\nPython toolbelt preferences:\\\\n- pytest\\\\n- dataclasses\\\\n&#34;\\n  },\\n #  \u2026 same conversation as earlier, ended with &#34;Make your own assumptions and state them explicitly before starting&#34;.\\n  {\\n    &#34;role&#34;: &#34;assistant&#34;,\\n    &#34;content&#34;: &#34;Assumptions:\\\\n1. Model: The model will contain the game&#39;s data, such as level information, character states, and enemy positions.\\\\n2. View: The view will handle the game&#39;s visuals, including rendering the game objects, backgrounds, and updating the display.\\\\n3. Controller: The controller will manage user input, such as keyboard controls, and update the model accordingly.\\\\n\\\\nWith these assumptions in mind, is there any specific aspect of the keyboard control implementation you would like me to clarify?&#34;\\n  },\\n  {\\n    &#34;role&#34;: &#34;user&#34;,\\n    &#34;content&#34;: &#34;Please now remember the steps:\\\\n\\\\nThink step by step and reason yourself to the right decisions to make sure we get it right.\\\\nFirst lay out the names of the core classes, functions, methods that will be necessary, As well as a quick comment on their purpose.\\\\n\\\\nThen you will output the content of each file including ALL code.\\\\nEach file must strictly follow a markdown code block format, where the following tokens must be replaced such that\\\\nFILENAME is the lowercase file name including the file extension,\\\\nLANG is the markup code block language for the code&#39;s language, and CODE is the code:\\\\n\\\\nFILENAME\\\\n\\`\\`\\`LANG\\\\nCODE\\\\n\\`\\`\\`\\\\n\\\\nPlease note that the code should be fully functional. No placeholders.\\\\n\\\\nYou will start with the \\\\&#34;entrypoint\\\\&#34; file, then go to the ones that are imported by that file, and so on.\\\\nFollow a language and framework appropriate best practice file naming convention.\\\\nMake sure that files contain all imports, types etc. The code should be fully functional. Make sure that code in different files are compatible with each other.\\\\nBefore you finish, double check that all parts of the architecture", "type": "Document"}, {"metadata": {"description": "markdownify is a Python package that converts HTML documents to Markdown format with customizable options for handling tags (links, images, ...), heading styles and other.", "language": "en", "changefreq": "weekly", "source": "https://python.langchain.com/docs/integrations/document_transformers/markdownify/", "title": "Markdownify | \ud83e\udd9c\ufe0f\ud83d\udd17 LangChain", "lastmod": null, "content_type": null, "priority": "0.5", "loc": "https://python.langchain.com/docs/integrations/document_transformers/markdownify/", "uuid": "fe6ca9cc-8348-5c45-a3eb-c9a4f91be801"}, "page_content": "Super Mario game in python. MVC components split in separate files. Keyboard control.}}\\\\\\\\n\\\\\" }, { \\\\\"role\\\\\": \\\\\"assistant\\\\\", \\\\\"content\\\\\": \\\\\"Summary of areas that need clarification:\\\\\\\\n1. Specifics of the Super Mario game (e.g. level design, characters, gameplay mechanics)\\\\\\\\n2. Details about the MVC components (e.g. which components are in each file)\\\\\\\\n3. Keyboard control implementation (e.g. which keys to use, how to handle input)\\\\\\\\n\\\\\\\\nClarifying question:\\\\\\\\nCan you provide more details about the Super Mario game, such as level design, characters, and gameplay mechanics?\\\\\" }, { \\\\\"role\\\\\": \\\\\"user\\\\\", \\\\\"content\\\\\": \\\\\"{{There are 10 levels in total. The main character is a plumber named Mario, who can walk and jump. It is a classical platform game just like Super Mario. The main character moves from left to right, trying to get to the destination, where there are many obstacles and attacks from enemies in the process.}}\\\\\\\\n\\\\\\\\nIs anything else unclear? If yes, only answer in the form:\\\\\\\\n{remaining unclear areas} remaining questions.\\\\\\\\n{Next question}\\\\\\\\nIf everything is sufficiently clear, only answer \\\\\\\\\\\\\"Nothing more to clarify.\\\\\\\\\\\\\".\\\\\" }, { \\\\\"role\\\\\": \\\\\"assistant\\\\\", \\\\\"content\\\\\": \\\\\"Remaining unclear areas: 2 remaining questions.\\\\\\\\nCan you provide more information about how the MVC components are split into separate files?\\\\\" }, { \\\\\"role\\\\\": \\\\\"user\\\\\", \\\\\"content\\\\\": \\\\\"{{Make your own assumptions and state them explicitly before starting}}\\\\\" } ] Then after these clarification, the agent moved into the code writing mode with a different system message. System message:\\\\nYou will get instructions for code to write. You will write a very long answer. Make sure that every detail of the architecture is, in the end, implemented as code. Make sure that every detail of the architecture is, in the end, implemented as code. Think step by step and reason yourself to the right decisions to make sure we get it right. You will first lay out the names of the core classes, functions, methods that will be necessary, as well as a quick comment on their purpose.\\\\nThen you will output the content of each file including ALL code. Each file must strictly follow a markdown code block format, where the following tokens must be replaced such that FILENAME is the lowercase file name including the file extension, LANG is the markup code block language for the code\u2019s language, and CODE is the code:\\\\nFILENAME\\\\nCODE You will start with the \u201centrypoint\u201d file, then go to the ones that are imported by that file, and so on. Please note that the code should be fully functional. No placeholders.\\\\nFollow a language and framework appropriate best practice file naming convention. Make sure that files contain all imports, types etc. Make sure that code in different files are compatible with each other. Ensure to implement all code, if you are unsure, write a plausible implementation. Include module dependency or package manager dependency definition file. Before you finish, double check that all parts of the architecture is present in the files.\\\\nUseful to know: You almost always put different classes in different files. For Python, you always create an appropriate requirements.txt file. For NodeJS, you always create an appropriate package.json file. You always add a comment briefly describing the purpose of the function definition. You try to add comments explaining very complex bits of logic. You always follow the best practices for the requested languages in terms of describing the code written as a defined package/project.\\\\nPython toolbelt preferences:\\\\npytest dataclasses Conversatin samples:\\\\n[ { \\\\\"role\\\\\": \\\\\"system\\\\\", \\\\\"content\\\\\": \\\\\"You will get instructions for code to write.\\\\\\\\nYou will write a very long answer. Make sure that every detail of the architecture is, in the end, implemented as code.\\\\\\\\nMake sure that every detail of the architecture is, in the end, implemented as", "type": "Document"}, {"metadata": {"description": "markdownify is a Python package that converts HTML documents to Markdown format with customizable options for handling tags (links, images, ...), heading styles and other.", "language": "en", "changefreq": "weekly", "source": "https://python.langchain.com/docs/integrations/document_transformers/markdownify/", "title": "Markdownify | \ud83e\udd9c\ufe0f\ud83d\udd17 LangChain", "content_type": null, "lastmod": null, "priority": "0.5", "loc": "https://python.langchain.com/docs/integrations/document_transformers/markdownify/", "uuid": "5463127a-20dc-5f9d-bdf9-5069f7a46d06"}, "page_content": "keys to use, how to handle input)\\\\n\\\\nClarifying question:\\\\nCan you provide more details about the Super Mario game, such as level design, characters, and gameplay mechanics?&#34;\\n  },\\n  {\\n    &#34;role&#34;: &#34;user&#34;,\\n    &#34;content&#34;: &#34;{{There are 10 levels in total. The main character is a plumber named Mario, who can walk and jump. It is a classical platform game just like Super Mario. The main character moves from left to right, trying to get to the destination, where there are many obstacles and attacks from enemies in the process.}}\\\\n\\\\nIs anything else unclear? If yes, only answer in the form:\\\\n{remaining unclear areas} remaining questions.\\\\n{Next question}\\\\nIf everything is sufficiently clear, only answer \\\\&#34;Nothing more to clarify.\\\\&#34;.&#34;\\n  },\\n  {\\n    &#34;role&#34;: &#34;assistant&#34;,\\n    &#34;content&#34;: &#34;Remaining unclear areas: 2 remaining questions.\\\\nCan you provide more information about how the MVC components are split into separate files?&#34;\\n  },\\n  {\\n    &#34;role&#34;: &#34;user&#34;,\\n    &#34;content&#34;: &#34;{{Make your own assumptions and state them explicitly before starting}}&#34;\\n  }\\n]\\n</code></pre><p>Then after these clarification, the agent moved into the code writing mode with a different system message.\\nSystem message:</p>\\n<div class=\"prompt\">\\nYou will get instructions for code to write.\\nYou will write a very long answer. Make sure that every detail of the architecture is, in the end, implemented as code.\\nMake sure that every detail of the architecture is, in the end, implemented as code.\\n<p>Think step by step and reason yourself to the right decisions to make sure we get it right.\\nYou will first lay out the names of the core classes, functions, methods that will be necessary, as well as a quick comment on their purpose.</p>\\n<p>Then you will output the content of each file including ALL code.\\nEach file must strictly follow a markdown code block format, where the following tokens must be replaced such that\\nFILENAME is the lowercase file name including the file extension,\\nLANG is the markup code block language for the code&rsquo;s language, and CODE is the code:</p>\\n<p>FILENAME</p>\\n<pre tabindex=\"0\"><code class=\"language-LANG\" data-lang=\"LANG\">CODE\\n</code></pre><p>You will start with the &ldquo;entrypoint&rdquo; file, then go to the ones that are imported by that file, and so on.\\nPlease note that the code should be fully functional. No placeholders.</p>\\n<p>Follow a language and framework appropriate best practice file naming convention.\\nMake sure that files contain all imports, types etc. Make sure that code in different files are compatible with each other.\\nEnsure to implement all code, if you are unsure, write a plausible implementation.\\nInclude module dependency or package manager dependency definition file.\\nBefore you finish, double check that all parts of the architecture is present in the files.</p>\\n<p>Useful to know:\\nYou almost always put different classes in different files.\\nFor Python, you always create an appropriate requirements.txt file.\\nFor NodeJS, you always create an appropriate package.json file.\\nYou always add a comment briefly describing the purpose of the function definition.\\nYou try to add comments explaining very complex bits of logic.\\nYou always follow the best practices for the requested languages in terms of describing the code written as a defined\\npackage/project.</p>\\n<p>Python toolbelt preferences:</p>\\n<ul>\\n<li>pytest</li>\\n<li>dataclasses</li>\\n</ul>\\n</div>\\n<p>Conversatin samples:</p>\\n<pre tabindex=\"0\"><code>[\\n  {\\n    &#34;role&#34;: &#34;system&#34;,\\n    &#34;content&#34;: &#34;You will get instructions for code to write.\\\\nYou will write a very long answer. Make sure that every detail of the architecture is, in the end, implemented as code.\\\\nMake sure that every detail of the architecture is, in the end, implemented as code.\\\\n\\\\nThink step by step and reason yourself to the", "type": "Document"}], "answer": "To upload a PDF using LangChain, you can utilize the `PDFMinerLoader` or `PDFPlumberLoader`. Here\u2019s a brief overview of how to do it with each loader:\n\n### Using PDFMinerLoader\n1. **Install the required package**:\n   ```bash\n   pip install langchain_community\n   ```\n\n2. **Load the PDF**:\n   ```python\n   from langchain_community.document_loaders import PDFMinerLoader\n\n   file_path = \"./path_to_your_pdf/document.pdf\"\n   loader = PDFMinerLoader(file_path)\n   docs = loader.load()\n   ```\n\n### Using PDFPlumberLoader\n1. **Install the required package**:\n   ```bash\n   pip install langchain_community\n   ```\n\n2. **Load the PDF**:\n   ```python\n   from langchain_community.document_loaders import PDFPlumberLoader\n\n   loader = PDFPlumberLoader(\"./path_to_your_pdf/document.pdf\")\n   docs = loader.load()\n   ```\n\n### Notes\n- Both loaders will return a list of documents, where each document corresponds to a page in the PDF.\n- No special credentials are needed to use these loaders.\n\nFor more detailed information, you can refer to the API references for [PDFMinerLoader](https://python.langchain.com/api_reference/community/document_loaders/langchain_community.document_loaders.pdf.PDFMinerLoader.html) and [PDFPlumberLoader](https://python.langchain.com/api_reference/community/document_loaders/langchain_community.document_loaders.pdf.PDFPlumberLoader.html).", "query": "how do i upload a pdf"}}
{"messages": [[{"lc": 1, "type": "constructor", "id": ["langchain", "schema", "messages", "SystemMessage"], "kwargs": {"content": "You are a LangChain expert and a world-class researcher, here to assist with any and all questions or issues with LangChain, LangGraph, LangSmith, or any related functionality. Users may come to you with questions or issues.\n\nBased on the conversation below, generate a plan for how you will research the answer to their question.\n\nThe plan should generally not be more than 3 steps long, it can be as short as one. The length of the plan depends on the question.\n\nYou have access to the following documentation sources:\n- Conceptual docs\n- Integration docs\n- How-to guides\n\nYou do not need to specify where you want to research for all steps of the plan, but it's sometimes helpful.", "type": "system"}}, {"lc": 1, "type": "constructor", "id": ["langchain", "schema", "messages", "HumanMessage"], "kwargs": {"content": "how do i upload a pdf", "type": "human", "id": "acdae6e0-4fa7-459f-8906-67b9372aba8f"}}, {"lc": 1, "type": "constructor", "id": ["langchain", "schema", "messages", "AIMessage"], "kwargs": {"content": "To upload a PDF using LangChain, you can utilize the `PDFMinerLoader` or `PDFPlumberLoader`. Here\u2019s a brief overview of how to do it with each loader:\n\n### Using PDFMinerLoader\n1. **Install the required package**:\n   ```bash\n   pip install langchain_community\n   ```\n\n2. **Load the PDF**:\n   ```python\n   from langchain_community.document_loaders import PDFMinerLoader\n\n   file_path = \"./path_to_your_pdf/document.pdf\"\n   loader = PDFMinerLoader(file_path)\n   docs = loader.load()\n   ```\n\n### Using PDFPlumberLoader\n1. **Install the required package**:\n   ```bash\n   pip install langchain_community\n   ```\n\n2. **Load the PDF**:\n   ```python\n   from langchain_community.document_loaders import PDFPlumberLoader\n\n   loader = PDFPlumberLoader(\"./path_to_your_pdf/document.pdf\")\n   docs = loader.load()\n   ```\n\n### Notes\n- Both loaders will return a list of documents, where each document corresponds to a page in the PDF.\n- No special credentials are needed to use these loaders.\n\nFor more detailed information, you can refer to the API references for [PDFMinerLoader](https://python.langchain.com/api_reference/community/document_loaders/langchain_community.document_loaders.pdf.PDFMinerLoader.html) and [PDFPlumberLoader](https://python.langchain.com/api_reference/community/document_loaders/langchain_community.document_loaders.pdf.PDFPlumberLoader.html).", "response_metadata": {"finish_reason": "stop", "model_name": "gpt-4o-mini-2024-07-18", "system_fingerprint": "fp_0705bf87c0"}, "type": "ai", "id": "run-646bc662-d299-4ff8-9700-03482e843756", "tool_calls": [], "invalid_tool_calls": []}}, {"lc": 1, "type": "constructor", "id": ["langchain", "schema", "messages", "HumanMessage"], "kwargs": {"content": "https://www.cambridge.org/core/services/aop-cambridge-core/content/view/0D4357A9A6150E706CC261B86BA47733/S0008423923000793a.pdf/ascent_of_the_canadian_judicial_council_bill_c9_and_the_move_towards_judicialized_governance.pdf  can you open this to answer questions for me ", "type": "human", "id": "97919fe7-0599-486c-90d0-7355c6c587d1"}}]]}
{"input": {"messages": [{"content": "how do i upload a pdf", "additional_kwargs": {}, "response_metadata": {}, "type": "human", "id": "acdae6e0-4fa7-459f-8906-67b9372aba8f", "example": false}, {"content": "To upload a PDF using LangChain, you can utilize the `PDFMinerLoader` or `PDFPlumberLoader`. Here\u2019s a brief overview of how to do it with each loader:\n\n### Using PDFMinerLoader\n1. **Install the required package**:\n   ```bash\n   pip install langchain_community\n   ```\n\n2. **Load the PDF**:\n   ```python\n   from langchain_community.document_loaders import PDFMinerLoader\n\n   file_path = \"./path_to_your_pdf/document.pdf\"\n   loader = PDFMinerLoader(file_path)\n   docs = loader.load()\n   ```\n\n### Using PDFPlumberLoader\n1. **Install the required package**:\n   ```bash\n   pip install langchain_community\n   ```\n\n2. **Load the PDF**:\n   ```python\n   from langchain_community.document_loaders import PDFPlumberLoader\n\n   loader = PDFPlumberLoader(\"./path_to_your_pdf/document.pdf\")\n   docs = loader.load()\n   ```\n\n### Notes\n- Both loaders will return a list of documents, where each document corresponds to a page in the PDF.\n- No special credentials are needed to use these loaders.\n\nFor more detailed information, you can refer to the API references for [PDFMinerLoader](https://python.langchain.com/api_reference/community/document_loaders/langchain_community.document_loaders.pdf.PDFMinerLoader.html) and [PDFPlumberLoader](https://python.langchain.com/api_reference/community/document_loaders/langchain_community.document_loaders.pdf.PDFPlumberLoader.html).", "additional_kwargs": {}, "response_metadata": {"finish_reason": "stop", "model_name": "gpt-4o-mini-2024-07-18", "system_fingerprint": "fp_0705bf87c0"}, "type": "ai", "id": "run-646bc662-d299-4ff8-9700-03482e843756", "example": false, "tool_calls": [], "invalid_tool_calls": []}, {"content": "https://www.cambridge.org/core/services/aop-cambridge-core/content/view/0D4357A9A6150E706CC261B86BA47733/S0008423923000793a.pdf/ascent_of_the_canadian_judicial_council_bill_c9_and_the_move_towards_judicialized_governance.pdf  can you open this to answer questions for me ", "additional_kwargs": {}, "response_metadata": {}, "type": "human", "id": "97919fe7-0599-486c-90d0-7355c6c587d1", "example": false}], "router": {"type": "general", "logic": ""}, "steps": ["Access the provided PDF link to review its content.", "Extract key information and insights relevant to potential questions about the Canadian Judicial Council and Bill C-9.", "Prepare to answer specific questions based on the extracted information."], "documents": [], "answer": "To upload a PDF using LangChain, you can utilize the `PDFMinerLoader` or `PDFPlumberLoader`. Here\u2019s a brief overview of how to do it with each loader:\n\n### Using PDFMinerLoader\n1. **Install the required package**:\n   ```bash\n   pip install langchain_community\n   ```\n\n2. **Load the PDF**:\n   ```python\n   from langchain_community.document_loaders import PDFMinerLoader\n\n   file_path = \"./path_to_your_pdf/document.pdf\"\n   loader = PDFMinerLoader(file_path)\n   docs = loader.load()\n   ```\n\n### Using PDFPlumberLoader\n1. **Install the required package**:\n   ```bash\n   pip install langchain_community\n   ```\n\n2. **Load the PDF**:\n   ```python\n   from langchain_community.document_loaders import PDFPlumberLoader\n\n   loader = PDFPlumberLoader(\"./path_to_your_pdf/document.pdf\")\n   docs = loader.load()\n   ```\n\n### Notes\n- Both loaders will return a list of documents, where each document corresponds to a page in the PDF.\n- No special credentials are needed to use these loaders.\n\nFor more detailed information, you can refer to the API references for [PDFMinerLoader](https://python.langchain.com/api_reference/community/document_loaders/langchain_community.document_loaders.pdf.PDFMinerLoader.html) and [PDFPlumberLoader](https://python.langchain.com/api_reference/community/document_loaders/langchain_community.document_loaders.pdf.PDFPlumberLoader.html).", "query": "https://www.cambridge.org/core/services/aop-cambridge-core/content/view/0D4357A9A6150E706CC261B86BA47733/S0008423923000793a.pdf/ascent_of_the_canadian_judicial_council_bill_c9_and_the_move_towards_judicialized_governance.pdf  can you open this to answer questions for me "}}
{"messages": [[{"lc": 1, "type": "constructor", "id": ["langchain", "schema", "messages", "SystemMessage"], "kwargs": {"content": "Generate 3 search queries to search for to answer the user's question.\n\nThese search queries should be diverse in nature - do not generate repetitive ones.", "type": "system"}}, {"lc": 1, "type": "constructor", "id": ["langchain", "schema", "messages", "HumanMessage"], "kwargs": {"content": "Access the provided PDF link to review its content.", "type": "human"}}]]}
{"input": {"messages": [{"content": "how do i upload a pdf", "additional_kwargs": {}, "response_metadata": {}, "type": "human", "id": "acdae6e0-4fa7-459f-8906-67b9372aba8f", "example": false}, {"content": "To upload a PDF using LangChain, you can utilize the `PDFMinerLoader` or `PDFPlumberLoader`. Here\u2019s a brief overview of how to do it with each loader:\n\n### Using PDFMinerLoader\n1. **Install the required package**:\n   ```bash\n   pip install langchain_community\n   ```\n\n2. **Load the PDF**:\n   ```python\n   from langchain_community.document_loaders import PDFMinerLoader\n\n   file_path = \"./path_to_your_pdf/document.pdf\"\n   loader = PDFMinerLoader(file_path)\n   docs = loader.load()\n   ```\n\n### Using PDFPlumberLoader\n1. **Install the required package**:\n   ```bash\n   pip install langchain_community\n   ```\n\n2. **Load the PDF**:\n   ```python\n   from langchain_community.document_loaders import PDFPlumberLoader\n\n   loader = PDFPlumberLoader(\"./path_to_your_pdf/document.pdf\")\n   docs = loader.load()\n   ```\n\n### Notes\n- Both loaders will return a list of documents, where each document corresponds to a page in the PDF.\n- No special credentials are needed to use these loaders.\n\nFor more detailed information, you can refer to the API references for [PDFMinerLoader](https://python.langchain.com/api_reference/community/document_loaders/langchain_community.document_loaders.pdf.PDFMinerLoader.html) and [PDFPlumberLoader](https://python.langchain.com/api_reference/community/document_loaders/langchain_community.document_loaders.pdf.PDFPlumberLoader.html).", "additional_kwargs": {}, "response_metadata": {"finish_reason": "stop", "model_name": "gpt-4o-mini-2024-07-18", "system_fingerprint": "fp_0705bf87c0"}, "type": "ai", "id": "run-646bc662-d299-4ff8-9700-03482e843756", "example": false, "tool_calls": [], "invalid_tool_calls": []}, {"content": "https://www.cambridge.org/core/services/aop-cambridge-core/content/view/0D4357A9A6150E706CC261B86BA47733/S0008423923000793a.pdf/ascent_of_the_canadian_judicial_council_bill_c9_and_the_move_towards_judicialized_governance.pdf  can you open this to answer questions for me ", "additional_kwargs": {}, "response_metadata": {}, "type": "human", "id": "97919fe7-0599-486c-90d0-7355c6c587d1", "example": false}], "router": {"type": "general", "logic": ""}, "steps": ["Extract key information and insights relevant to potential questions about the Canadian Judicial Council and Bill C-9.", "Prepare to answer specific questions based on the extracted information."], "documents": [{"metadata": {"language": "en", "description": "Portable Document Format (PDF), standardized as ISO 32000, is a file format developed by Adobe in 1992 to present documents, including text formatting and images, in a manner independent of application software, hardware, and operating systems.", "changefreq": "weekly", "source": "https://python.langchain.com/docs/how_to/document_loader_pdf/", "title": "How to load PDFs | \ud83e\udd9c\ufe0f\ud83d\udd17 LangChain", "lastmod": null, "content_type": null, "priority": "0.5", "loc": "https://python.langchain.com/docs/how_to/document_loader_pdf/", "uuid": "a3f9bbc3-306a-5a26-94ac-f0fe755afbb7"}, "page_content": "How to load PDFs | \ud83e\udd9c\ufe0f\ud83d\udd17 LangChain\n\n[Skip to main content](#__docusaurus_skipToContent_fallback)# How to load PDFs\n\n[Portable Document Format (PDF)](https://en.wikipedia.org/wiki/PDF), standardized as ISO 32000, is a file format developed by Adobe in 1992 to present documents, including text formatting and images, in a manner independent of application software, hardware, and operating systems.\n\nThis guide covers how to [load](/docs/concepts/document_loaders/) `PDF` documents into the LangChain [Document](https://python.langchain.com/api_reference/core/documents/langchain_core.documents.base.Document.html) format that we use downstream.\n\nText in PDFs is typically represented via text boxes. They may also contain images. A PDF parser might do some combination of the following:\n\n- Agglomerate text boxes into lines, paragraphs, and other structures via heuristics or ML inference;\n\n- Run [OCR](https://en.wikipedia.org/wiki/Optical_character_recognition) on images to detect text therein;\n\n- Classify text as belonging to paragraphs, lists, tables, or other structures;\n\n- Structure text into table rows and columns, or key-value pairs.\n\nLangChain integrates with a host of PDF parsers. Some are simple and relatively low-level; others will support OCR and image-processing, or perform advanced document layout analysis. The right choice will depend on your needs. Below we enumerate the possibilities.\n\nWe will demonstrate these approaches on a [sample file](https://github.com/langchain-ai/langchain/blob/master/libs/community/tests/integration_tests/examples/layout-parser-paper.pdf):\n\n```python\nfile_path = (\n    \"../../docs/integrations/document_loaders/example_data/layout-parser-paper.pdf\"\n)\n```\n\nA note on multimodal modelsMany modern LLMs support inference over multimodal inputs (e.g., images). In some applications -- such as question-answering over PDFs with complex layouts, diagrams, or scans -- it may be advantageous to skip the PDF parsing, instead casting a PDF page to an image and passing it to a model directly. We demonstrate an example of this in the [Use of multimodal models](/docs/how_to/document_loader_pdf/#use-of-multimodal-models) section below.\n\n## Simple and fast text extraction\u200b\n\nIf you are looking for a simple string representation of text that is embedded in a PDF, the method below is appropriate. It will return a list of [Document](https://python.langchain.com/api_reference/core/documents/langchain_core.documents.base.Document.html) objects-- one per page-- containing a single string of the page's text in the Document's `page_content` attribute. It will not parse text in images or scanned PDF pages. Under the hood it uses the [pypdf](https://pypdf.readthedocs.io/en/stable/) Python library.\n\nLangChain [document loaders](/docs/concepts/document_loaders/) implement `lazy_load` and its async variant, `alazy_load`, which return iterators of `Document` objects. We will use these below.\n\n```python\n%pip install -qU pypdf\n```\n\n```python\nfrom langchain_community.document_loaders import PyPDFLoader\n\nloader = PyPDFLoader(file_path)\npages = []\nasync for page in loader.alazy_load():\n    pages.append(page)\n```\n\n**API Reference:**[PyPDFLoader](https://python.langchain.com/api_reference/community/document_loaders/langchain_community.document_loaders.pdf.PyPDFLoader.html)\n```python\nprint(f\"{pages[0].metadata}\\n\")\nprint(pages[0].page_content)\n```\n\n```output\n{'source': '../../docs/integrations/document_loaders/example_data/layout-parser-paper.pdf', 'page': 0}", "type": "Document"}, {"metadata": {"description": "Overview", "language": "en", "changefreq": "weekly", "source": "https://python.langchain.com/docs/integrations/document_loaders/unstructured_pdfloader/", "title": "UnstructuredPDFLoader | \ud83e\udd9c\ufe0f\ud83d\udd17 LangChain", "lastmod": null, "content_type": null, "priority": "0.5", "loc": "https://python.langchain.com/docs/integrations/document_loaders/unstructured_pdfloader/", "uuid": "8e7d3de8-e7e7-5cc2-bee5-618901e9e15f"}, "page_content": "**API Reference:**[OnlinePDFLoader](https://python.langchain.com/api_reference/community/document_loaders/langchain_community.document_loaders.pdf.OnlinePDFLoader.html)\n```output", "type": "Document"}, {"metadata": {"description": "Overview", "language": "en", "changefreq": "weekly", "source": "https://python.langchain.com/docs/integrations/document_loaders/unstructured_pdfloader/", "title": "UnstructuredPDFLoader | \ud83e\udd9c\ufe0f\ud83d\udd17 LangChain", "lastmod": null, "content_type": null, "priority": "0.5", "loc": "https://python.langchain.com/docs/integrations/document_loaders/unstructured_pdfloader/", "uuid": "f896de9c-6074-587c-8ebd-21697b8fcf4e"}, "page_content": "```python\nprint(docs[0].metadata)\n```\n\n```output\n{'source': './example_data/layout-parser-paper.pdf'}\n```\n\n### Retain Elements\u200b\n\nUnder the hood, Unstructured creates different \"elements\" for different chunks of text. By default we combine those together, but you can easily keep that separation by specifying `mode=\"elements\"`.\n\n```python\nfile_path = \"./example_data/layout-parser-paper.pdf\"\nloader = UnstructuredPDFLoader(file_path, mode=\"elements\")\n\ndata = loader.load()\ndata[0]\n```\n\n```output\nDocument(metadata={'source': './example_data/layout-parser-paper.pdf', 'coordinates': {'points': ((16.34, 213.36), (16.34, 253.36), (36.34, 253.36), (36.34, 213.36)), 'system': 'PixelSpace', 'layout_width': 612, 'layout_height': 792}, 'file_directory': './example_data', 'filename': 'layout-parser-paper.pdf', 'languages': ['eng'], 'last_modified': '2024-07-25T21:28:58', 'page_number': 1, 'filetype': 'application/pdf', 'category': 'UncategorizedText', 'element_id': 'd3ce55f220dfb75891b4394a18bcb973'}, page_content='1 2 0 2')\n```\n\nSee the full set of element types for this particular document:\n\n```python\nset(doc.metadata[\"category\"] for doc in data)\n```\n\n```output\n{'ListItem', 'NarrativeText', 'Title', 'UncategorizedText'}\n```\n\n### Fetching remote PDFs using Unstructured\u200b\n\nThis covers how to load online PDFs into a document format that we can use downstream. This can be used for various online PDF sites such as [https://open.umn.edu/opentextbooks/textbooks/](https://open.umn.edu/opentextbooks/textbooks/) and [https://arxiv.org/archive/](https://arxiv.org/archive/)\n\nNote: all other PDF loaders can also be used to fetch remote PDFs, but `OnlinePDFLoader` is a legacy function, and works specifically with `UnstructuredPDFLoader`.\n\n```python\nfrom langchain_community.document_loaders import OnlinePDFLoader\n\nloader = OnlinePDFLoader(\"https://arxiv.org/pdf/2302.03803.pdf\")\ndata = loader.load()\ndata[0]\n```", "type": "Document"}, {"metadata": {"language": "en", "description": "DocumentLoaders load data into the standard LangChain Document format.", "changefreq": "weekly", "source": "https://python.langchain.com/docs/integrations/document_loaders/", "title": "Document loaders | \ud83e\udd9c\ufe0f\ud83d\udd17 LangChain", "content_type": null, "lastmod": null, "priority": "0.5", "loc": "https://python.langchain.com/docs/integrations/document_loaders/", "uuid": "cbcffc89-a3d2-5630-9fc5-b89ee88d3d68"}, "page_content": "#### Was this page helpful?\n\n- [Webpages](#webpages)\n\n- [PDFs](#pdfs)\n\n- [Cloud Providers](#cloud-providers)\n\n- [Social Platforms](#social-platforms)\n\n- [Messaging Services](#messaging-services)\n\n- [Productivity tools](#productivity-tools)\n\n- [Common File Types](#common-file-types)\n\n- [All document loaders](#all-document-loaders)", "type": "Document"}, {"metadata": {"description": "Overview", "language": "en", "changefreq": "weekly", "source": "https://python.langchain.com/docs/integrations/document_loaders/pdfminer/", "title": "PDFMiner | \ud83e\udd9c\ufe0f\ud83d\udd17 LangChain", "content_type": null, "lastmod": null, "priority": "0.5", "loc": "https://python.langchain.com/docs/integrations/document_loaders/pdfminer/", "uuid": "85d9d38c-a640-5f59-b00d-5ff43f93ac91"}, "page_content": "5 shows two examples of how\\n<br></span><span style=\"font-family: CMTT10; font-size:9px\">LayoutParser </span><span style=\"font-family: CMR10; font-size:9px\">can be used in practical DIA projects, and Section 6 concludes.\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:134px; top:1990px; width:102px; height:11px;\"><span style=\"font-family: CMBX12; font-size:11px\">2 Related Work\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:134px; top:2016px; width:347px; height:81px;\"><span style=\"font-family: CMR10; font-size:9px\">Recently, various DL models and datasets have been developed for layout analysis\\n<br>tasks. The dhSegment [22] utilizes fully convolutional networks [20] for segmen-\\n<br>tation tasks on historical documents. Object detection-based methods like Faster\\n<br>R-CNN [28] and Mask R-CNN [12] are used for identifying document elements [38]\\n<br>and detecting tables [30, 26]. Most recently, Graph Neural Networks [29] have also\\n<br>been used in table detection [27]. However, these models are usually implemented\\n<br>individually and there is no uni\ufb01ed framework to load and use such models.\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:134px; top:2100px; width:348px; height:189px;\"><span style=\"font-family: CMR10; font-size:9px\">There has been a surge of interest in creating open-source tools for document\\n<br>image processing: a search of </span><span style=\"font-family: CMTT10; font-size:9px\">document image analysis </span><span style=\"font-family: CMR10; font-size:9px\">in Github leads to 5M\\n<br>relevant code pieces </span><span style=\"font-family: CMR7; font-size:6px\">6</span><span style=\"font-family: CMR10; font-size:9px\">; yet most of them rely on traditional rule-based methods\\n<br>or provide limited functionalities. The closest prior research to our work is the\\n<br>OCR-D project</span><span style=\"font-family: CMR7; font-size:6px\">7</span><span style=\"font-family: CMR10; font-size:9px\">, which also tries to build a complete toolkit for DIA. However,\\n<br>similar to the platform developed by Neudecker et al. [21], it is designed for\\n<br>analyzing historical documents, and provides no supports for recent DL models.\\n<br>The </span><span style=\"font-family: CMTT10; font-size:9px\">DocumentLayoutAnalysis </span><span style=\"font-family: CMR10; font-size:9px\">project</span><span style=\"font-family: CMR7; font-size:6px\">8 </span><span style=\"font-family: CMR10; font-size:9px\">focuses on processing born-digital PDF\\n<br>documents via analyzing the stored PDF data. Repositories like </span><span style=\"font-family: CMTT10; font-size:9px\">DeepLayout</span><span style=\"font-family: CMR7; font-size:6px\">9\\n<br></span><span style=\"font-family: CMR10; font-size:9px\">and </span><span style=\"font-family: CMTT10; font-size:9px\">Detectron2-PubLayNet</span><span style=\"font-family: CMR7; font-size:6px\">10 </span><span style=\"font-family: CMR10; font-size:9px\">are individual deep learning models trained on\\n<br>layout analysis datasets without support for the full DIA pipeline. The Document\\n<br>Analysis and Exploitation (DAE) platform [15] and the DeepDIVA project [2]\\n<br>aim to improve the reproducibility of DIA methods (or DL models), yet they\\n<br>are not actively maintained. OCR engines like </span><span style=\"font-family: CMTT10; font-size:9px\">Tesseract </span><span style=\"font-family: CMR10; font-size:9px\">[14], </span><span style=\"font-family: CMTT10; font-size:9px\">easyOCR</span><span style=\"font-family: CMR7; font-size:6px\">11 </span><span style=\"font-family: CMR10; font-size:9px\">and\\n<br></span><span style=\"font-family: CMTT10; font-size:9px\">paddleOCR</span><span style=\"font-family: CMR7; font-size:6px\">12 </span><span style=\"font-family: CMR10; font-size:9px\">usually do not come with comprehensive functionalities for other\\n<br>DIA tasks like layout", "type": "Document"}, {"metadata": {"description": "Overview", "language": "en", "changefreq": "weekly", "source": "https://python.langchain.com/docs/integrations/document_loaders/pdfminer/", "title": "PDFMiner | \ud83e\udd9c\ufe0f\ud83d\udd17 LangChain", "lastmod": null, "content_type": null, "priority": "0.5", "loc": "https://python.langchain.com/docs/integrations/document_loaders/pdfminer/", "uuid": "c86c93ad-5ca1-59e1-8dfe-832cf69ffa35"}, "page_content": "CMR9; font-size:8px\">the maximum is 1.\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:133px; top:9955px; width:348px; height:10px;\"><span style=\"font-family: CMR6; font-size:5px\">17 </span><span style=\"font-family: CMR9; font-size:8px\">This measures the number of edits from the ground-truth text to the predicted text,\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:144px; top:9967px; width:78px; height:8px;\"><span style=\"font-family: CMR9; font-size:8px\">and lower is better.\\n<br></span></div><span style=\"position:absolute; border: black 1px solid; left:134px; top:9931px; width:56px; height:0px;\"></span>\\n<span style=\"position:absolute; border: gray 1px solid; left:0px; top:10154px; width:612px; height:792px;\"></span>\\n<div style=\"position:absolute; top:10154px;\"><a name=\"13\">Page 13</a></div>\\n<div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:237px; top:10246px; width:210px; height:9px;\"><span style=\"font-family: CMTT9; font-size:8px\">LayoutParser</span><span style=\"font-family: CMR9; font-size:8px\">: A Uni\ufb01ed Toolkit for DL-Based DIA\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:471px; top:10246px; width:9px; height:8px;\"><span style=\"font-family: CMR9; font-size:8px\">13\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:134px; top:10398px; width:346px; height:45px;\"><span style=\"font-family: CMR10; font-size:9px\">Fig. 6: This lightweight table detector can identify tables (outlined in red) and\\n<br>cells (shaded in blue) in di\ufb00erent locations on a page. In very few cases (d), it\\n<br>might generate minor error predictions, e.g, failing to capture the top text line of\\n<br></span><span style=\"font-family: CMR10; font-size:9px\">a table.\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:134px; top:10478px; width:216px; height:9px;\"><span style=\"font-family: CMBX10; font-size:9px\">5.2 A light-weight Visual Table Extractor\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:134px; top:10518px; width:347px; height:81px;\"><span style=\"font-family: CMR10; font-size:9px\">Detecting tables and parsing their structures (table extraction) are of central im-\\n<br>portance for many document digitization tasks. Many previous works [26, 30, 27]\\n<br>and tools </span><span style=\"font-family: CMR7; font-size:6px\">18 </span><span style=\"font-family: CMR10; font-size:9px\">have been developed to identify and parse table structures. Yet they\\n<br>might require training complicated models from scratch, or are only applicable\\n<br>for born-digital PDF documents. In this section, we show how </span><span style=\"font-family: CMTT10; font-size:9px\">LayoutParser </span><span style=\"font-family: CMR10; font-size:9px\">can\\n<br>help build a light-weight accurate visual table extractor for legal docket tables\\n<br>using the existing resources with minimal e\ufb00ort.\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:134px; top:10606px; width:347px; height:177px;\"><span style=\"font-family: CMR10; font-size:9px\">The extractor uses a pre-trained layout detection model for identifying the\\n<br>table regions and some simple rules for pairing the rows and the columns in the\\n<br>PDF image. Mask R-CNN [12] trained on the PubLayNet dataset [38] from the\\n<br></span><span style=\"font-family: CMTT10; font-size:9px\">LayoutParser </span><span style=\"font-family: CMR10; font-size:9px\">Model Zoo can be used for detecting table regions. By \ufb01ltering\\n<br>out model predictions of low con\ufb01dence and removing overlapping predictions,\\n<br></span><span style=\"font-family: CMTT10; font-size:9px\">LayoutParser </span><span style=\"font-family: CMR10; font-size:9px\">can identify the tabular", "type": "Document"}, {"metadata": {"description": "Portable Document Format (PDF), standardized as ISO 32000, is a file format developed by Adobe in 1992 to present documents, including text formatting and images, in a manner independent of application software, hardware, and operating systems.", "language": "en", "changefreq": "weekly", "source": "https://python.langchain.com/docs/how_to/document_loader_pdf/", "title": "How to load PDFs | \ud83e\udd9c\ufe0f\ud83d\udd17 LangChain", "content_type": null, "lastmod": null, "priority": "0.5", "loc": "https://python.langchain.com/docs/how_to/document_loader_pdf/", "uuid": "5a2a91d5-0d47-5a95-8791-d9a4adade490"}, "page_content": "```output\n{'source': '../../docs/integrations/document_loaders/example_data/layout-parser-paper.pdf', 'page': 0}\n\nLayoutParser : A Uni\ufb01ed Toolkit for Deep\nLearning Based Document Image Analysis\nZejiang Shen1( \ufffd), Ruochen Zhang2, Melissa Dell3, Benjamin Charles Germain\nLee4, Jacob Carlson3, and Weining Li5\n1Allen Institute for AI\nshannons@allenai.org\n2Brown University\nruochen zhang@brown.edu\n3Harvard University\n{melissadell,jacob carlson }@fas.harvard.edu\n4University of Washington\nbcgl@cs.washington.edu\n5University of Waterloo\nw422li@uwaterloo.ca\nAbstract. Recent advances in document image analysis (DIA) have been\nprimarily driven by the application of neural networks. Ideally, research\noutcomes could be easily deployed in production and extended for further\ninvestigation. However, various factors like loosely organized codebases\nand sophisticated model con\ufb01gurations complicate the easy reuse of im-\nportant innovations by a wide audience. Though there have been on-going\ne\ufb00orts to improve reusability and simplify deep learning (DL) model\ndevelopment in disciplines like natural language processing and computer\nvision, none of them are optimized for challenges in the domain of DIA.\nThis represents a major gap in the existing toolkit, as DIA is central to\nacademic research across a wide range of disciplines in the social sciences\nand humanities. This paper introduces LayoutParser , an open-source\nlibrary for streamlining the usage of DL in DIA research and applica-\ntions. The core LayoutParser library comes with a set of simple and\nintuitive interfaces for applying and customizing DL models for layout de-\ntection, character recognition, and many other document processing tasks.\nTo promote extensibility, LayoutParser also incorporates a community\nplatform for sharing both pre-trained models and full document digiti-\nzation pipelines. We demonstrate that LayoutParser is helpful for both\nlightweight and large-scale digitization pipelines in real-word use cases.\nThe library is publicly available at https://layout-parser.github.io .\nKeywords: Document Image Analysis \u00b7Deep Learning \u00b7Layout Analysis\n\u00b7Character Recognition \u00b7Open Source library \u00b7Toolkit.\n1 Introduction\nDeep Learning(DL)-based approaches are the state-of-the-art for a wide range of\ndocument image analysis (DIA) tasks including document image classi\ufb01cation [ 11,arXiv:2103.15348v2  [cs.CV]  21 Jun 2021\n```\n\nNote that the metadata of each document stores the corresponding page number.\n\n### Vector search over PDFs\u200b\n\nOnce we have loaded PDFs into LangChain `Document` objects, we can index them (e.g., a RAG application) in the usual way. Below we use OpenAI embeddings, although any LangChain [embeddings](https://python.langchain.com/docs/concepts/embedding_models) model will suffice.\n\n```python\n%pip install -qU langchain-openai\n```\n\n```python\nimport getpass\nimport os\n\nif \"OPENAI_API_KEY\" not in os.environ:\n    os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"OpenAI API Key:\")\n```\n\n```python\nfrom langchain_core.vectorstores import InMemoryVectorStore\nfrom langchain_openai import OpenAIEmbeddings\n\nvector_store = InMemoryVectorStore.from_documents(pages, OpenAIEmbeddings())\ndocs = vector_store.similarity_search(\"What is LayoutParser?\", k=2)\nfor doc in docs:\n    print(f'Page {doc.metadata[\"page\"]}: {doc.page_content[:300]}\\n')\n```\n\n**API Reference:**[InMemoryVectorStore](https://python.langchain.com/api_reference/core/vectorstores/langchain_core.vectorstores.in_memory.InMemoryVectorStore.html) | [OpenAIEmbeddings](https://python.langchain.com/api_reference/openai/embeddings/langchain_openai.embeddings.base.OpenAIEmbeddings.html)\n```output\nPage 13: 14 Z. Shen et al.\n6 Conclusion\nLayoutParser provides a comprehensive toolkit for deep learning-based document\nimage analysis. The o\ufb00-the-shelf library is easy to install, and can be used to\nbuild \ufb02exible and accurate pipelines for processing documents with complicated\nstructures. It also supports hi", "type": "Document"}], "answer": "To upload a PDF using LangChain, you can utilize the `PDFMinerLoader` or `PDFPlumberLoader`. Here\u2019s a brief overview of how to do it with each loader:\n\n### Using PDFMinerLoader\n1. **Install the required package**:\n   ```bash\n   pip install langchain_community\n   ```\n\n2. **Load the PDF**:\n   ```python\n   from langchain_community.document_loaders import PDFMinerLoader\n\n   file_path = \"./path_to_your_pdf/document.pdf\"\n   loader = PDFMinerLoader(file_path)\n   docs = loader.load()\n   ```\n\n### Using PDFPlumberLoader\n1. **Install the required package**:\n   ```bash\n   pip install langchain_community\n   ```\n\n2. **Load the PDF**:\n   ```python\n   from langchain_community.document_loaders import PDFPlumberLoader\n\n   loader = PDFPlumberLoader(\"./path_to_your_pdf/document.pdf\")\n   docs = loader.load()\n   ```\n\n### Notes\n- Both loaders will return a list of documents, where each document corresponds to a page in the PDF.\n- No special credentials are needed to use these loaders.\n\nFor more detailed information, you can refer to the API references for [PDFMinerLoader](https://python.langchain.com/api_reference/community/document_loaders/langchain_community.document_loaders.pdf.PDFMinerLoader.html) and [PDFPlumberLoader](https://python.langchain.com/api_reference/community/document_loaders/langchain_community.document_loaders.pdf.PDFPlumberLoader.html).", "query": "https://www.cambridge.org/core/services/aop-cambridge-core/content/view/0D4357A9A6150E706CC261B86BA47733/S0008423923000793a.pdf/ascent_of_the_canadian_judicial_council_bill_c9_and_the_move_towards_judicialized_governance.pdf  can you open this to answer questions for me "}}
{"messages": [[{"lc": 1, "type": "constructor", "id": ["langchain", "schema", "messages", "SystemMessage"], "kwargs": {"content": "Generate 3 search queries to search for to answer the user's question.\n\nThese search queries should be diverse in nature - do not generate repetitive ones.", "type": "system"}}, {"lc": 1, "type": "constructor", "id": ["langchain", "schema", "messages", "HumanMessage"], "kwargs": {"content": "Extract key information and insights relevant to potential questions about the Canadian Judicial Council and Bill C-9.", "type": "human"}}]]}
{"input": {"messages": [{"content": "how do i upload a pdf", "additional_kwargs": {}, "response_metadata": {}, "type": "human", "id": "acdae6e0-4fa7-459f-8906-67b9372aba8f", "example": false}, {"content": "To upload a PDF using LangChain, you can utilize the `PDFMinerLoader` or `PDFPlumberLoader`. Here\u2019s a brief overview of how to do it with each loader:\n\n### Using PDFMinerLoader\n1. **Install the required package**:\n   ```bash\n   pip install langchain_community\n   ```\n\n2. **Load the PDF**:\n   ```python\n   from langchain_community.document_loaders import PDFMinerLoader\n\n   file_path = \"./path_to_your_pdf/document.pdf\"\n   loader = PDFMinerLoader(file_path)\n   docs = loader.load()\n   ```\n\n### Using PDFPlumberLoader\n1. **Install the required package**:\n   ```bash\n   pip install langchain_community\n   ```\n\n2. **Load the PDF**:\n   ```python\n   from langchain_community.document_loaders import PDFPlumberLoader\n\n   loader = PDFPlumberLoader(\"./path_to_your_pdf/document.pdf\")\n   docs = loader.load()\n   ```\n\n### Notes\n- Both loaders will return a list of documents, where each document corresponds to a page in the PDF.\n- No special credentials are needed to use these loaders.\n\nFor more detailed information, you can refer to the API references for [PDFMinerLoader](https://python.langchain.com/api_reference/community/document_loaders/langchain_community.document_loaders.pdf.PDFMinerLoader.html) and [PDFPlumberLoader](https://python.langchain.com/api_reference/community/document_loaders/langchain_community.document_loaders.pdf.PDFPlumberLoader.html).", "additional_kwargs": {}, "response_metadata": {"finish_reason": "stop", "model_name": "gpt-4o-mini-2024-07-18", "system_fingerprint": "fp_0705bf87c0"}, "type": "ai", "id": "run-646bc662-d299-4ff8-9700-03482e843756", "example": false, "tool_calls": [], "invalid_tool_calls": []}, {"content": "https://www.cambridge.org/core/services/aop-cambridge-core/content/view/0D4357A9A6150E706CC261B86BA47733/S0008423923000793a.pdf/ascent_of_the_canadian_judicial_council_bill_c9_and_the_move_towards_judicialized_governance.pdf  can you open this to answer questions for me ", "additional_kwargs": {}, "response_metadata": {}, "type": "human", "id": "97919fe7-0599-486c-90d0-7355c6c587d1", "example": false}], "router": {"type": "general", "logic": ""}, "steps": ["Prepare to answer specific questions based on the extracted information."], "documents": [{"metadata": {"language": "en", "description": "Portable Document Format (PDF), standardized as ISO 32000, is a file format developed by Adobe in 1992 to present documents, including text formatting and images, in a manner independent of application software, hardware, and operating systems.", "changefreq": "weekly", "source": "https://python.langchain.com/docs/how_to/document_loader_pdf/", "title": "How to load PDFs | \ud83e\udd9c\ufe0f\ud83d\udd17 LangChain", "lastmod": null, "content_type": null, "priority": "0.5", "loc": "https://python.langchain.com/docs/how_to/document_loader_pdf/", "uuid": "a3f9bbc3-306a-5a26-94ac-f0fe755afbb7"}, "page_content": "How to load PDFs | \ud83e\udd9c\ufe0f\ud83d\udd17 LangChain\n\n[Skip to main content](#__docusaurus_skipToContent_fallback)# How to load PDFs\n\n[Portable Document Format (PDF)](https://en.wikipedia.org/wiki/PDF), standardized as ISO 32000, is a file format developed by Adobe in 1992 to present documents, including text formatting and images, in a manner independent of application software, hardware, and operating systems.\n\nThis guide covers how to [load](/docs/concepts/document_loaders/) `PDF` documents into the LangChain [Document](https://python.langchain.com/api_reference/core/documents/langchain_core.documents.base.Document.html) format that we use downstream.\n\nText in PDFs is typically represented via text boxes. They may also contain images. A PDF parser might do some combination of the following:\n\n- Agglomerate text boxes into lines, paragraphs, and other structures via heuristics or ML inference;\n\n- Run [OCR](https://en.wikipedia.org/wiki/Optical_character_recognition) on images to detect text therein;\n\n- Classify text as belonging to paragraphs, lists, tables, or other structures;\n\n- Structure text into table rows and columns, or key-value pairs.\n\nLangChain integrates with a host of PDF parsers. Some are simple and relatively low-level; others will support OCR and image-processing, or perform advanced document layout analysis. The right choice will depend on your needs. Below we enumerate the possibilities.\n\nWe will demonstrate these approaches on a [sample file](https://github.com/langchain-ai/langchain/blob/master/libs/community/tests/integration_tests/examples/layout-parser-paper.pdf):\n\n```python\nfile_path = (\n    \"../../docs/integrations/document_loaders/example_data/layout-parser-paper.pdf\"\n)\n```\n\nA note on multimodal modelsMany modern LLMs support inference over multimodal inputs (e.g., images). In some applications -- such as question-answering over PDFs with complex layouts, diagrams, or scans -- it may be advantageous to skip the PDF parsing, instead casting a PDF page to an image and passing it to a model directly. We demonstrate an example of this in the [Use of multimodal models](/docs/how_to/document_loader_pdf/#use-of-multimodal-models) section below.\n\n## Simple and fast text extraction\u200b\n\nIf you are looking for a simple string representation of text that is embedded in a PDF, the method below is appropriate. It will return a list of [Document](https://python.langchain.com/api_reference/core/documents/langchain_core.documents.base.Document.html) objects-- one per page-- containing a single string of the page's text in the Document's `page_content` attribute. It will not parse text in images or scanned PDF pages. Under the hood it uses the [pypdf](https://pypdf.readthedocs.io/en/stable/) Python library.\n\nLangChain [document loaders](/docs/concepts/document_loaders/) implement `lazy_load` and its async variant, `alazy_load`, which return iterators of `Document` objects. We will use these below.\n\n```python\n%pip install -qU pypdf\n```\n\n```python\nfrom langchain_community.document_loaders import PyPDFLoader\n\nloader = PyPDFLoader(file_path)\npages = []\nasync for page in loader.alazy_load():\n    pages.append(page)\n```\n\n**API Reference:**[PyPDFLoader](https://python.langchain.com/api_reference/community/document_loaders/langchain_community.document_loaders.pdf.PyPDFLoader.html)\n```python\nprint(f\"{pages[0].metadata}\\n\")\nprint(pages[0].page_content)\n```\n\n```output\n{'source': '../../docs/integrations/document_loaders/example_data/layout-parser-paper.pdf', 'page': 0}", "type": "Document"}, {"metadata": {"description": "Overview", "language": "en", "changefreq": "weekly", "source": "https://python.langchain.com/docs/integrations/document_loaders/unstructured_pdfloader/", "title": "UnstructuredPDFLoader | \ud83e\udd9c\ufe0f\ud83d\udd17 LangChain", "lastmod": null, "content_type": null, "priority": "0.5", "loc": "https://python.langchain.com/docs/integrations/document_loaders/unstructured_pdfloader/", "uuid": "8e7d3de8-e7e7-5cc2-bee5-618901e9e15f"}, "page_content": "**API Reference:**[OnlinePDFLoader](https://python.langchain.com/api_reference/community/document_loaders/langchain_community.document_loaders.pdf.OnlinePDFLoader.html)\n```output", "type": "Document"}, {"metadata": {"description": "Overview", "language": "en", "changefreq": "weekly", "source": "https://python.langchain.com/docs/integrations/document_loaders/unstructured_pdfloader/", "title": "UnstructuredPDFLoader | \ud83e\udd9c\ufe0f\ud83d\udd17 LangChain", "lastmod": null, "content_type": null, "priority": "0.5", "loc": "https://python.langchain.com/docs/integrations/document_loaders/unstructured_pdfloader/", "uuid": "f896de9c-6074-587c-8ebd-21697b8fcf4e"}, "page_content": "```python\nprint(docs[0].metadata)\n```\n\n```output\n{'source': './example_data/layout-parser-paper.pdf'}\n```\n\n### Retain Elements\u200b\n\nUnder the hood, Unstructured creates different \"elements\" for different chunks of text. By default we combine those together, but you can easily keep that separation by specifying `mode=\"elements\"`.\n\n```python\nfile_path = \"./example_data/layout-parser-paper.pdf\"\nloader = UnstructuredPDFLoader(file_path, mode=\"elements\")\n\ndata = loader.load()\ndata[0]\n```\n\n```output\nDocument(metadata={'source': './example_data/layout-parser-paper.pdf', 'coordinates': {'points': ((16.34, 213.36), (16.34, 253.36), (36.34, 253.36), (36.34, 213.36)), 'system': 'PixelSpace', 'layout_width': 612, 'layout_height': 792}, 'file_directory': './example_data', 'filename': 'layout-parser-paper.pdf', 'languages': ['eng'], 'last_modified': '2024-07-25T21:28:58', 'page_number': 1, 'filetype': 'application/pdf', 'category': 'UncategorizedText', 'element_id': 'd3ce55f220dfb75891b4394a18bcb973'}, page_content='1 2 0 2')\n```\n\nSee the full set of element types for this particular document:\n\n```python\nset(doc.metadata[\"category\"] for doc in data)\n```\n\n```output\n{'ListItem', 'NarrativeText', 'Title', 'UncategorizedText'}\n```\n\n### Fetching remote PDFs using Unstructured\u200b\n\nThis covers how to load online PDFs into a document format that we can use downstream. This can be used for various online PDF sites such as [https://open.umn.edu/opentextbooks/textbooks/](https://open.umn.edu/opentextbooks/textbooks/) and [https://arxiv.org/archive/](https://arxiv.org/archive/)\n\nNote: all other PDF loaders can also be used to fetch remote PDFs, but `OnlinePDFLoader` is a legacy function, and works specifically with `UnstructuredPDFLoader`.\n\n```python\nfrom langchain_community.document_loaders import OnlinePDFLoader\n\nloader = OnlinePDFLoader(\"https://arxiv.org/pdf/2302.03803.pdf\")\ndata = loader.load()\ndata[0]\n```", "type": "Document"}, {"metadata": {"language": "en", "description": "DocumentLoaders load data into the standard LangChain Document format.", "changefreq": "weekly", "source": "https://python.langchain.com/docs/integrations/document_loaders/", "title": "Document loaders | \ud83e\udd9c\ufe0f\ud83d\udd17 LangChain", "content_type": null, "lastmod": null, "priority": "0.5", "loc": "https://python.langchain.com/docs/integrations/document_loaders/", "uuid": "cbcffc89-a3d2-5630-9fc5-b89ee88d3d68"}, "page_content": "#### Was this page helpful?\n\n- [Webpages](#webpages)\n\n- [PDFs](#pdfs)\n\n- [Cloud Providers](#cloud-providers)\n\n- [Social Platforms](#social-platforms)\n\n- [Messaging Services](#messaging-services)\n\n- [Productivity tools](#productivity-tools)\n\n- [Common File Types](#common-file-types)\n\n- [All document loaders](#all-document-loaders)", "type": "Document"}, {"metadata": {"description": "Overview", "language": "en", "changefreq": "weekly", "source": "https://python.langchain.com/docs/integrations/document_loaders/pdfminer/", "title": "PDFMiner | \ud83e\udd9c\ufe0f\ud83d\udd17 LangChain", "content_type": null, "lastmod": null, "priority": "0.5", "loc": "https://python.langchain.com/docs/integrations/document_loaders/pdfminer/", "uuid": "85d9d38c-a640-5f59-b00d-5ff43f93ac91"}, "page_content": "5 shows two examples of how\\n<br></span><span style=\"font-family: CMTT10; font-size:9px\">LayoutParser </span><span style=\"font-family: CMR10; font-size:9px\">can be used in practical DIA projects, and Section 6 concludes.\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:134px; top:1990px; width:102px; height:11px;\"><span style=\"font-family: CMBX12; font-size:11px\">2 Related Work\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:134px; top:2016px; width:347px; height:81px;\"><span style=\"font-family: CMR10; font-size:9px\">Recently, various DL models and datasets have been developed for layout analysis\\n<br>tasks. The dhSegment [22] utilizes fully convolutional networks [20] for segmen-\\n<br>tation tasks on historical documents. Object detection-based methods like Faster\\n<br>R-CNN [28] and Mask R-CNN [12] are used for identifying document elements [38]\\n<br>and detecting tables [30, 26]. Most recently, Graph Neural Networks [29] have also\\n<br>been used in table detection [27]. However, these models are usually implemented\\n<br>individually and there is no uni\ufb01ed framework to load and use such models.\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:134px; top:2100px; width:348px; height:189px;\"><span style=\"font-family: CMR10; font-size:9px\">There has been a surge of interest in creating open-source tools for document\\n<br>image processing: a search of </span><span style=\"font-family: CMTT10; font-size:9px\">document image analysis </span><span style=\"font-family: CMR10; font-size:9px\">in Github leads to 5M\\n<br>relevant code pieces </span><span style=\"font-family: CMR7; font-size:6px\">6</span><span style=\"font-family: CMR10; font-size:9px\">; yet most of them rely on traditional rule-based methods\\n<br>or provide limited functionalities. The closest prior research to our work is the\\n<br>OCR-D project</span><span style=\"font-family: CMR7; font-size:6px\">7</span><span style=\"font-family: CMR10; font-size:9px\">, which also tries to build a complete toolkit for DIA. However,\\n<br>similar to the platform developed by Neudecker et al. [21], it is designed for\\n<br>analyzing historical documents, and provides no supports for recent DL models.\\n<br>The </span><span style=\"font-family: CMTT10; font-size:9px\">DocumentLayoutAnalysis </span><span style=\"font-family: CMR10; font-size:9px\">project</span><span style=\"font-family: CMR7; font-size:6px\">8 </span><span style=\"font-family: CMR10; font-size:9px\">focuses on processing born-digital PDF\\n<br>documents via analyzing the stored PDF data. Repositories like </span><span style=\"font-family: CMTT10; font-size:9px\">DeepLayout</span><span style=\"font-family: CMR7; font-size:6px\">9\\n<br></span><span style=\"font-family: CMR10; font-size:9px\">and </span><span style=\"font-family: CMTT10; font-size:9px\">Detectron2-PubLayNet</span><span style=\"font-family: CMR7; font-size:6px\">10 </span><span style=\"font-family: CMR10; font-size:9px\">are individual deep learning models trained on\\n<br>layout analysis datasets without support for the full DIA pipeline. The Document\\n<br>Analysis and Exploitation (DAE) platform [15] and the DeepDIVA project [2]\\n<br>aim to improve the reproducibility of DIA methods (or DL models), yet they\\n<br>are not actively maintained. OCR engines like </span><span style=\"font-family: CMTT10; font-size:9px\">Tesseract </span><span style=\"font-family: CMR10; font-size:9px\">[14], </span><span style=\"font-family: CMTT10; font-size:9px\">easyOCR</span><span style=\"font-family: CMR7; font-size:6px\">11 </span><span style=\"font-family: CMR10; font-size:9px\">and\\n<br></span><span style=\"font-family: CMTT10; font-size:9px\">paddleOCR</span><span style=\"font-family: CMR7; font-size:6px\">12 </span><span style=\"font-family: CMR10; font-size:9px\">usually do not come with comprehensive functionalities for other\\n<br>DIA tasks like layout", "type": "Document"}, {"metadata": {"description": "Overview", "language": "en", "changefreq": "weekly", "source": "https://python.langchain.com/docs/integrations/document_loaders/pdfminer/", "title": "PDFMiner | \ud83e\udd9c\ufe0f\ud83d\udd17 LangChain", "lastmod": null, "content_type": null, "priority": "0.5", "loc": "https://python.langchain.com/docs/integrations/document_loaders/pdfminer/", "uuid": "c86c93ad-5ca1-59e1-8dfe-832cf69ffa35"}, "page_content": "CMR9; font-size:8px\">the maximum is 1.\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:133px; top:9955px; width:348px; height:10px;\"><span style=\"font-family: CMR6; font-size:5px\">17 </span><span style=\"font-family: CMR9; font-size:8px\">This measures the number of edits from the ground-truth text to the predicted text,\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:144px; top:9967px; width:78px; height:8px;\"><span style=\"font-family: CMR9; font-size:8px\">and lower is better.\\n<br></span></div><span style=\"position:absolute; border: black 1px solid; left:134px; top:9931px; width:56px; height:0px;\"></span>\\n<span style=\"position:absolute; border: gray 1px solid; left:0px; top:10154px; width:612px; height:792px;\"></span>\\n<div style=\"position:absolute; top:10154px;\"><a name=\"13\">Page 13</a></div>\\n<div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:237px; top:10246px; width:210px; height:9px;\"><span style=\"font-family: CMTT9; font-size:8px\">LayoutParser</span><span style=\"font-family: CMR9; font-size:8px\">: A Uni\ufb01ed Toolkit for DL-Based DIA\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:471px; top:10246px; width:9px; height:8px;\"><span style=\"font-family: CMR9; font-size:8px\">13\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:134px; top:10398px; width:346px; height:45px;\"><span style=\"font-family: CMR10; font-size:9px\">Fig. 6: This lightweight table detector can identify tables (outlined in red) and\\n<br>cells (shaded in blue) in di\ufb00erent locations on a page. In very few cases (d), it\\n<br>might generate minor error predictions, e.g, failing to capture the top text line of\\n<br></span><span style=\"font-family: CMR10; font-size:9px\">a table.\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:134px; top:10478px; width:216px; height:9px;\"><span style=\"font-family: CMBX10; font-size:9px\">5.2 A light-weight Visual Table Extractor\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:134px; top:10518px; width:347px; height:81px;\"><span style=\"font-family: CMR10; font-size:9px\">Detecting tables and parsing their structures (table extraction) are of central im-\\n<br>portance for many document digitization tasks. Many previous works [26, 30, 27]\\n<br>and tools </span><span style=\"font-family: CMR7; font-size:6px\">18 </span><span style=\"font-family: CMR10; font-size:9px\">have been developed to identify and parse table structures. Yet they\\n<br>might require training complicated models from scratch, or are only applicable\\n<br>for born-digital PDF documents. In this section, we show how </span><span style=\"font-family: CMTT10; font-size:9px\">LayoutParser </span><span style=\"font-family: CMR10; font-size:9px\">can\\n<br>help build a light-weight accurate visual table extractor for legal docket tables\\n<br>using the existing resources with minimal e\ufb00ort.\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:134px; top:10606px; width:347px; height:177px;\"><span style=\"font-family: CMR10; font-size:9px\">The extractor uses a pre-trained layout detection model for identifying the\\n<br>table regions and some simple rules for pairing the rows and the columns in the\\n<br>PDF image. Mask R-CNN [12] trained on the PubLayNet dataset [38] from the\\n<br></span><span style=\"font-family: CMTT10; font-size:9px\">LayoutParser </span><span style=\"font-family: CMR10; font-size:9px\">Model Zoo can be used for detecting table regions. By \ufb01ltering\\n<br>out model predictions of low con\ufb01dence and removing overlapping predictions,\\n<br></span><span style=\"font-family: CMTT10; font-size:9px\">LayoutParser </span><span style=\"font-family: CMR10; font-size:9px\">can identify the tabular", "type": "Document"}, {"metadata": {"description": "Portable Document Format (PDF), standardized as ISO 32000, is a file format developed by Adobe in 1992 to present documents, including text formatting and images, in a manner independent of application software, hardware, and operating systems.", "language": "en", "changefreq": "weekly", "source": "https://python.langchain.com/docs/how_to/document_loader_pdf/", "title": "How to load PDFs | \ud83e\udd9c\ufe0f\ud83d\udd17 LangChain", "content_type": null, "lastmod": null, "priority": "0.5", "loc": "https://python.langchain.com/docs/how_to/document_loader_pdf/", "uuid": "5a2a91d5-0d47-5a95-8791-d9a4adade490"}, "page_content": "```output\n{'source': '../../docs/integrations/document_loaders/example_data/layout-parser-paper.pdf', 'page': 0}\n\nLayoutParser : A Uni\ufb01ed Toolkit for Deep\nLearning Based Document Image Analysis\nZejiang Shen1( \ufffd), Ruochen Zhang2, Melissa Dell3, Benjamin Charles Germain\nLee4, Jacob Carlson3, and Weining Li5\n1Allen Institute for AI\nshannons@allenai.org\n2Brown University\nruochen zhang@brown.edu\n3Harvard University\n{melissadell,jacob carlson }@fas.harvard.edu\n4University of Washington\nbcgl@cs.washington.edu\n5University of Waterloo\nw422li@uwaterloo.ca\nAbstract. Recent advances in document image analysis (DIA) have been\nprimarily driven by the application of neural networks. Ideally, research\noutcomes could be easily deployed in production and extended for further\ninvestigation. However, various factors like loosely organized codebases\nand sophisticated model con\ufb01gurations complicate the easy reuse of im-\nportant innovations by a wide audience. Though there have been on-going\ne\ufb00orts to improve reusability and simplify deep learning (DL) model\ndevelopment in disciplines like natural language processing and computer\nvision, none of them are optimized for challenges in the domain of DIA.\nThis represents a major gap in the existing toolkit, as DIA is central to\nacademic research across a wide range of disciplines in the social sciences\nand humanities. This paper introduces LayoutParser , an open-source\nlibrary for streamlining the usage of DL in DIA research and applica-\ntions. The core LayoutParser library comes with a set of simple and\nintuitive interfaces for applying and customizing DL models for layout de-\ntection, character recognition, and many other document processing tasks.\nTo promote extensibility, LayoutParser also incorporates a community\nplatform for sharing both pre-trained models and full document digiti-\nzation pipelines. We demonstrate that LayoutParser is helpful for both\nlightweight and large-scale digitization pipelines in real-word use cases.\nThe library is publicly available at https://layout-parser.github.io .\nKeywords: Document Image Analysis \u00b7Deep Learning \u00b7Layout Analysis\n\u00b7Character Recognition \u00b7Open Source library \u00b7Toolkit.\n1 Introduction\nDeep Learning(DL)-based approaches are the state-of-the-art for a wide range of\ndocument image analysis (DIA) tasks including document image classi\ufb01cation [ 11,arXiv:2103.15348v2  [cs.CV]  21 Jun 2021\n```\n\nNote that the metadata of each document stores the corresponding page number.\n\n### Vector search over PDFs\u200b\n\nOnce we have loaded PDFs into LangChain `Document` objects, we can index them (e.g., a RAG application) in the usual way. Below we use OpenAI embeddings, although any LangChain [embeddings](https://python.langchain.com/docs/concepts/embedding_models) model will suffice.\n\n```python\n%pip install -qU langchain-openai\n```\n\n```python\nimport getpass\nimport os\n\nif \"OPENAI_API_KEY\" not in os.environ:\n    os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"OpenAI API Key:\")\n```\n\n```python\nfrom langchain_core.vectorstores import InMemoryVectorStore\nfrom langchain_openai import OpenAIEmbeddings\n\nvector_store = InMemoryVectorStore.from_documents(pages, OpenAIEmbeddings())\ndocs = vector_store.similarity_search(\"What is LayoutParser?\", k=2)\nfor doc in docs:\n    print(f'Page {doc.metadata[\"page\"]}: {doc.page_content[:300]}\\n')\n```\n\n**API Reference:**[InMemoryVectorStore](https://python.langchain.com/api_reference/core/vectorstores/langchain_core.vectorstores.in_memory.InMemoryVectorStore.html) | [OpenAIEmbeddings](https://python.langchain.com/api_reference/openai/embeddings/langchain_openai.embeddings.base.OpenAIEmbeddings.html)\n```output\nPage 13: 14 Z. Shen et al.\n6 Conclusion\nLayoutParser provides a comprehensive toolkit for deep learning-based document\nimage analysis. The o\ufb00-the-shelf library is easy to install, and can be used to\nbuild \ufb02exible and accurate pipelines for processing documents with complicated\nstructures. It also supports hi", "type": "Document"}, {"metadata": {"language": "en", "description": "The pace of AI application development is often rate-limited by high-quality evaluations because there is a paradox of choice. Developers often wonder how to engineer their prompt or which LLM best balances accuracy, latency, and cost. High quality evaluations can help you rapidly answer these types of questions with confidence.", "changefreq": null, "source": "https://docs.smith.langchain.com/evaluation/concepts", "title": "Concepts | \ud83e\udd9c\ufe0f\ud83d\udee0\ufe0f LangSmith", "content_type": "text/html; charset=utf-8", "lastmod": null, "priority": null, "loc": null, "uuid": "e07006e1-3edd-5630-8851-49f0e2518263"}, "page_content": "Use CaseDetailReference-free?LLM-as-judge?Pairwise relevantCriteriaTag if specific criteria is metYesYes - promptNoAccuracyStandard definitionNo (ground truth class)NoNoPrecisionStandard definitionNo (ground truth class)NoNoRecallStandard definitionNo (ground truth class)NoNoWas this page helpful?You can leave detailed feedback on GitHub.PreviousQuick StartNextEvaluation how-to guidesDatasetsCreating datasetsPartitioning datasetsEvaluatorsHumanHeuristicLLM-as-judgePairwiseApplying evaluationsUnit TestsRegression TestingBack-testingPairwise-testingOnline EvaluationExperiment ConfigurationsAgentsEvaluating an agent's final responseEvaluating a single step of an agentEvaluating an agent's trajectoryBest practicesRetrieval Augmented Generation (RAG)DatasetEvaluatorApplying RAG EvaluationRAG evaluation summaryCommon use-casesSummarizationClassification / TaggingCommunityDiscordTwitterGitHubDocs CodeLangSmith SDKPythonJS/TSMoreHomepageBlogLangChain Python DocsLangChain JS/TS DocsCopyright \u00a9 2024 LangChain, Inc.", "type": "Document"}, {"metadata": {"description": "AnalyticDB for PostgreSQL is a massively parallel processing (MPP) data warehousing service that is designed to analyze large volumes of data online.", "language": "en", "changefreq": "weekly", "source": "https://python.langchain.com/docs/integrations/vectorstores/analyticdb/", "title": "AnalyticDB | \ud83e\udd9c\ufe0f\ud83d\udd17 LangChain", "content_type": null, "lastmod": null, "priority": "0.5", "loc": "https://python.langchain.com/docs/integrations/vectorstores/analyticdb/", "uuid": "602e584b-8d9f-574d-9391-97abe4a39b64"}, "page_content": "Tonight, I\u2019d like to honor someone who has dedicated his life to serve this country: Justice Stephen Breyer\u2014an Army veteran, Constitutional scholar, and retiring Justice of the United States Supreme Court. Justice Breyer, thank you for your service. \n\nOne of the most serious constitutional responsibilities a President has is nominating someone to serve on the United States Supreme Court. \n\nAnd I did that 4 days ago, when I nominated Circuit Court of Appeals Judge Ketanji Brown Jackson. One of our nation\u2019s top legal minds, who will continue Justice Breyer\u2019s legacy of excellence.\n```\n\n## Related\u200b\n\n- Vector store [conceptual guide](/docs/concepts/vectorstores/)\n\n- Vector store [how-to guides](/docs/how_to/#vector-stores)\n\n#### Was this page helpful?\n\n- [Related](#related)", "type": "Document"}, {"metadata": {"description": "Hologres is a unified real-time data warehousing service developed by Alibaba Cloud. You can use Hologres to write, update, process, and analyze large amounts of data in real time.", "language": "en", "changefreq": "weekly", "source": "https://python.langchain.com/docs/integrations/vectorstores/hologres/", "title": "Hologres | \ud83e\udd9c\ufe0f\ud83d\udd17 LangChain", "content_type": null, "lastmod": null, "priority": "0.5", "loc": "https://python.langchain.com/docs/integrations/vectorstores/hologres/", "uuid": "ab394f69-6b1c-5a06-8672-ad6c91feda6f"}, "page_content": "Tonight, I\u2019d like to honor someone who has dedicated his life to serve this country: Justice Stephen Breyer\u2014an Army veteran, Constitutional scholar, and retiring Justice of the United States Supreme Court. Justice Breyer, thank you for your service. \n\nOne of the most serious constitutional responsibilities a President has is nominating someone to serve on the United States Supreme Court. \n\nAnd I did that 4 days ago, when I nominated Circuit Court of Appeals Judge Ketanji Brown Jackson. One of our nation\u2019s top legal minds, who will continue Justice Breyer\u2019s legacy of excellence.\n```\n\n## Related\u200b\n\n- Vector store [conceptual guide](/docs/concepts/vectorstores/)\n\n- Vector store [how-to guides](/docs/how_to/#vector-stores)\n\n#### Was this page helpful?\n\n- [Related](#related)", "type": "Document"}, {"metadata": {"description": "One challenge with retrieval is that usually you don't know the specific queries your document storage system will face when you ingest data into the system. This means that the information most relevant to a query may be buried in a document with a lot of irrelevant text. Passing that full document through your application can lead to more expensive LLM calls and poorer responses.", "language": "en", "changefreq": "weekly", "source": "https://python.langchain.com/docs/how_to/contextual_compression/", "title": "How to do retrieval with contextual compression | \ud83e\udd9c\ufe0f\ud83d\udd17 LangChain", "lastmod": null, "content_type": null, "priority": "0.5", "loc": "https://python.langchain.com/docs/how_to/contextual_compression/", "uuid": "0e224cfa-3f17-580f-83cd-030c2df600c0"}, "page_content": "compressed_docs = compression_retriever.invoke(\n    \"What did the president say about Ketanji Jackson Brown\"\n)\npretty_print_docs(compressed_docs)\n```\n\n**API Reference:**[LLMListwiseRerank](https://python.langchain.com/api_reference/langchain/retrievers/langchain.retrievers.document_compressors.listwise_rerank.LLMListwiseRerank.html) | [ChatOpenAI](https://python.langchain.com/api_reference/openai/chat_models/langchain_openai.chat_models.base.ChatOpenAI.html)\n```output\nDocument 1:\n\nTonight. I call on the Senate to: Pass the Freedom to Vote Act. Pass the John Lewis Voting Rights Act. And while you\u2019re at it, pass the Disclose Act so Americans can know who is funding our elections. \n\nTonight, I\u2019d like to honor someone who has dedicated his life to serve this country: Justice Stephen Breyer\u2014an Army veteran, Constitutional scholar, and retiring Justice of the United States Supreme Court. Justice Breyer, thank you for your service. \n\nOne of the most serious constitutional responsibilities a President has is nominating someone to serve on the United States Supreme Court. \n\nAnd I did that 4 days ago, when I nominated Circuit Court of Appeals Judge Ketanji Brown Jackson. One of our nation\u2019s top legal minds, who will continue Justice Breyer\u2019s legacy of excellence.\n```\n\n### EmbeddingsFilter\u200b\n\nMaking an extra LLM call over each retrieved document is expensive and slow. The `EmbeddingsFilter` provides a cheaper and faster option by embedding the documents and query and only returning those documents which have sufficiently similar embeddings to the query.\n\n```python\nfrom langchain.retrievers.document_compressors import EmbeddingsFilter\nfrom langchain_openai import OpenAIEmbeddings\n\nembeddings = OpenAIEmbeddings()\nembeddings_filter = EmbeddingsFilter(embeddings=embeddings, similarity_threshold=0.76)\ncompression_retriever = ContextualCompressionRetriever(\n    base_compressor=embeddings_filter, base_retriever=retriever\n)\n\ncompressed_docs = compression_retriever.invoke(\n    \"What did the president say about Ketanji Jackson Brown\"\n)\npretty_print_docs(compressed_docs)\n```\n\n**API Reference:**[EmbeddingsFilter](https://python.langchain.com/api_reference/langchain/retrievers/langchain.retrievers.document_compressors.embeddings_filter.EmbeddingsFilter.html) | [OpenAIEmbeddings](https://python.langchain.com/api_reference/openai/embeddings/langchain_openai.embeddings.base.OpenAIEmbeddings.html)\n```output\nDocument 1:\n\nTonight. I call on the Senate to: Pass the Freedom to Vote Act. Pass the John Lewis Voting Rights Act. And while you\u2019re at it, pass the Disclose Act so Americans can know who is funding our elections. \n\nTonight, I\u2019d like to honor someone who has dedicated his life to serve this country: Justice Stephen Breyer\u2014an Army veteran, Constitutional scholar, and retiring Justice of the United States Supreme Court. Justice Breyer, thank you for your service. \n\nOne of the most serious constitutional responsibilities a President has is nominating someone to serve on the United States Supreme Court. \n\nAnd I did that 4 days ago, when I nominated Circuit Court of Appeals Judge Ketanji Brown Jackson. One of our nation\u2019s top legal minds, who will continue Justice Breyer\u2019s legacy of excellence.\n----------------------------------------------------------------------------------------------------\nDocument 2:\n\nA former top litigator in private practice. A former federal public defender. And from a family of public school educators and police officers. A consensus builder. Since she\u2019s been nominated, she\u2019s received a broad range of support\u2014from the Fraternal Order of Police to former judges appointed by Democrats and Republicans. \n\nAnd if we are to advance liberty and justice, we need to secure the Border and fix the immigration system. \n\nWe can do both. At our border, we\u2019ve installed new technology like cutting-edge scanners to better detect drug smuggling.  \n\nWe\u2019ve set up joint patrols with Mexico and Guatemala to catch more human traffickers.", "type": "Document"}, {"metadata": {"description": "This notebook shows how to use DashScope Reranker for document compression and retrieval. DashScope is the generative AI service from Alibaba Cloud (Aliyun).", "language": "en", "changefreq": "weekly", "source": "https://python.langchain.com/docs/integrations/document_transformers/dashscope_rerank/", "title": "DashScope Reranker | \ud83e\udd9c\ufe0f\ud83d\udd17 LangChain", "content_type": null, "lastmod": null, "priority": "0.5", "loc": "https://python.langchain.com/docs/integrations/document_transformers/dashscope_rerank/", "uuid": "a9da7658-305c-5a2e-8f60-e5c6cc7296c2"}, "page_content": "One of the most serious constitutional responsibilities a President has is nominating someone to serve on the United States Supreme Court. \n\nAnd I did that 4 days ago, when I nominated Circuit Court of Appeals Judge Ketanji Brown Jackson. One of our nation\u2019s top legal minds, who will continue Justice Breyer\u2019s legacy of excellence.\n----------------------------------------------------------------------------------------------------\nDocument 3:\n\nTo all Americans, I will be honest with you, as I\u2019ve always promised. A Russian dictator, invading a foreign country, has costs around the world. \n\nAnd I\u2019m taking robust action to make sure the pain of our sanctions  is targeted at Russia\u2019s economy. And I will use every tool at our disposal to protect American businesses and consumers. \n\nTonight, I can announce that the United States has worked with 30 other countries to release 60 Million barrels of oil from reserves around the world.\n----------------------------------------------------------------------------------------------------\nDocument 4:\n\nWe cannot let this happen. \n\nTonight. I call on the Senate to: Pass the Freedom to Vote Act. Pass the John Lewis Voting Rights Act. And while you\u2019re at it, pass the Disclose Act so Americans can know who is funding our elections. \n\nTonight, I\u2019d like to honor someone who has dedicated his life to serve this country: Justice Stephen Breyer\u2014an Army veteran, Constitutional scholar, and retiring Justice of the United States Supreme Court. Justice Breyer, thank you for your service.\n----------------------------------------------------------------------------------------------------\nDocument 5:\n\nTonight I say to the Russian oligarchs and corrupt leaders who have bilked billions of dollars off this violent regime no more. \n\nThe U.S. Department of Justice is assembling a dedicated task force to go after the crimes of Russian oligarchs.  \n\nWe are joining with our European allies to find and seize your yachts your luxury apartments your private jets. We are coming for your ill-begotten gains.\n----------------------------------------------------------------------------------------------------\nDocument 6:\n\nEvery Administration says they\u2019ll do it, but we are actually doing it. \n\nWe will buy American to make sure everything from the deck of an aircraft carrier to the steel on highway guardrails are made in America. \n\nBut to compete for the best jobs of the future, we also need to level the playing field with China and other competitors.\n----------------------------------------------------------------------------------------------------\nDocument 7:\n\nWhen we invest in our workers, when we build the economy from the bottom up and the middle out together, we can do something we haven\u2019t done in a long time: build a better America. \n\nFor more than two years, COVID-19 has impacted every decision in our lives and the life of the nation. \n\nAnd I know you\u2019re tired, frustrated, and exhausted. \n\nBut I also know this.\n----------------------------------------------------------------------------------------------------\nDocument 8:\n\nA former top litigator in private practice. A former federal public defender. And from a family of public school educators and police officers. A consensus builder. Since she\u2019s been nominated, she\u2019s received a broad range of support\u2014from the Fraternal Order of Police to former judges appointed by Democrats and Republicans. \n\nAnd if we are to advance liberty and justice, we need to secure the Border and fix the immigration system.\n----------------------------------------------------------------------------------------------------\nDocument 9:\n\nMy plan will not only lower costs to give families a fair shot, it will lower the deficit. \n\nThe previous Administration not only ballooned the deficit with tax cuts for the very wealthy and corporations, it undermined the watchdogs whose job was to keep pandemic relief funds from being wasted.", "type": "Document"}, {"metadata": {"description": "When splitting documents for retrieval, there are often conflicting desires:", "language": "en", "changefreq": "weekly", "source": "https://python.langchain.com/docs/how_to/parent_document_retriever/", "title": "How to use the Parent Document Retriever | \ud83e\udd9c\ufe0f\ud83d\udd17 LangChain", "lastmod": null, "content_type": null, "priority": "0.5", "loc": "https://python.langchain.com/docs/how_to/parent_document_retriever/", "uuid": "5c24f9cf-90e6-52f4-8da6-d8535cfad74d"}, "page_content": "```python\nretrieved_docs = retriever.invoke(\"justice breyer\")\n```\n\n```python\nlen(retrieved_docs[0].page_content)\n```\n\n```output\n38540\n```\n\n## Retrieving larger chunks\u200b\n\nSometimes, the full documents can be too big to want to retrieve them as is. In that case, what we really want to do is to first split the raw documents into larger chunks, and then split it into smaller chunks. We then index the smaller chunks, but on retrieval we retrieve the larger chunks (but still not the full documents).\n\n```python\n# This text splitter is used to create the parent documents\nparent_splitter = RecursiveCharacterTextSplitter(chunk_size=2000)\n# This text splitter is used to create the child documents\n# It should create documents smaller than the parent\nchild_splitter = RecursiveCharacterTextSplitter(chunk_size=400)\n# The vectorstore to use to index the child chunks\nvectorstore = Chroma(\n    collection_name=\"split_parents\", embedding_function=OpenAIEmbeddings()\n)\n# The storage layer for the parent documents\nstore = InMemoryStore()\n```\n\n```python\nretriever = ParentDocumentRetriever(\n    vectorstore=vectorstore,\n    docstore=store,\n    child_splitter=child_splitter,\n    parent_splitter=parent_splitter,\n)\n```\n\n```python\nretriever.add_documents(docs)\n```\n\nWe can see that there are much more than two documents now - these are the larger chunks.\n\n```python\nlen(list(store.yield_keys()))\n```\n\n```output\n66\n```\n\nLet's make sure the underlying vector store still retrieves the small chunks.\n\n```python\nsub_docs = vectorstore.similarity_search(\"justice breyer\")\n```\n\n```python\nprint(sub_docs[0].page_content)\n```\n\n```output\nTonight, I\u2019d like to honor someone who has dedicated his life to serve this country: Justice Stephen Breyer\u2014an Army veteran, Constitutional scholar, and retiring Justice of the United States Supreme Court. Justice Breyer, thank you for your service. \n\nOne of the most serious constitutional responsibilities a President has is nominating someone to serve on the United States Supreme Court.\n```\n\n```python\nretrieved_docs = retriever.invoke(\"justice breyer\")\n```\n\n```python\nlen(retrieved_docs[0].page_content)\n```\n\n```output\n1849\n```\n\n```python\nprint(retrieved_docs[0].page_content)\n```\n\n```output\nIn state after state, new laws have been passed, not only to suppress the vote, but to subvert entire elections. \n\nWe cannot let this happen. \n\nTonight. I call on the Senate to: Pass the Freedom to Vote Act. Pass the John Lewis Voting Rights Act. And while you\u2019re at it, pass the Disclose Act so Americans can know who is funding our elections. \n\nTonight, I\u2019d like to honor someone who has dedicated his life to serve this country: Justice Stephen Breyer\u2014an Army veteran, Constitutional scholar, and retiring Justice of the United States Supreme Court. Justice Breyer, thank you for your service. \n\nOne of the most serious constitutional responsibilities a President has is nominating someone to serve on the United States Supreme Court. \n\nAnd I did that 4 days ago, when I nominated Circuit Court of Appeals Judge Ketanji Brown Jackson. One of our nation\u2019s top legal minds, who will continue Justice Breyer\u2019s legacy of excellence. \n\nA former top litigator in private practice. A former federal public defender. And from a family of public school educators and police officers. A consensus builder. Since she\u2019s been nominated, she\u2019s received a broad range of support\u2014from the Fraternal Order of Police to former judges appointed by Democrats and Republicans. \n\nAnd if we are to advance liberty and justice, we need to secure the Border and fix the immigration system. \n\nWe can do both. At our border, we\u2019ve installed new technology like cutting-edge scanners to better detect drug smuggling.  \n\nWe\u2019ve set up joint patrols with Mexico and Guatemala to catch more human traffickers.  \n\nWe\u2019re putting in place dedicated immigration judges so families fleeing persecution and violence can have their cases heard faster.", "type": "Document"}, {"metadata": {"description": "UpTrain [github || website || docs] is an open-source platform to evaluate and improve LLM applications. It provides grades for 20+ preconfigured checks (covering language, code, embedding use cases), performs root cause analyses on instances of failure cases and provides guidance for resolving them.", "language": "en", "changefreq": "weekly", "source": "https://python.langchain.com/docs/integrations/callbacks/uptrain/", "title": "uptrain | \ud83e\udd9c\ufe0f\ud83d\udd17 LangChain", "lastmod": null, "content_type": null, "priority": "0.5", "loc": "https://python.langchain.com/docs/integrations/callbacks/uptrain/", "uuid": "6c5602df-140a-5c31-b5f5-cc188744c2ee"}, "page_content": "Question: What did the president say about Ketanji Brown Jackson\nResponse: The president mentioned that he had nominated Ketanji Brown Jackson to serve on the United States Supreme Court 4 days ago. He described her as one of the nation's top legal minds who will continue Justice Breyer\u2019s legacy of excellence. He also mentioned that she is a former top litigator in private practice, a former federal public defender, and comes from a family of public school educators and police officers. He described her as a consensus builder and noted that since her nomination, she has received a broad range of support from various groups, including the Fraternal Order of Police and former judges appointed by both Democrats and Republicans.\n\nContext Relevance Score: 1.0\nFactual Accuracy Score: 1.0\nResponse Completeness Score: 1.0\n```\n\n# 2. Multi Query Generation\n\nThe **MultiQueryRetriever** is used to tackle the problem that the RAG pipeline might not return the best set of documents based on the query. It generates multiple queries that mean the same as the original query and then fetches documents for each.\n\nTo evluate this retriever, UpTrain will run the following evaluation:\n\n- **Multi Query Accuracy**: Checks if the multi-queries generated mean the same as the original query.\n\n```python\n# Create the retriever\nmulti_query_retriever = MultiQueryRetriever.from_llm(retriever=retriever, llm=llm)\n\n# Create the uptrain callback\nuptrain_callback = UpTrainCallbackHandler(key_type=KEY_TYPE, api_key=API_KEY)\nconfig = {\"callbacks\": [uptrain_callback]}\n\n# Create the RAG prompt\ntemplate = \"\"\"Answer the question based only on the following context, which can include text and tables:\n{context}\nQuestion: {question}\n\"\"\"\nrag_prompt_text = ChatPromptTemplate.from_template(template)\n\nchain = (\n    {\"context\": multi_query_retriever, \"question\": RunnablePassthrough()}\n    | rag_prompt_text\n    | llm\n    | StrOutputParser()\n)\n\n# Invoke the chain with a query\nquestion = \"What did the president say about Ketanji Brown Jackson\"\ndocs = chain.invoke(question, config=config)\n```\n\n```output\n[32m2024-04-17 17:04:10.675[0m | [1mINFO    [0m | [36muptrain.framework.evalllm[0m:[36mevaluate_on_server[0m:[36m378[0m - [1mSending evaluation request for rows 0 to <50 to the Uptrain[0m\n[32m2024-04-17 17:04:16.804[0m | [1mINFO    [0m | [36muptrain.framework.evalllm[0m:[36mevaluate[0m:[36m367[0m - [1mLocal server not running, start the server to log data and visualize in the dashboard![0m\n``````output\n\nQuestion: What did the president say about Ketanji Brown Jackson\nMulti Queries:\n  - How did the president comment on Ketanji Brown Jackson?\n  - What were the president's remarks regarding Ketanji Brown Jackson?\n  - What statements has the president made about Ketanji Brown Jackson?\n\nMulti Query Accuracy Score: 0.5\n``````output\n[32m2024-04-17 17:04:22.027[0m | [1mINFO    [0m | [36muptrain.framework.evalllm[0m:[36mevaluate_on_server[0m:[36m378[0m - [1mSending evaluation request for rows 0 to <50 to the Uptrain[0m\n[32m2024-04-17 17:04:44.033[0m | [1mINFO    [0m | [36muptrain.framework.evalllm[0m:[36mevaluate[0m:[36m367[0m - [1mLocal server not running, start the server to log data and visualize in the dashboard![0m\n``````output\n\nQuestion: What did the president say about Ketanji Brown Jackson\nResponse: The president mentioned that he had nominated Circuit Court of Appeals Judge Ketanji Brown Jackson to serve on the United States Supreme Court 4 days ago. He described her as one of the nation's top legal minds who will continue Justice Breyer\u2019s legacy of excellence. He also mentioned that since her nomination, she has received a broad range of support\u2014from the Fraternal Order of Police to former judges appointed by Democrats and Republicans.\n\nContext Relevance Score: 1.0\nFactual Accuracy Score: 1.0\nResponse Completeness Score: 1.0\n```\n\n# 3. Context Compression and Reranking", "type": "Document"}, {"metadata": {"language": "en", "description": "Timescale Vector is PostgreSQL++ vector database for AI applications.", "changefreq": "weekly", "source": "https://python.langchain.com/docs/integrations/vectorstores/timescalevector/", "title": "Timescale Vector (Postgres) | \ud83e\udd9c\ufe0f\ud83d\udd17 LangChain", "content_type": null, "lastmod": null, "priority": "0.5", "loc": "https://python.langchain.com/docs/integrations/vectorstores/timescalevector/", "uuid": "97b75c76-ec70-52a3-a5bc-f34f7df23687"}, "page_content": "Tonight, I\u2019d like to honor someone who has dedicated his life to serve this country: Justice Stephen Breyer\u2014an Army veteran, Constitutional scholar, and retiring Justice of the United States Supreme Court. Justice Breyer, thank you for your service. \n\nOne of the most serious constitutional responsibilities a President has is nominating someone to serve on the United States Supreme Court. \n\nAnd I did that 4 days ago, when I nominated Circuit Court of Appeals Judge Ketanji Brown Jackson. One of our nation\u2019s top legal minds, who will continue Justice Breyer\u2019s legacy of excellence.\n--------------------------------------------------------------------------------\n--------------------------------------------------------------------------------\nScore:  0.18452197313308139\nTonight. I call on the Senate to: Pass the Freedom to Vote Act. Pass the John Lewis Voting Rights Act. And while you\u2019re at it, pass the Disclose Act so Americans can know who is funding our elections. \n\nTonight, I\u2019d like to honor someone who has dedicated his life to serve this country: Justice Stephen Breyer\u2014an Army veteran, Constitutional scholar, and retiring Justice of the United States Supreme Court. Justice Breyer, thank you for your service. \n\nOne of the most serious constitutional responsibilities a President has is nominating someone to serve on the United States Supreme Court. \n\nAnd I did that 4 days ago, when I nominated Circuit Court of Appeals Judge Ketanji Brown Jackson. One of our nation\u2019s top legal minds, who will continue Justice Breyer\u2019s legacy of excellence.\n--------------------------------------------------------------------------------\n--------------------------------------------------------------------------------\nScore:  0.21720781018594182\nA former top litigator in private practice. A former federal public defender. And from a family of public school educators and police officers. A consensus builder. Since she\u2019s been nominated, she\u2019s received a broad range of support\u2014from the Fraternal Order of Police to former judges appointed by Democrats and Republicans. \n\nAnd if we are to advance liberty and justice, we need to secure the Border and fix the immigration system. \n\nWe can do both. At our border, we\u2019ve installed new technology like cutting-edge scanners to better detect drug smuggling.  \n\nWe\u2019ve set up joint patrols with Mexico and Guatemala to catch more human traffickers.  \n\nWe\u2019re putting in place dedicated immigration judges so families fleeing persecution and violence can have their cases heard faster. \n\nWe\u2019re securing commitments and supporting partners in South and Central America to host more refugees and secure their own borders.\n--------------------------------------------------------------------------------\n--------------------------------------------------------------------------------\nScore:  0.21724902288621384\nA former top litigator in private practice. A former federal public defender. And from a family of public school educators and police officers. A consensus builder. Since she\u2019s been nominated, she\u2019s received a broad range of support\u2014from the Fraternal Order of Police to former judges appointed by Democrats and Republicans. \n\nAnd if we are to advance liberty and justice, we need to secure the Border and fix the immigration system. \n\nWe can do both. At our border, we\u2019ve installed new technology like cutting-edge scanners to better detect drug smuggling.  \n\nWe\u2019ve set up joint patrols with Mexico and Guatemala to catch more human traffickers.  \n\nWe\u2019re putting in place dedicated immigration judges so families fleeing persecution and violence can have their cases heard faster. \n\nWe\u2019re securing commitments and supporting partners in South and Central America to host more refugees and secure their own borders.\n--------------------------------------------------------------------------------\n```\n\n### Using a Timescale Vector as a Retriever\u200b", "type": "Document"}, {"metadata": {"description": "Intel's VDMS is a storage solution for efficient access of big-\u201dvisual\u201d-data that aims to achieve cloud scale by searching for relevant visual data via visual metadata stored as a graph and enabling machine friendly enhancements to visual data for faster access. VDMS is licensed under MIT.", "language": "en", "changefreq": "weekly", "source": "https://python.langchain.com/docs/integrations/vectorstores/vdms/", "title": "Intel's Visual Data Management System (VDMS) | \ud83e\udd9c\ufe0f\ud83d\udd17 LangChain", "lastmod": null, "content_type": null, "priority": "0.5", "loc": "https://python.langchain.com/docs/integrations/vectorstores/vdms/", "uuid": "4f15705d-8620-58e1-9dfd-0218bc8b858c"}, "page_content": "Metadata:\n\tid:\t32\n\tpage_number:\t32\n\tpresident_included:\tTrue\n\tsource:\t../../how_to/state_of_the_union.txt\n--------------------------------------------------\n\nContent:\n\tAs Frances Haugen, who is here with us tonight, has shown, we must hold social media platforms accountable for the national experiment they\u2019re conducting on our children for profit. \n\nIt\u2019s time to strengthen privacy protections, ban targeted advertising to children, demand tech companies stop collecting personal data on our children. \n\nAnd let\u2019s get all Americans the mental health services they need. More people they can turn to for help, and full parity between physical and mental health care. \n\nThird, support our veterans. \n\nVeterans are the best of us. \n\nI\u2019ve always believed that we have a sacred obligation to equip all those we send to war and care for them and their families when they come home. \n\nMy administration is providing assistance with job training and housing, and now helping lower-income veterans get VA care debt-free.  \n\nOur troops in Iraq and Afghanistan faced many dangers.\n\nMetadata:\n\tid:\t37\n\tpage_number:\t37\n\tpresident_included:\tFalse\n\tsource:\t../../how_to/state_of_the_union.txt\n--------------------------------------------------\n\nContent:\n\tA former top litigator in private practice. A former federal public defender. And from a family of public school educators and police officers. A consensus builder. Since she\u2019s been nominated, she\u2019s received a broad range of support\u2014from the Fraternal Order of Police to former judges appointed by Democrats and Republicans. \n\nAnd if we are to advance liberty and justice, we need to secure the Border and fix the immigration system. \n\nWe can do both. At our border, we\u2019ve installed new technology like cutting-edge scanners to better detect drug smuggling.  \n\nWe\u2019ve set up joint patrols with Mexico and Guatemala to catch more human traffickers.  \n\nWe\u2019re putting in place dedicated immigration judges so families fleeing persecution and violence can have their cases heard faster. \n\nWe\u2019re securing commitments and supporting partners in South and Central America to host more refugees and secure their own borders.\n\nMetadata:\n\tid:\t33\n\tpage_number:\t33\n\tpresident_included:\tFalse\n\tsource:\t../../how_to/state_of_the_union.txt\n--------------------------------------------------\n```\n\n```python\n# Query (with filtering)\nk = 3\nconstraints = {\"page_number\": [\">\", 30], \"president_included\": [\"==\", True]}\nquery = \"What did the president say about Ketanji Brown Jackson\"\nreturned_docs = db_FaissFlat.similarity_search(query, k=k, filter=constraints)\nprint_results(returned_docs, score=False)\n```\n\n```output\n--------------------------------------------------\n\nContent:\n\tTonight. I call on the Senate to: Pass the Freedom to Vote Act. Pass the John Lewis Voting Rights Act. And while you\u2019re at it, pass the Disclose Act so Americans can know who is funding our elections. \n\nTonight, I\u2019d like to honor someone who has dedicated his life to serve this country: Justice Stephen Breyer\u2014an Army veteran, Constitutional scholar, and retiring Justice of the United States Supreme Court. Justice Breyer, thank you for your service. \n\nOne of the most serious constitutional responsibilities a President has is nominating someone to serve on the United States Supreme Court. \n\nAnd I did that 4 days ago, when I nominated Circuit Court of Appeals Judge Ketanji Brown Jackson. One of our nation\u2019s top legal minds, who will continue Justice Breyer\u2019s legacy of excellence.\n\nMetadata:\n\tid:\t32\n\tpage_number:\t32\n\tpresident_included:\tTrue\n\tsource:\t../../how_to/state_of_the_union.txt\n--------------------------------------------------\n\nContent:\n\tAnd for our LGBTQ+ Americans, let\u2019s finally get the bipartisan Equality Act to my desk. The onslaught of state laws targeting transgender Americans and their families is wrong.", "type": "Document"}], "answer": "To upload a PDF using LangChain, you can utilize the `PDFMinerLoader` or `PDFPlumberLoader`. Here\u2019s a brief overview of how to do it with each loader:\n\n### Using PDFMinerLoader\n1. **Install the required package**:\n   ```bash\n   pip install langchain_community\n   ```\n\n2. **Load the PDF**:\n   ```python\n   from langchain_community.document_loaders import PDFMinerLoader\n\n   file_path = \"./path_to_your_pdf/document.pdf\"\n   loader = PDFMinerLoader(file_path)\n   docs = loader.load()\n   ```\n\n### Using PDFPlumberLoader\n1. **Install the required package**:\n   ```bash\n   pip install langchain_community\n   ```\n\n2. **Load the PDF**:\n   ```python\n   from langchain_community.document_loaders import PDFPlumberLoader\n\n   loader = PDFPlumberLoader(\"./path_to_your_pdf/document.pdf\")\n   docs = loader.load()\n   ```\n\n### Notes\n- Both loaders will return a list of documents, where each document corresponds to a page in the PDF.\n- No special credentials are needed to use these loaders.\n\nFor more detailed information, you can refer to the API references for [PDFMinerLoader](https://python.langchain.com/api_reference/community/document_loaders/langchain_community.document_loaders.pdf.PDFMinerLoader.html) and [PDFPlumberLoader](https://python.langchain.com/api_reference/community/document_loaders/langchain_community.document_loaders.pdf.PDFPlumberLoader.html).", "query": "https://www.cambridge.org/core/services/aop-cambridge-core/content/view/0D4357A9A6150E706CC261B86BA47733/S0008423923000793a.pdf/ascent_of_the_canadian_judicial_council_bill_c9_and_the_move_towards_judicialized_governance.pdf  can you open this to answer questions for me "}}
{"messages": [[{"lc": 1, "type": "constructor", "id": ["langchain", "schema", "messages", "SystemMessage"], "kwargs": {"content": "Generate 3 search queries to search for to answer the user's question.\n\nThese search queries should be diverse in nature - do not generate repetitive ones.", "type": "system"}}, {"lc": 1, "type": "constructor", "id": ["langchain", "schema", "messages", "HumanMessage"], "kwargs": {"content": "Prepare to answer specific questions based on the extracted information.", "type": "human"}}]]}
{"input": {"messages": [{"content": "how do i upload a pdf", "additional_kwargs": {}, "response_metadata": {}, "type": "human", "id": "acdae6e0-4fa7-459f-8906-67b9372aba8f", "example": false}, {"content": "To upload a PDF using LangChain, you can utilize the `PDFMinerLoader` or `PDFPlumberLoader`. Here\u2019s a brief overview of how to do it with each loader:\n\n### Using PDFMinerLoader\n1. **Install the required package**:\n   ```bash\n   pip install langchain_community\n   ```\n\n2. **Load the PDF**:\n   ```python\n   from langchain_community.document_loaders import PDFMinerLoader\n\n   file_path = \"./path_to_your_pdf/document.pdf\"\n   loader = PDFMinerLoader(file_path)\n   docs = loader.load()\n   ```\n\n### Using PDFPlumberLoader\n1. **Install the required package**:\n   ```bash\n   pip install langchain_community\n   ```\n\n2. **Load the PDF**:\n   ```python\n   from langchain_community.document_loaders import PDFPlumberLoader\n\n   loader = PDFPlumberLoader(\"./path_to_your_pdf/document.pdf\")\n   docs = loader.load()\n   ```\n\n### Notes\n- Both loaders will return a list of documents, where each document corresponds to a page in the PDF.\n- No special credentials are needed to use these loaders.\n\nFor more detailed information, you can refer to the API references for [PDFMinerLoader](https://python.langchain.com/api_reference/community/document_loaders/langchain_community.document_loaders.pdf.PDFMinerLoader.html) and [PDFPlumberLoader](https://python.langchain.com/api_reference/community/document_loaders/langchain_community.document_loaders.pdf.PDFPlumberLoader.html).", "additional_kwargs": {}, "response_metadata": {"finish_reason": "stop", "model_name": "gpt-4o-mini-2024-07-18", "system_fingerprint": "fp_0705bf87c0"}, "type": "ai", "id": "run-646bc662-d299-4ff8-9700-03482e843756", "example": false, "tool_calls": [], "invalid_tool_calls": []}, {"content": "https://www.cambridge.org/core/services/aop-cambridge-core/content/view/0D4357A9A6150E706CC261B86BA47733/S0008423923000793a.pdf/ascent_of_the_canadian_judicial_council_bill_c9_and_the_move_towards_judicialized_governance.pdf  can you open this to answer questions for me ", "additional_kwargs": {}, "response_metadata": {}, "type": "human", "id": "97919fe7-0599-486c-90d0-7355c6c587d1", "example": false}], "router": {"type": "general", "logic": ""}, "steps": [], "documents": [{"metadata": {"language": "en", "description": "Portable Document Format (PDF), standardized as ISO 32000, is a file format developed by Adobe in 1992 to present documents, including text formatting and images, in a manner independent of application software, hardware, and operating systems.", "changefreq": "weekly", "source": "https://python.langchain.com/docs/how_to/document_loader_pdf/", "title": "How to load PDFs | \ud83e\udd9c\ufe0f\ud83d\udd17 LangChain", "lastmod": null, "content_type": null, "priority": "0.5", "loc": "https://python.langchain.com/docs/how_to/document_loader_pdf/", "uuid": "a3f9bbc3-306a-5a26-94ac-f0fe755afbb7"}, "page_content": "How to load PDFs | \ud83e\udd9c\ufe0f\ud83d\udd17 LangChain\n\n[Skip to main content](#__docusaurus_skipToContent_fallback)# How to load PDFs\n\n[Portable Document Format (PDF)](https://en.wikipedia.org/wiki/PDF), standardized as ISO 32000, is a file format developed by Adobe in 1992 to present documents, including text formatting and images, in a manner independent of application software, hardware, and operating systems.\n\nThis guide covers how to [load](/docs/concepts/document_loaders/) `PDF` documents into the LangChain [Document](https://python.langchain.com/api_reference/core/documents/langchain_core.documents.base.Document.html) format that we use downstream.\n\nText in PDFs is typically represented via text boxes. They may also contain images. A PDF parser might do some combination of the following:\n\n- Agglomerate text boxes into lines, paragraphs, and other structures via heuristics or ML inference;\n\n- Run [OCR](https://en.wikipedia.org/wiki/Optical_character_recognition) on images to detect text therein;\n\n- Classify text as belonging to paragraphs, lists, tables, or other structures;\n\n- Structure text into table rows and columns, or key-value pairs.\n\nLangChain integrates with a host of PDF parsers. Some are simple and relatively low-level; others will support OCR and image-processing, or perform advanced document layout analysis. The right choice will depend on your needs. Below we enumerate the possibilities.\n\nWe will demonstrate these approaches on a [sample file](https://github.com/langchain-ai/langchain/blob/master/libs/community/tests/integration_tests/examples/layout-parser-paper.pdf):\n\n```python\nfile_path = (\n    \"../../docs/integrations/document_loaders/example_data/layout-parser-paper.pdf\"\n)\n```\n\nA note on multimodal modelsMany modern LLMs support inference over multimodal inputs (e.g., images). In some applications -- such as question-answering over PDFs with complex layouts, diagrams, or scans -- it may be advantageous to skip the PDF parsing, instead casting a PDF page to an image and passing it to a model directly. We demonstrate an example of this in the [Use of multimodal models](/docs/how_to/document_loader_pdf/#use-of-multimodal-models) section below.\n\n## Simple and fast text extraction\u200b\n\nIf you are looking for a simple string representation of text that is embedded in a PDF, the method below is appropriate. It will return a list of [Document](https://python.langchain.com/api_reference/core/documents/langchain_core.documents.base.Document.html) objects-- one per page-- containing a single string of the page's text in the Document's `page_content` attribute. It will not parse text in images or scanned PDF pages. Under the hood it uses the [pypdf](https://pypdf.readthedocs.io/en/stable/) Python library.\n\nLangChain [document loaders](/docs/concepts/document_loaders/) implement `lazy_load` and its async variant, `alazy_load`, which return iterators of `Document` objects. We will use these below.\n\n```python\n%pip install -qU pypdf\n```\n\n```python\nfrom langchain_community.document_loaders import PyPDFLoader\n\nloader = PyPDFLoader(file_path)\npages = []\nasync for page in loader.alazy_load():\n    pages.append(page)\n```\n\n**API Reference:**[PyPDFLoader](https://python.langchain.com/api_reference/community/document_loaders/langchain_community.document_loaders.pdf.PyPDFLoader.html)\n```python\nprint(f\"{pages[0].metadata}\\n\")\nprint(pages[0].page_content)\n```\n\n```output\n{'source': '../../docs/integrations/document_loaders/example_data/layout-parser-paper.pdf', 'page': 0}", "type": "Document"}, {"metadata": {"description": "Overview", "language": "en", "changefreq": "weekly", "source": "https://python.langchain.com/docs/integrations/document_loaders/unstructured_pdfloader/", "title": "UnstructuredPDFLoader | \ud83e\udd9c\ufe0f\ud83d\udd17 LangChain", "lastmod": null, "content_type": null, "priority": "0.5", "loc": "https://python.langchain.com/docs/integrations/document_loaders/unstructured_pdfloader/", "uuid": "8e7d3de8-e7e7-5cc2-bee5-618901e9e15f"}, "page_content": "**API Reference:**[OnlinePDFLoader](https://python.langchain.com/api_reference/community/document_loaders/langchain_community.document_loaders.pdf.OnlinePDFLoader.html)\n```output", "type": "Document"}, {"metadata": {"description": "Overview", "language": "en", "changefreq": "weekly", "source": "https://python.langchain.com/docs/integrations/document_loaders/unstructured_pdfloader/", "title": "UnstructuredPDFLoader | \ud83e\udd9c\ufe0f\ud83d\udd17 LangChain", "lastmod": null, "content_type": null, "priority": "0.5", "loc": "https://python.langchain.com/docs/integrations/document_loaders/unstructured_pdfloader/", "uuid": "f896de9c-6074-587c-8ebd-21697b8fcf4e"}, "page_content": "```python\nprint(docs[0].metadata)\n```\n\n```output\n{'source': './example_data/layout-parser-paper.pdf'}\n```\n\n### Retain Elements\u200b\n\nUnder the hood, Unstructured creates different \"elements\" for different chunks of text. By default we combine those together, but you can easily keep that separation by specifying `mode=\"elements\"`.\n\n```python\nfile_path = \"./example_data/layout-parser-paper.pdf\"\nloader = UnstructuredPDFLoader(file_path, mode=\"elements\")\n\ndata = loader.load()\ndata[0]\n```\n\n```output\nDocument(metadata={'source': './example_data/layout-parser-paper.pdf', 'coordinates': {'points': ((16.34, 213.36), (16.34, 253.36), (36.34, 253.36), (36.34, 213.36)), 'system': 'PixelSpace', 'layout_width': 612, 'layout_height': 792}, 'file_directory': './example_data', 'filename': 'layout-parser-paper.pdf', 'languages': ['eng'], 'last_modified': '2024-07-25T21:28:58', 'page_number': 1, 'filetype': 'application/pdf', 'category': 'UncategorizedText', 'element_id': 'd3ce55f220dfb75891b4394a18bcb973'}, page_content='1 2 0 2')\n```\n\nSee the full set of element types for this particular document:\n\n```python\nset(doc.metadata[\"category\"] for doc in data)\n```\n\n```output\n{'ListItem', 'NarrativeText', 'Title', 'UncategorizedText'}\n```\n\n### Fetching remote PDFs using Unstructured\u200b\n\nThis covers how to load online PDFs into a document format that we can use downstream. This can be used for various online PDF sites such as [https://open.umn.edu/opentextbooks/textbooks/](https://open.umn.edu/opentextbooks/textbooks/) and [https://arxiv.org/archive/](https://arxiv.org/archive/)\n\nNote: all other PDF loaders can also be used to fetch remote PDFs, but `OnlinePDFLoader` is a legacy function, and works specifically with `UnstructuredPDFLoader`.\n\n```python\nfrom langchain_community.document_loaders import OnlinePDFLoader\n\nloader = OnlinePDFLoader(\"https://arxiv.org/pdf/2302.03803.pdf\")\ndata = loader.load()\ndata[0]\n```", "type": "Document"}, {"metadata": {"language": "en", "description": "DocumentLoaders load data into the standard LangChain Document format.", "changefreq": "weekly", "source": "https://python.langchain.com/docs/integrations/document_loaders/", "title": "Document loaders | \ud83e\udd9c\ufe0f\ud83d\udd17 LangChain", "content_type": null, "lastmod": null, "priority": "0.5", "loc": "https://python.langchain.com/docs/integrations/document_loaders/", "uuid": "cbcffc89-a3d2-5630-9fc5-b89ee88d3d68"}, "page_content": "#### Was this page helpful?\n\n- [Webpages](#webpages)\n\n- [PDFs](#pdfs)\n\n- [Cloud Providers](#cloud-providers)\n\n- [Social Platforms](#social-platforms)\n\n- [Messaging Services](#messaging-services)\n\n- [Productivity tools](#productivity-tools)\n\n- [Common File Types](#common-file-types)\n\n- [All document loaders](#all-document-loaders)", "type": "Document"}, {"metadata": {"description": "Overview", "language": "en", "changefreq": "weekly", "source": "https://python.langchain.com/docs/integrations/document_loaders/pdfminer/", "title": "PDFMiner | \ud83e\udd9c\ufe0f\ud83d\udd17 LangChain", "content_type": null, "lastmod": null, "priority": "0.5", "loc": "https://python.langchain.com/docs/integrations/document_loaders/pdfminer/", "uuid": "85d9d38c-a640-5f59-b00d-5ff43f93ac91"}, "page_content": "5 shows two examples of how\\n<br></span><span style=\"font-family: CMTT10; font-size:9px\">LayoutParser </span><span style=\"font-family: CMR10; font-size:9px\">can be used in practical DIA projects, and Section 6 concludes.\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:134px; top:1990px; width:102px; height:11px;\"><span style=\"font-family: CMBX12; font-size:11px\">2 Related Work\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:134px; top:2016px; width:347px; height:81px;\"><span style=\"font-family: CMR10; font-size:9px\">Recently, various DL models and datasets have been developed for layout analysis\\n<br>tasks. The dhSegment [22] utilizes fully convolutional networks [20] for segmen-\\n<br>tation tasks on historical documents. Object detection-based methods like Faster\\n<br>R-CNN [28] and Mask R-CNN [12] are used for identifying document elements [38]\\n<br>and detecting tables [30, 26]. Most recently, Graph Neural Networks [29] have also\\n<br>been used in table detection [27]. However, these models are usually implemented\\n<br>individually and there is no uni\ufb01ed framework to load and use such models.\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:134px; top:2100px; width:348px; height:189px;\"><span style=\"font-family: CMR10; font-size:9px\">There has been a surge of interest in creating open-source tools for document\\n<br>image processing: a search of </span><span style=\"font-family: CMTT10; font-size:9px\">document image analysis </span><span style=\"font-family: CMR10; font-size:9px\">in Github leads to 5M\\n<br>relevant code pieces </span><span style=\"font-family: CMR7; font-size:6px\">6</span><span style=\"font-family: CMR10; font-size:9px\">; yet most of them rely on traditional rule-based methods\\n<br>or provide limited functionalities. The closest prior research to our work is the\\n<br>OCR-D project</span><span style=\"font-family: CMR7; font-size:6px\">7</span><span style=\"font-family: CMR10; font-size:9px\">, which also tries to build a complete toolkit for DIA. However,\\n<br>similar to the platform developed by Neudecker et al. [21], it is designed for\\n<br>analyzing historical documents, and provides no supports for recent DL models.\\n<br>The </span><span style=\"font-family: CMTT10; font-size:9px\">DocumentLayoutAnalysis </span><span style=\"font-family: CMR10; font-size:9px\">project</span><span style=\"font-family: CMR7; font-size:6px\">8 </span><span style=\"font-family: CMR10; font-size:9px\">focuses on processing born-digital PDF\\n<br>documents via analyzing the stored PDF data. Repositories like </span><span style=\"font-family: CMTT10; font-size:9px\">DeepLayout</span><span style=\"font-family: CMR7; font-size:6px\">9\\n<br></span><span style=\"font-family: CMR10; font-size:9px\">and </span><span style=\"font-family: CMTT10; font-size:9px\">Detectron2-PubLayNet</span><span style=\"font-family: CMR7; font-size:6px\">10 </span><span style=\"font-family: CMR10; font-size:9px\">are individual deep learning models trained on\\n<br>layout analysis datasets without support for the full DIA pipeline. The Document\\n<br>Analysis and Exploitation (DAE) platform [15] and the DeepDIVA project [2]\\n<br>aim to improve the reproducibility of DIA methods (or DL models), yet they\\n<br>are not actively maintained. OCR engines like </span><span style=\"font-family: CMTT10; font-size:9px\">Tesseract </span><span style=\"font-family: CMR10; font-size:9px\">[14], </span><span style=\"font-family: CMTT10; font-size:9px\">easyOCR</span><span style=\"font-family: CMR7; font-size:6px\">11 </span><span style=\"font-family: CMR10; font-size:9px\">and\\n<br></span><span style=\"font-family: CMTT10; font-size:9px\">paddleOCR</span><span style=\"font-family: CMR7; font-size:6px\">12 </span><span style=\"font-family: CMR10; font-size:9px\">usually do not come with comprehensive functionalities for other\\n<br>DIA tasks like layout", "type": "Document"}, {"metadata": {"description": "Overview", "language": "en", "changefreq": "weekly", "source": "https://python.langchain.com/docs/integrations/document_loaders/pdfminer/", "title": "PDFMiner | \ud83e\udd9c\ufe0f\ud83d\udd17 LangChain", "lastmod": null, "content_type": null, "priority": "0.5", "loc": "https://python.langchain.com/docs/integrations/document_loaders/pdfminer/", "uuid": "c86c93ad-5ca1-59e1-8dfe-832cf69ffa35"}, "page_content": "CMR9; font-size:8px\">the maximum is 1.\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:133px; top:9955px; width:348px; height:10px;\"><span style=\"font-family: CMR6; font-size:5px\">17 </span><span style=\"font-family: CMR9; font-size:8px\">This measures the number of edits from the ground-truth text to the predicted text,\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:144px; top:9967px; width:78px; height:8px;\"><span style=\"font-family: CMR9; font-size:8px\">and lower is better.\\n<br></span></div><span style=\"position:absolute; border: black 1px solid; left:134px; top:9931px; width:56px; height:0px;\"></span>\\n<span style=\"position:absolute; border: gray 1px solid; left:0px; top:10154px; width:612px; height:792px;\"></span>\\n<div style=\"position:absolute; top:10154px;\"><a name=\"13\">Page 13</a></div>\\n<div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:237px; top:10246px; width:210px; height:9px;\"><span style=\"font-family: CMTT9; font-size:8px\">LayoutParser</span><span style=\"font-family: CMR9; font-size:8px\">: A Uni\ufb01ed Toolkit for DL-Based DIA\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:471px; top:10246px; width:9px; height:8px;\"><span style=\"font-family: CMR9; font-size:8px\">13\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:134px; top:10398px; width:346px; height:45px;\"><span style=\"font-family: CMR10; font-size:9px\">Fig. 6: This lightweight table detector can identify tables (outlined in red) and\\n<br>cells (shaded in blue) in di\ufb00erent locations on a page. In very few cases (d), it\\n<br>might generate minor error predictions, e.g, failing to capture the top text line of\\n<br></span><span style=\"font-family: CMR10; font-size:9px\">a table.\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:134px; top:10478px; width:216px; height:9px;\"><span style=\"font-family: CMBX10; font-size:9px\">5.2 A light-weight Visual Table Extractor\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:134px; top:10518px; width:347px; height:81px;\"><span style=\"font-family: CMR10; font-size:9px\">Detecting tables and parsing their structures (table extraction) are of central im-\\n<br>portance for many document digitization tasks. Many previous works [26, 30, 27]\\n<br>and tools </span><span style=\"font-family: CMR7; font-size:6px\">18 </span><span style=\"font-family: CMR10; font-size:9px\">have been developed to identify and parse table structures. Yet they\\n<br>might require training complicated models from scratch, or are only applicable\\n<br>for born-digital PDF documents. In this section, we show how </span><span style=\"font-family: CMTT10; font-size:9px\">LayoutParser </span><span style=\"font-family: CMR10; font-size:9px\">can\\n<br>help build a light-weight accurate visual table extractor for legal docket tables\\n<br>using the existing resources with minimal e\ufb00ort.\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:134px; top:10606px; width:347px; height:177px;\"><span style=\"font-family: CMR10; font-size:9px\">The extractor uses a pre-trained layout detection model for identifying the\\n<br>table regions and some simple rules for pairing the rows and the columns in the\\n<br>PDF image. Mask R-CNN [12] trained on the PubLayNet dataset [38] from the\\n<br></span><span style=\"font-family: CMTT10; font-size:9px\">LayoutParser </span><span style=\"font-family: CMR10; font-size:9px\">Model Zoo can be used for detecting table regions. By \ufb01ltering\\n<br>out model predictions of low con\ufb01dence and removing overlapping predictions,\\n<br></span><span style=\"font-family: CMTT10; font-size:9px\">LayoutParser </span><span style=\"font-family: CMR10; font-size:9px\">can identify the tabular", "type": "Document"}, {"metadata": {"description": "Portable Document Format (PDF), standardized as ISO 32000, is a file format developed by Adobe in 1992 to present documents, including text formatting and images, in a manner independent of application software, hardware, and operating systems.", "language": "en", "changefreq": "weekly", "source": "https://python.langchain.com/docs/how_to/document_loader_pdf/", "title": "How to load PDFs | \ud83e\udd9c\ufe0f\ud83d\udd17 LangChain", "content_type": null, "lastmod": null, "priority": "0.5", "loc": "https://python.langchain.com/docs/how_to/document_loader_pdf/", "uuid": "5a2a91d5-0d47-5a95-8791-d9a4adade490"}, "page_content": "```output\n{'source': '../../docs/integrations/document_loaders/example_data/layout-parser-paper.pdf', 'page': 0}\n\nLayoutParser : A Uni\ufb01ed Toolkit for Deep\nLearning Based Document Image Analysis\nZejiang Shen1( \ufffd), Ruochen Zhang2, Melissa Dell3, Benjamin Charles Germain\nLee4, Jacob Carlson3, and Weining Li5\n1Allen Institute for AI\nshannons@allenai.org\n2Brown University\nruochen zhang@brown.edu\n3Harvard University\n{melissadell,jacob carlson }@fas.harvard.edu\n4University of Washington\nbcgl@cs.washington.edu\n5University of Waterloo\nw422li@uwaterloo.ca\nAbstract. Recent advances in document image analysis (DIA) have been\nprimarily driven by the application of neural networks. Ideally, research\noutcomes could be easily deployed in production and extended for further\ninvestigation. However, various factors like loosely organized codebases\nand sophisticated model con\ufb01gurations complicate the easy reuse of im-\nportant innovations by a wide audience. Though there have been on-going\ne\ufb00orts to improve reusability and simplify deep learning (DL) model\ndevelopment in disciplines like natural language processing and computer\nvision, none of them are optimized for challenges in the domain of DIA.\nThis represents a major gap in the existing toolkit, as DIA is central to\nacademic research across a wide range of disciplines in the social sciences\nand humanities. This paper introduces LayoutParser , an open-source\nlibrary for streamlining the usage of DL in DIA research and applica-\ntions. The core LayoutParser library comes with a set of simple and\nintuitive interfaces for applying and customizing DL models for layout de-\ntection, character recognition, and many other document processing tasks.\nTo promote extensibility, LayoutParser also incorporates a community\nplatform for sharing both pre-trained models and full document digiti-\nzation pipelines. We demonstrate that LayoutParser is helpful for both\nlightweight and large-scale digitization pipelines in real-word use cases.\nThe library is publicly available at https://layout-parser.github.io .\nKeywords: Document Image Analysis \u00b7Deep Learning \u00b7Layout Analysis\n\u00b7Character Recognition \u00b7Open Source library \u00b7Toolkit.\n1 Introduction\nDeep Learning(DL)-based approaches are the state-of-the-art for a wide range of\ndocument image analysis (DIA) tasks including document image classi\ufb01cation [ 11,arXiv:2103.15348v2  [cs.CV]  21 Jun 2021\n```\n\nNote that the metadata of each document stores the corresponding page number.\n\n### Vector search over PDFs\u200b\n\nOnce we have loaded PDFs into LangChain `Document` objects, we can index them (e.g., a RAG application) in the usual way. Below we use OpenAI embeddings, although any LangChain [embeddings](https://python.langchain.com/docs/concepts/embedding_models) model will suffice.\n\n```python\n%pip install -qU langchain-openai\n```\n\n```python\nimport getpass\nimport os\n\nif \"OPENAI_API_KEY\" not in os.environ:\n    os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"OpenAI API Key:\")\n```\n\n```python\nfrom langchain_core.vectorstores import InMemoryVectorStore\nfrom langchain_openai import OpenAIEmbeddings\n\nvector_store = InMemoryVectorStore.from_documents(pages, OpenAIEmbeddings())\ndocs = vector_store.similarity_search(\"What is LayoutParser?\", k=2)\nfor doc in docs:\n    print(f'Page {doc.metadata[\"page\"]}: {doc.page_content[:300]}\\n')\n```\n\n**API Reference:**[InMemoryVectorStore](https://python.langchain.com/api_reference/core/vectorstores/langchain_core.vectorstores.in_memory.InMemoryVectorStore.html) | [OpenAIEmbeddings](https://python.langchain.com/api_reference/openai/embeddings/langchain_openai.embeddings.base.OpenAIEmbeddings.html)\n```output\nPage 13: 14 Z. Shen et al.\n6 Conclusion\nLayoutParser provides a comprehensive toolkit for deep learning-based document\nimage analysis. The o\ufb00-the-shelf library is easy to install, and can be used to\nbuild \ufb02exible and accurate pipelines for processing documents with complicated\nstructures. It also supports hi", "type": "Document"}, {"metadata": {"language": "en", "description": "The pace of AI application development is often rate-limited by high-quality evaluations because there is a paradox of choice. Developers often wonder how to engineer their prompt or which LLM best balances accuracy, latency, and cost. High quality evaluations can help you rapidly answer these types of questions with confidence.", "changefreq": null, "source": "https://docs.smith.langchain.com/evaluation/concepts", "title": "Concepts | \ud83e\udd9c\ufe0f\ud83d\udee0\ufe0f LangSmith", "content_type": "text/html; charset=utf-8", "lastmod": null, "priority": null, "loc": null, "uuid": "e07006e1-3edd-5630-8851-49f0e2518263"}, "page_content": "Use CaseDetailReference-free?LLM-as-judge?Pairwise relevantCriteriaTag if specific criteria is metYesYes - promptNoAccuracyStandard definitionNo (ground truth class)NoNoPrecisionStandard definitionNo (ground truth class)NoNoRecallStandard definitionNo (ground truth class)NoNoWas this page helpful?You can leave detailed feedback on GitHub.PreviousQuick StartNextEvaluation how-to guidesDatasetsCreating datasetsPartitioning datasetsEvaluatorsHumanHeuristicLLM-as-judgePairwiseApplying evaluationsUnit TestsRegression TestingBack-testingPairwise-testingOnline EvaluationExperiment ConfigurationsAgentsEvaluating an agent's final responseEvaluating a single step of an agentEvaluating an agent's trajectoryBest practicesRetrieval Augmented Generation (RAG)DatasetEvaluatorApplying RAG EvaluationRAG evaluation summaryCommon use-casesSummarizationClassification / TaggingCommunityDiscordTwitterGitHubDocs CodeLangSmith SDKPythonJS/TSMoreHomepageBlogLangChain Python DocsLangChain JS/TS DocsCopyright \u00a9 2024 LangChain, Inc.", "type": "Document"}, {"metadata": {"description": "AnalyticDB for PostgreSQL is a massively parallel processing (MPP) data warehousing service that is designed to analyze large volumes of data online.", "language": "en", "changefreq": "weekly", "source": "https://python.langchain.com/docs/integrations/vectorstores/analyticdb/", "title": "AnalyticDB | \ud83e\udd9c\ufe0f\ud83d\udd17 LangChain", "content_type": null, "lastmod": null, "priority": "0.5", "loc": "https://python.langchain.com/docs/integrations/vectorstores/analyticdb/", "uuid": "602e584b-8d9f-574d-9391-97abe4a39b64"}, "page_content": "Tonight, I\u2019d like to honor someone who has dedicated his life to serve this country: Justice Stephen Breyer\u2014an Army veteran, Constitutional scholar, and retiring Justice of the United States Supreme Court. Justice Breyer, thank you for your service. \n\nOne of the most serious constitutional responsibilities a President has is nominating someone to serve on the United States Supreme Court. \n\nAnd I did that 4 days ago, when I nominated Circuit Court of Appeals Judge Ketanji Brown Jackson. One of our nation\u2019s top legal minds, who will continue Justice Breyer\u2019s legacy of excellence.\n```\n\n## Related\u200b\n\n- Vector store [conceptual guide](/docs/concepts/vectorstores/)\n\n- Vector store [how-to guides](/docs/how_to/#vector-stores)\n\n#### Was this page helpful?\n\n- [Related](#related)", "type": "Document"}, {"metadata": {"description": "Hologres is a unified real-time data warehousing service developed by Alibaba Cloud. You can use Hologres to write, update, process, and analyze large amounts of data in real time.", "language": "en", "changefreq": "weekly", "source": "https://python.langchain.com/docs/integrations/vectorstores/hologres/", "title": "Hologres | \ud83e\udd9c\ufe0f\ud83d\udd17 LangChain", "content_type": null, "lastmod": null, "priority": "0.5", "loc": "https://python.langchain.com/docs/integrations/vectorstores/hologres/", "uuid": "ab394f69-6b1c-5a06-8672-ad6c91feda6f"}, "page_content": "Tonight, I\u2019d like to honor someone who has dedicated his life to serve this country: Justice Stephen Breyer\u2014an Army veteran, Constitutional scholar, and retiring Justice of the United States Supreme Court. Justice Breyer, thank you for your service. \n\nOne of the most serious constitutional responsibilities a President has is nominating someone to serve on the United States Supreme Court. \n\nAnd I did that 4 days ago, when I nominated Circuit Court of Appeals Judge Ketanji Brown Jackson. One of our nation\u2019s top legal minds, who will continue Justice Breyer\u2019s legacy of excellence.\n```\n\n## Related\u200b\n\n- Vector store [conceptual guide](/docs/concepts/vectorstores/)\n\n- Vector store [how-to guides](/docs/how_to/#vector-stores)\n\n#### Was this page helpful?\n\n- [Related](#related)", "type": "Document"}, {"metadata": {"description": "One challenge with retrieval is that usually you don't know the specific queries your document storage system will face when you ingest data into the system. This means that the information most relevant to a query may be buried in a document with a lot of irrelevant text. Passing that full document through your application can lead to more expensive LLM calls and poorer responses.", "language": "en", "changefreq": "weekly", "source": "https://python.langchain.com/docs/how_to/contextual_compression/", "title": "How to do retrieval with contextual compression | \ud83e\udd9c\ufe0f\ud83d\udd17 LangChain", "lastmod": null, "content_type": null, "priority": "0.5", "loc": "https://python.langchain.com/docs/how_to/contextual_compression/", "uuid": "0e224cfa-3f17-580f-83cd-030c2df600c0"}, "page_content": "compressed_docs = compression_retriever.invoke(\n    \"What did the president say about Ketanji Jackson Brown\"\n)\npretty_print_docs(compressed_docs)\n```\n\n**API Reference:**[LLMListwiseRerank](https://python.langchain.com/api_reference/langchain/retrievers/langchain.retrievers.document_compressors.listwise_rerank.LLMListwiseRerank.html) | [ChatOpenAI](https://python.langchain.com/api_reference/openai/chat_models/langchain_openai.chat_models.base.ChatOpenAI.html)\n```output\nDocument 1:\n\nTonight. I call on the Senate to: Pass the Freedom to Vote Act. Pass the John Lewis Voting Rights Act. And while you\u2019re at it, pass the Disclose Act so Americans can know who is funding our elections. \n\nTonight, I\u2019d like to honor someone who has dedicated his life to serve this country: Justice Stephen Breyer\u2014an Army veteran, Constitutional scholar, and retiring Justice of the United States Supreme Court. Justice Breyer, thank you for your service. \n\nOne of the most serious constitutional responsibilities a President has is nominating someone to serve on the United States Supreme Court. \n\nAnd I did that 4 days ago, when I nominated Circuit Court of Appeals Judge Ketanji Brown Jackson. One of our nation\u2019s top legal minds, who will continue Justice Breyer\u2019s legacy of excellence.\n```\n\n### EmbeddingsFilter\u200b\n\nMaking an extra LLM call over each retrieved document is expensive and slow. The `EmbeddingsFilter` provides a cheaper and faster option by embedding the documents and query and only returning those documents which have sufficiently similar embeddings to the query.\n\n```python\nfrom langchain.retrievers.document_compressors import EmbeddingsFilter\nfrom langchain_openai import OpenAIEmbeddings\n\nembeddings = OpenAIEmbeddings()\nembeddings_filter = EmbeddingsFilter(embeddings=embeddings, similarity_threshold=0.76)\ncompression_retriever = ContextualCompressionRetriever(\n    base_compressor=embeddings_filter, base_retriever=retriever\n)\n\ncompressed_docs = compression_retriever.invoke(\n    \"What did the president say about Ketanji Jackson Brown\"\n)\npretty_print_docs(compressed_docs)\n```\n\n**API Reference:**[EmbeddingsFilter](https://python.langchain.com/api_reference/langchain/retrievers/langchain.retrievers.document_compressors.embeddings_filter.EmbeddingsFilter.html) | [OpenAIEmbeddings](https://python.langchain.com/api_reference/openai/embeddings/langchain_openai.embeddings.base.OpenAIEmbeddings.html)\n```output\nDocument 1:\n\nTonight. I call on the Senate to: Pass the Freedom to Vote Act. Pass the John Lewis Voting Rights Act. And while you\u2019re at it, pass the Disclose Act so Americans can know who is funding our elections. \n\nTonight, I\u2019d like to honor someone who has dedicated his life to serve this country: Justice Stephen Breyer\u2014an Army veteran, Constitutional scholar, and retiring Justice of the United States Supreme Court. Justice Breyer, thank you for your service. \n\nOne of the most serious constitutional responsibilities a President has is nominating someone to serve on the United States Supreme Court. \n\nAnd I did that 4 days ago, when I nominated Circuit Court of Appeals Judge Ketanji Brown Jackson. One of our nation\u2019s top legal minds, who will continue Justice Breyer\u2019s legacy of excellence.\n----------------------------------------------------------------------------------------------------\nDocument 2:\n\nA former top litigator in private practice. A former federal public defender. And from a family of public school educators and police officers. A consensus builder. Since she\u2019s been nominated, she\u2019s received a broad range of support\u2014from the Fraternal Order of Police to former judges appointed by Democrats and Republicans. \n\nAnd if we are to advance liberty and justice, we need to secure the Border and fix the immigration system. \n\nWe can do both. At our border, we\u2019ve installed new technology like cutting-edge scanners to better detect drug smuggling.  \n\nWe\u2019ve set up joint patrols with Mexico and Guatemala to catch more human traffickers.", "type": "Document"}, {"metadata": {"description": "This notebook shows how to use DashScope Reranker for document compression and retrieval. DashScope is the generative AI service from Alibaba Cloud (Aliyun).", "language": "en", "changefreq": "weekly", "source": "https://python.langchain.com/docs/integrations/document_transformers/dashscope_rerank/", "title": "DashScope Reranker | \ud83e\udd9c\ufe0f\ud83d\udd17 LangChain", "content_type": null, "lastmod": null, "priority": "0.5", "loc": "https://python.langchain.com/docs/integrations/document_transformers/dashscope_rerank/", "uuid": "a9da7658-305c-5a2e-8f60-e5c6cc7296c2"}, "page_content": "One of the most serious constitutional responsibilities a President has is nominating someone to serve on the United States Supreme Court. \n\nAnd I did that 4 days ago, when I nominated Circuit Court of Appeals Judge Ketanji Brown Jackson. One of our nation\u2019s top legal minds, who will continue Justice Breyer\u2019s legacy of excellence.\n----------------------------------------------------------------------------------------------------\nDocument 3:\n\nTo all Americans, I will be honest with you, as I\u2019ve always promised. A Russian dictator, invading a foreign country, has costs around the world. \n\nAnd I\u2019m taking robust action to make sure the pain of our sanctions  is targeted at Russia\u2019s economy. And I will use every tool at our disposal to protect American businesses and consumers. \n\nTonight, I can announce that the United States has worked with 30 other countries to release 60 Million barrels of oil from reserves around the world.\n----------------------------------------------------------------------------------------------------\nDocument 4:\n\nWe cannot let this happen. \n\nTonight. I call on the Senate to: Pass the Freedom to Vote Act. Pass the John Lewis Voting Rights Act. And while you\u2019re at it, pass the Disclose Act so Americans can know who is funding our elections. \n\nTonight, I\u2019d like to honor someone who has dedicated his life to serve this country: Justice Stephen Breyer\u2014an Army veteran, Constitutional scholar, and retiring Justice of the United States Supreme Court. Justice Breyer, thank you for your service.\n----------------------------------------------------------------------------------------------------\nDocument 5:\n\nTonight I say to the Russian oligarchs and corrupt leaders who have bilked billions of dollars off this violent regime no more. \n\nThe U.S. Department of Justice is assembling a dedicated task force to go after the crimes of Russian oligarchs.  \n\nWe are joining with our European allies to find and seize your yachts your luxury apartments your private jets. We are coming for your ill-begotten gains.\n----------------------------------------------------------------------------------------------------\nDocument 6:\n\nEvery Administration says they\u2019ll do it, but we are actually doing it. \n\nWe will buy American to make sure everything from the deck of an aircraft carrier to the steel on highway guardrails are made in America. \n\nBut to compete for the best jobs of the future, we also need to level the playing field with China and other competitors.\n----------------------------------------------------------------------------------------------------\nDocument 7:\n\nWhen we invest in our workers, when we build the economy from the bottom up and the middle out together, we can do something we haven\u2019t done in a long time: build a better America. \n\nFor more than two years, COVID-19 has impacted every decision in our lives and the life of the nation. \n\nAnd I know you\u2019re tired, frustrated, and exhausted. \n\nBut I also know this.\n----------------------------------------------------------------------------------------------------\nDocument 8:\n\nA former top litigator in private practice. A former federal public defender. And from a family of public school educators and police officers. A consensus builder. Since she\u2019s been nominated, she\u2019s received a broad range of support\u2014from the Fraternal Order of Police to former judges appointed by Democrats and Republicans. \n\nAnd if we are to advance liberty and justice, we need to secure the Border and fix the immigration system.\n----------------------------------------------------------------------------------------------------\nDocument 9:\n\nMy plan will not only lower costs to give families a fair shot, it will lower the deficit. \n\nThe previous Administration not only ballooned the deficit with tax cuts for the very wealthy and corporations, it undermined the watchdogs whose job was to keep pandemic relief funds from being wasted.", "type": "Document"}, {"metadata": {"description": "When splitting documents for retrieval, there are often conflicting desires:", "language": "en", "changefreq": "weekly", "source": "https://python.langchain.com/docs/how_to/parent_document_retriever/", "title": "How to use the Parent Document Retriever | \ud83e\udd9c\ufe0f\ud83d\udd17 LangChain", "lastmod": null, "content_type": null, "priority": "0.5", "loc": "https://python.langchain.com/docs/how_to/parent_document_retriever/", "uuid": "5c24f9cf-90e6-52f4-8da6-d8535cfad74d"}, "page_content": "```python\nretrieved_docs = retriever.invoke(\"justice breyer\")\n```\n\n```python\nlen(retrieved_docs[0].page_content)\n```\n\n```output\n38540\n```\n\n## Retrieving larger chunks\u200b\n\nSometimes, the full documents can be too big to want to retrieve them as is. In that case, what we really want to do is to first split the raw documents into larger chunks, and then split it into smaller chunks. We then index the smaller chunks, but on retrieval we retrieve the larger chunks (but still not the full documents).\n\n```python\n# This text splitter is used to create the parent documents\nparent_splitter = RecursiveCharacterTextSplitter(chunk_size=2000)\n# This text splitter is used to create the child documents\n# It should create documents smaller than the parent\nchild_splitter = RecursiveCharacterTextSplitter(chunk_size=400)\n# The vectorstore to use to index the child chunks\nvectorstore = Chroma(\n    collection_name=\"split_parents\", embedding_function=OpenAIEmbeddings()\n)\n# The storage layer for the parent documents\nstore = InMemoryStore()\n```\n\n```python\nretriever = ParentDocumentRetriever(\n    vectorstore=vectorstore,\n    docstore=store,\n    child_splitter=child_splitter,\n    parent_splitter=parent_splitter,\n)\n```\n\n```python\nretriever.add_documents(docs)\n```\n\nWe can see that there are much more than two documents now - these are the larger chunks.\n\n```python\nlen(list(store.yield_keys()))\n```\n\n```output\n66\n```\n\nLet's make sure the underlying vector store still retrieves the small chunks.\n\n```python\nsub_docs = vectorstore.similarity_search(\"justice breyer\")\n```\n\n```python\nprint(sub_docs[0].page_content)\n```\n\n```output\nTonight, I\u2019d like to honor someone who has dedicated his life to serve this country: Justice Stephen Breyer\u2014an Army veteran, Constitutional scholar, and retiring Justice of the United States Supreme Court. Justice Breyer, thank you for your service. \n\nOne of the most serious constitutional responsibilities a President has is nominating someone to serve on the United States Supreme Court.\n```\n\n```python\nretrieved_docs = retriever.invoke(\"justice breyer\")\n```\n\n```python\nlen(retrieved_docs[0].page_content)\n```\n\n```output\n1849\n```\n\n```python\nprint(retrieved_docs[0].page_content)\n```\n\n```output\nIn state after state, new laws have been passed, not only to suppress the vote, but to subvert entire elections. \n\nWe cannot let this happen. \n\nTonight. I call on the Senate to: Pass the Freedom to Vote Act. Pass the John Lewis Voting Rights Act. And while you\u2019re at it, pass the Disclose Act so Americans can know who is funding our elections. \n\nTonight, I\u2019d like to honor someone who has dedicated his life to serve this country: Justice Stephen Breyer\u2014an Army veteran, Constitutional scholar, and retiring Justice of the United States Supreme Court. Justice Breyer, thank you for your service. \n\nOne of the most serious constitutional responsibilities a President has is nominating someone to serve on the United States Supreme Court. \n\nAnd I did that 4 days ago, when I nominated Circuit Court of Appeals Judge Ketanji Brown Jackson. One of our nation\u2019s top legal minds, who will continue Justice Breyer\u2019s legacy of excellence. \n\nA former top litigator in private practice. A former federal public defender. And from a family of public school educators and police officers. A consensus builder. Since she\u2019s been nominated, she\u2019s received a broad range of support\u2014from the Fraternal Order of Police to former judges appointed by Democrats and Republicans. \n\nAnd if we are to advance liberty and justice, we need to secure the Border and fix the immigration system. \n\nWe can do both. At our border, we\u2019ve installed new technology like cutting-edge scanners to better detect drug smuggling.  \n\nWe\u2019ve set up joint patrols with Mexico and Guatemala to catch more human traffickers.  \n\nWe\u2019re putting in place dedicated immigration judges so families fleeing persecution and violence can have their cases heard faster.", "type": "Document"}, {"metadata": {"description": "UpTrain [github || website || docs] is an open-source platform to evaluate and improve LLM applications. It provides grades for 20+ preconfigured checks (covering language, code, embedding use cases), performs root cause analyses on instances of failure cases and provides guidance for resolving them.", "language": "en", "changefreq": "weekly", "source": "https://python.langchain.com/docs/integrations/callbacks/uptrain/", "title": "uptrain | \ud83e\udd9c\ufe0f\ud83d\udd17 LangChain", "lastmod": null, "content_type": null, "priority": "0.5", "loc": "https://python.langchain.com/docs/integrations/callbacks/uptrain/", "uuid": "6c5602df-140a-5c31-b5f5-cc188744c2ee"}, "page_content": "Question: What did the president say about Ketanji Brown Jackson\nResponse: The president mentioned that he had nominated Ketanji Brown Jackson to serve on the United States Supreme Court 4 days ago. He described her as one of the nation's top legal minds who will continue Justice Breyer\u2019s legacy of excellence. He also mentioned that she is a former top litigator in private practice, a former federal public defender, and comes from a family of public school educators and police officers. He described her as a consensus builder and noted that since her nomination, she has received a broad range of support from various groups, including the Fraternal Order of Police and former judges appointed by both Democrats and Republicans.\n\nContext Relevance Score: 1.0\nFactual Accuracy Score: 1.0\nResponse Completeness Score: 1.0\n```\n\n# 2. Multi Query Generation\n\nThe **MultiQueryRetriever** is used to tackle the problem that the RAG pipeline might not return the best set of documents based on the query. It generates multiple queries that mean the same as the original query and then fetches documents for each.\n\nTo evluate this retriever, UpTrain will run the following evaluation:\n\n- **Multi Query Accuracy**: Checks if the multi-queries generated mean the same as the original query.\n\n```python\n# Create the retriever\nmulti_query_retriever = MultiQueryRetriever.from_llm(retriever=retriever, llm=llm)\n\n# Create the uptrain callback\nuptrain_callback = UpTrainCallbackHandler(key_type=KEY_TYPE, api_key=API_KEY)\nconfig = {\"callbacks\": [uptrain_callback]}\n\n# Create the RAG prompt\ntemplate = \"\"\"Answer the question based only on the following context, which can include text and tables:\n{context}\nQuestion: {question}\n\"\"\"\nrag_prompt_text = ChatPromptTemplate.from_template(template)\n\nchain = (\n    {\"context\": multi_query_retriever, \"question\": RunnablePassthrough()}\n    | rag_prompt_text\n    | llm\n    | StrOutputParser()\n)\n\n# Invoke the chain with a query\nquestion = \"What did the president say about Ketanji Brown Jackson\"\ndocs = chain.invoke(question, config=config)\n```\n\n```output\n[32m2024-04-17 17:04:10.675[0m | [1mINFO    [0m | [36muptrain.framework.evalllm[0m:[36mevaluate_on_server[0m:[36m378[0m - [1mSending evaluation request for rows 0 to <50 to the Uptrain[0m\n[32m2024-04-17 17:04:16.804[0m | [1mINFO    [0m | [36muptrain.framework.evalllm[0m:[36mevaluate[0m:[36m367[0m - [1mLocal server not running, start the server to log data and visualize in the dashboard![0m\n``````output\n\nQuestion: What did the president say about Ketanji Brown Jackson\nMulti Queries:\n  - How did the president comment on Ketanji Brown Jackson?\n  - What were the president's remarks regarding Ketanji Brown Jackson?\n  - What statements has the president made about Ketanji Brown Jackson?\n\nMulti Query Accuracy Score: 0.5\n``````output\n[32m2024-04-17 17:04:22.027[0m | [1mINFO    [0m | [36muptrain.framework.evalllm[0m:[36mevaluate_on_server[0m:[36m378[0m - [1mSending evaluation request for rows 0 to <50 to the Uptrain[0m\n[32m2024-04-17 17:04:44.033[0m | [1mINFO    [0m | [36muptrain.framework.evalllm[0m:[36mevaluate[0m:[36m367[0m - [1mLocal server not running, start the server to log data and visualize in the dashboard![0m\n``````output\n\nQuestion: What did the president say about Ketanji Brown Jackson\nResponse: The president mentioned that he had nominated Circuit Court of Appeals Judge Ketanji Brown Jackson to serve on the United States Supreme Court 4 days ago. He described her as one of the nation's top legal minds who will continue Justice Breyer\u2019s legacy of excellence. He also mentioned that since her nomination, she has received a broad range of support\u2014from the Fraternal Order of Police to former judges appointed by Democrats and Republicans.\n\nContext Relevance Score: 1.0\nFactual Accuracy Score: 1.0\nResponse Completeness Score: 1.0\n```\n\n# 3. Context Compression and Reranking", "type": "Document"}, {"metadata": {"language": "en", "description": "Timescale Vector is PostgreSQL++ vector database for AI applications.", "changefreq": "weekly", "source": "https://python.langchain.com/docs/integrations/vectorstores/timescalevector/", "title": "Timescale Vector (Postgres) | \ud83e\udd9c\ufe0f\ud83d\udd17 LangChain", "content_type": null, "lastmod": null, "priority": "0.5", "loc": "https://python.langchain.com/docs/integrations/vectorstores/timescalevector/", "uuid": "97b75c76-ec70-52a3-a5bc-f34f7df23687"}, "page_content": "Tonight, I\u2019d like to honor someone who has dedicated his life to serve this country: Justice Stephen Breyer\u2014an Army veteran, Constitutional scholar, and retiring Justice of the United States Supreme Court. Justice Breyer, thank you for your service. \n\nOne of the most serious constitutional responsibilities a President has is nominating someone to serve on the United States Supreme Court. \n\nAnd I did that 4 days ago, when I nominated Circuit Court of Appeals Judge Ketanji Brown Jackson. One of our nation\u2019s top legal minds, who will continue Justice Breyer\u2019s legacy of excellence.\n--------------------------------------------------------------------------------\n--------------------------------------------------------------------------------\nScore:  0.18452197313308139\nTonight. I call on the Senate to: Pass the Freedom to Vote Act. Pass the John Lewis Voting Rights Act. And while you\u2019re at it, pass the Disclose Act so Americans can know who is funding our elections. \n\nTonight, I\u2019d like to honor someone who has dedicated his life to serve this country: Justice Stephen Breyer\u2014an Army veteran, Constitutional scholar, and retiring Justice of the United States Supreme Court. Justice Breyer, thank you for your service. \n\nOne of the most serious constitutional responsibilities a President has is nominating someone to serve on the United States Supreme Court. \n\nAnd I did that 4 days ago, when I nominated Circuit Court of Appeals Judge Ketanji Brown Jackson. One of our nation\u2019s top legal minds, who will continue Justice Breyer\u2019s legacy of excellence.\n--------------------------------------------------------------------------------\n--------------------------------------------------------------------------------\nScore:  0.21720781018594182\nA former top litigator in private practice. A former federal public defender. And from a family of public school educators and police officers. A consensus builder. Since she\u2019s been nominated, she\u2019s received a broad range of support\u2014from the Fraternal Order of Police to former judges appointed by Democrats and Republicans. \n\nAnd if we are to advance liberty and justice, we need to secure the Border and fix the immigration system. \n\nWe can do both. At our border, we\u2019ve installed new technology like cutting-edge scanners to better detect drug smuggling.  \n\nWe\u2019ve set up joint patrols with Mexico and Guatemala to catch more human traffickers.  \n\nWe\u2019re putting in place dedicated immigration judges so families fleeing persecution and violence can have their cases heard faster. \n\nWe\u2019re securing commitments and supporting partners in South and Central America to host more refugees and secure their own borders.\n--------------------------------------------------------------------------------\n--------------------------------------------------------------------------------\nScore:  0.21724902288621384\nA former top litigator in private practice. A former federal public defender. And from a family of public school educators and police officers. A consensus builder. Since she\u2019s been nominated, she\u2019s received a broad range of support\u2014from the Fraternal Order of Police to former judges appointed by Democrats and Republicans. \n\nAnd if we are to advance liberty and justice, we need to secure the Border and fix the immigration system. \n\nWe can do both. At our border, we\u2019ve installed new technology like cutting-edge scanners to better detect drug smuggling.  \n\nWe\u2019ve set up joint patrols with Mexico and Guatemala to catch more human traffickers.  \n\nWe\u2019re putting in place dedicated immigration judges so families fleeing persecution and violence can have their cases heard faster. \n\nWe\u2019re securing commitments and supporting partners in South and Central America to host more refugees and secure their own borders.\n--------------------------------------------------------------------------------\n```\n\n### Using a Timescale Vector as a Retriever\u200b", "type": "Document"}, {"metadata": {"description": "Intel's VDMS is a storage solution for efficient access of big-\u201dvisual\u201d-data that aims to achieve cloud scale by searching for relevant visual data via visual metadata stored as a graph and enabling machine friendly enhancements to visual data for faster access. VDMS is licensed under MIT.", "language": "en", "changefreq": "weekly", "source": "https://python.langchain.com/docs/integrations/vectorstores/vdms/", "title": "Intel's Visual Data Management System (VDMS) | \ud83e\udd9c\ufe0f\ud83d\udd17 LangChain", "lastmod": null, "content_type": null, "priority": "0.5", "loc": "https://python.langchain.com/docs/integrations/vectorstores/vdms/", "uuid": "4f15705d-8620-58e1-9dfd-0218bc8b858c"}, "page_content": "Metadata:\n\tid:\t32\n\tpage_number:\t32\n\tpresident_included:\tTrue\n\tsource:\t../../how_to/state_of_the_union.txt\n--------------------------------------------------\n\nContent:\n\tAs Frances Haugen, who is here with us tonight, has shown, we must hold social media platforms accountable for the national experiment they\u2019re conducting on our children for profit. \n\nIt\u2019s time to strengthen privacy protections, ban targeted advertising to children, demand tech companies stop collecting personal data on our children. \n\nAnd let\u2019s get all Americans the mental health services they need. More people they can turn to for help, and full parity between physical and mental health care. \n\nThird, support our veterans. \n\nVeterans are the best of us. \n\nI\u2019ve always believed that we have a sacred obligation to equip all those we send to war and care for them and their families when they come home. \n\nMy administration is providing assistance with job training and housing, and now helping lower-income veterans get VA care debt-free.  \n\nOur troops in Iraq and Afghanistan faced many dangers.\n\nMetadata:\n\tid:\t37\n\tpage_number:\t37\n\tpresident_included:\tFalse\n\tsource:\t../../how_to/state_of_the_union.txt\n--------------------------------------------------\n\nContent:\n\tA former top litigator in private practice. A former federal public defender. And from a family of public school educators and police officers. A consensus builder. Since she\u2019s been nominated, she\u2019s received a broad range of support\u2014from the Fraternal Order of Police to former judges appointed by Democrats and Republicans. \n\nAnd if we are to advance liberty and justice, we need to secure the Border and fix the immigration system. \n\nWe can do both. At our border, we\u2019ve installed new technology like cutting-edge scanners to better detect drug smuggling.  \n\nWe\u2019ve set up joint patrols with Mexico and Guatemala to catch more human traffickers.  \n\nWe\u2019re putting in place dedicated immigration judges so families fleeing persecution and violence can have their cases heard faster. \n\nWe\u2019re securing commitments and supporting partners in South and Central America to host more refugees and secure their own borders.\n\nMetadata:\n\tid:\t33\n\tpage_number:\t33\n\tpresident_included:\tFalse\n\tsource:\t../../how_to/state_of_the_union.txt\n--------------------------------------------------\n```\n\n```python\n# Query (with filtering)\nk = 3\nconstraints = {\"page_number\": [\">\", 30], \"president_included\": [\"==\", True]}\nquery = \"What did the president say about Ketanji Brown Jackson\"\nreturned_docs = db_FaissFlat.similarity_search(query, k=k, filter=constraints)\nprint_results(returned_docs, score=False)\n```\n\n```output\n--------------------------------------------------\n\nContent:\n\tTonight. I call on the Senate to: Pass the Freedom to Vote Act. Pass the John Lewis Voting Rights Act. And while you\u2019re at it, pass the Disclose Act so Americans can know who is funding our elections. \n\nTonight, I\u2019d like to honor someone who has dedicated his life to serve this country: Justice Stephen Breyer\u2014an Army veteran, Constitutional scholar, and retiring Justice of the United States Supreme Court. Justice Breyer, thank you for your service. \n\nOne of the most serious constitutional responsibilities a President has is nominating someone to serve on the United States Supreme Court. \n\nAnd I did that 4 days ago, when I nominated Circuit Court of Appeals Judge Ketanji Brown Jackson. One of our nation\u2019s top legal minds, who will continue Justice Breyer\u2019s legacy of excellence.\n\nMetadata:\n\tid:\t32\n\tpage_number:\t32\n\tpresident_included:\tTrue\n\tsource:\t../../how_to/state_of_the_union.txt\n--------------------------------------------------\n\nContent:\n\tAnd for our LGBTQ+ Americans, let\u2019s finally get the bipartisan Equality Act to my desk. The onslaught of state laws targeting transgender Americans and their families is wrong.", "type": "Document"}, {"metadata": {"description": "When working with files, like PDFs, you're likely to encounter text that exceeds your language model's context window. To process this text, consider these strategies:", "language": "en", "changefreq": "weekly", "source": "https://python.langchain.com/docs/how_to/extraction_long_text/", "title": "How to handle long text when doing extraction | \ud83e\udd9c\ufe0f\ud83d\udd17 LangChain", "content_type": null, "lastmod": null, "priority": "0.5", "loc": "https://python.langchain.com/docs/how_to/extraction_long_text/", "uuid": "7dfd32a5-8904-50c5-b15c-624f51caf4e1"}, "page_content": "We suggest experimenting with your use case and determining whether this approach works or not.\n\nTo implement the RAG based approach:\n\n1. Chunk up your document(s) and index them (e.g., in a vectorstore);\n\n2. Prepend the `extractor` chain with a retrieval step using the vectorstore.\n\nHere's a simple example that relies on the `FAISS` vectorstore.\n\n```python\nfrom langchain_community.vectorstores import FAISS\nfrom langchain_core.documents import Document\nfrom langchain_core.runnables import RunnableLambda\nfrom langchain_openai import OpenAIEmbeddings\nfrom langchain_text_splitters import CharacterTextSplitter\n\ntexts = text_splitter.split_text(document.page_content)\nvectorstore = FAISS.from_texts(texts, embedding=OpenAIEmbeddings())\n\nretriever = vectorstore.as_retriever(\n    search_kwargs={\"k\": 1}\n)  # Only extract from first document\n```\n\n**API Reference:**[FAISS](https://python.langchain.com/api_reference/community/vectorstores/langchain_community.vectorstores.faiss.FAISS.html) | [Document](https://python.langchain.com/api_reference/core/documents/langchain_core.documents.base.Document.html) | [RunnableLambda](https://python.langchain.com/api_reference/core/runnables/langchain_core.runnables.base.RunnableLambda.html) | [OpenAIEmbeddings](https://python.langchain.com/api_reference/openai/embeddings/langchain_openai.embeddings.base.OpenAIEmbeddings.html) | [CharacterTextSplitter](https://python.langchain.com/api_reference/text_splitters/character/langchain_text_splitters.character.CharacterTextSplitter.html)\nIn this case the RAG extractor is only looking at the top document.\n\n```python\nrag_extractor = {\n    \"text\": retriever | (lambda docs: docs[0].page_content)  # fetch content of top doc\n} | extractor\n```\n\n```python\nresults = rag_extractor.invoke(\"Key developments associated with cars\")\n```\n\n```python\nfor key_development in results.key_developments:\n    print(key_development)\n```\n\n```output\nyear=2006 description='Car-sharing services in the US experienced double-digit growth in revenue and membership.' evidence='in the US, some car-sharing services have experienced double-digit growth in revenue and membership growth between 2006 and 2007.'\nyear=2020 description='56 million cars were manufactured worldwide, with China producing the most.' evidence='In 2020, there were 56 million cars manufactured worldwide, down from 67 million the previous year. The automotive industry in China produces by far the most (20 million in 2020).'\n```\n\n## Common issues\u200b\n\nDifferent methods have their own pros and cons related to cost, speed, and accuracy.\n\nWatch out for these issues:\n\n- Chunking content means that the LLM can fail to extract information if the information is spread across multiple chunks.\n\n- Large chunk overlap may cause the same information to be extracted twice, so be prepared to de-duplicate!\n\n- LLMs can make up data. If looking for a single fact across a large text and using a brute force approach, you may end up getting more made up data.\n\n#### Was this page helpful?\n\n- [Setup](#setup)\n\n- [Define the schema](#define-the-schema)\n\n- [Create an extractor](#create-an-extractor)\n\n- [Brute force approach](#brute-force-approach)- [Merge results](#merge-results)\n\n- [RAG based approach](#rag-based-approach)\n\n- [Common issues](#common-issues)", "type": "Document"}, {"metadata": {"description": "When working with files, like PDFs, you're likely to encounter text that exceeds your language model's context window. To process this text, consider these strategies:", "language": "en", "changefreq": "weekly", "source": "https://python.langchain.com/docs/how_to/extraction_long_text/", "title": "How to handle long text when doing extraction | \ud83e\udd9c\ufe0f\ud83d\udd17 LangChain", "lastmod": null, "content_type": null, "priority": "0.5", "loc": "https://python.langchain.com/docs/how_to/extraction_long_text/", "uuid": "5c687db0-8502-5dc9-8617-22f2d5ecf7f1"}, "page_content": "```python\nkey_developments = []\n\nfor extraction in extractions:\n    key_developments.extend(extraction.key_developments)\n\nkey_developments[:10]\n```\n\n```output\n[KeyDevelopment(year=1769, description='Nicolas-Joseph Cugnot built the first full-scale, self-propelled mechanical vehicle, a steam-powered tricycle.', evidence='Nicolas-Joseph Cugnot is widely credited with building the first full-scale, self-propelled mechanical vehicle in about 1769; he created a steam-powered tricycle.'),\n KeyDevelopment(year=1807, description=\"Nic\u00e9phore Ni\u00e9pce and his brother Claude created what was probably the world's first internal combustion engine.\", evidence=\"In 1807, Nic\u00e9phore Ni\u00e9pce and his brother Claude created what was probably the world's first internal combustion engine (which they called a Pyr\u00e9olophore), but installed it in a boat on the river Saone in France.\"),\n KeyDevelopment(year=1886, description='Carl Benz patented the Benz Patent-Motorwagen, marking the birth of the modern car.', evidence='In November 1881, French inventor Gustave Trouv\u00e9 demonstrated a three-wheeled car powered by electricity at the International Exposition of Electricity. Although several other German engineers (including Gottlieb Daimler, Wilhelm Maybach, and Siegfried Marcus) were working on cars at about the same time, the year 1886 is regarded as the birth year of the modern car\u2014a practical, marketable automobile for everyday use\u2014when the German Carl Benz patented his Benz Patent-Motorwagen; he is generally acknowledged as the inventor of the car.'),\n KeyDevelopment(year=1886, description='Carl Benz began promotion of his vehicle, marking the introduction of the first commercially available automobile.', evidence='Benz began promotion of the vehicle on 3 July 1886.'),\n KeyDevelopment(year=1888, description=\"Bertha Benz undertook the first road trip by car to prove the road-worthiness of her husband's invention.\", evidence=\"In August 1888, Bertha Benz, the wife and business partner of Carl Benz, undertook the first road trip by car, to prove the road-worthiness of her husband's invention.\"),\n KeyDevelopment(year=1896, description='Benz designed and patented the first internal-combustion flat engine, called boxermotor.', evidence='In 1896, Benz designed and patented the first internal-combustion flat engine, called boxermotor.'),\n KeyDevelopment(year=1897, description='The first motor car in central Europe and one of the first factory-made cars in the world, the Pr\u00e4sident automobil, was produced by Nesselsdorfer Wagenbau.', evidence='The first motor car in central Europe and one of the first factory-made cars in the world, was produced by Czech company Nesselsdorfer Wagenbau (later renamed to Tatra) in 1897, the Pr\u00e4sident automobil.'),\n KeyDevelopment(year=1901, description='Ransom Olds started large-scale, production-line manufacturing of affordable cars at his Oldsmobile factory in Lansing, Michigan.', evidence='Large-scale, production-line manufacturing of affordable cars was started by Ransom Olds in 1901 at his Oldsmobile factory in Lansing, Michigan.'),\n KeyDevelopment(year=1913, description=\"Henry Ford introduced the world's first moving assembly line for cars at the Highland Park Ford Plant.\", evidence=\"This concept was greatly expanded by Henry Ford, beginning in 1913 with the world's first moving assembly line for cars at the Highland Park Ford Plant.\")]\n```\n\n## RAG based approach\u200b\n\nAnother simple idea is to chunk up the text, but instead of extracting information from every chunk, just focus on the the most relevant chunks.\n\ncautionIt can be difficult to identify which chunks are relevant.\n\nFor example, in the `car` article we're using here, most of the article contains key development information. So by using\n**RAG**, we'll likely be throwing out a lot of relevant information.\n\nWe suggest experimenting with your use case and determining whether this approach works or not.\n\nTo implement the RAG based approach:", "type": "Document"}, {"metadata": {"description": "This guide assumes familiarity with the following concepts:", "language": "en", "changefreq": "weekly", "source": "https://python.langchain.com/docs/tutorials/extraction/", "title": "Build an Extraction Chain | \ud83e\udd9c\ufe0f\ud83d\udd17 LangChain", "lastmod": null, "content_type": null, "priority": "0.5", "loc": "https://python.langchain.com/docs/tutorials/extraction/", "uuid": "f4b59370-e4c5-529d-9adc-b2a6eb8d4eef"}, "page_content": "class Data(BaseModel):\n    \"\"\"Extracted data about people.\"\"\"\n\n    # Creates a model so that we can extract multiple entities.\n    people: List[Person]\n```\n\nimportantExtraction might not be perfect here. Please continue to see how to use **Reference Examples** to improve the quality of extraction, and see the **guidelines** section!\n\n```python\nrunnable = prompt | llm.with_structured_output(schema=Data)\ntext = \"My name is Jeff, my hair is black and i am 6 feet tall. Anna has the same color hair as me.\"\nrunnable.invoke({\"text\": text})\n```\n\n```output\nData(people=[Person(name='Jeff', hair_color=None, height_in_meters=None), Person(name='Anna', hair_color=None, height_in_meters=None)])\n```\n\ntipWhen the schema accommodates the extraction of **multiple entities**, it also allows the model to extract **no entities** if no relevant information\nis in the text by providing an empty list.\n\nThis is usually a **good** thing! It allows specifying **required** attributes on an entity without necessarily forcing the model to detect this entity.\n\nWe can see the LangSmith trace here: [https://smith.langchain.com/public/7173764d-5e76-45fe-8496-84460bd9cdef/r](https://smith.langchain.com/public/7173764d-5e76-45fe-8496-84460bd9cdef/r)\n\n## Next steps\u200b\n\nNow that you understand the basics of extraction with LangChain, you're ready to proceed to the rest of the how-to guides:\n\n- [Add Examples](/docs/how_to/extraction_examples/): Learn how to use **reference examples** to improve performance.\n\n- [Handle Long Text](/docs/how_to/extraction_long_text/): What should you do if the text does not fit into the context window of the LLM?\n\n- [Use a Parsing Approach](/docs/how_to/extraction_parse/): Use a prompt based approach to extract with models that do not support **tool/function calling**.\n\n#### Was this page helpful?\n\n- [Setup](#setup)- [Jupyter Notebook](#jupyter-notebook)\n\n- [Installation](#installation)\n\n- [LangSmith](#langsmith)\n\n- [The Schema](#the-schema)\n\n- [The Extractor](#the-extractor)\n\n- [Multiple Entities](#multiple-entities)\n\n- [Next steps](#next-steps)", "type": "Document"}, {"metadata": {"language": "en", "description": "This Jupyter Notebook demonstrates how to use Eden AI tools with an Agent.", "changefreq": "weekly", "source": "https://python.langchain.com/docs/integrations/tools/edenai_tools/", "title": "Eden AI | \ud83e\udd9c\ufe0f\ud83d\udd17 LangChain", "lastmod": null, "content_type": null, "priority": "0.5", "loc": "https://python.langchain.com/docs/integrations/tools/edenai_tools/", "uuid": "c2b59f24-a6ed-5923-b04e-763734df2c8f"}, "page_content": "you can have more details of the execution by printing the result\n\n```python\nresult\n```\n\n```output\n{'input': ' i have this url of an image : \"https://static.javatpoint.com/images/objects.jpg\"\\n                   first : i want to know if the image contain objects .\\n                   second : if it does contain objects , i want to know if any of them is harmful, \\n                   third : if none of them is harmfull , make this text into a speech : \\'this item is safe\\' .\\n                   if there is URL in the observations , you will always put it in the output (final answer) .\\n                   ',\n 'output': \"The image contains objects such as Apple, Backpack, Luggage & bags, and Container. None of them are harmful. The text 'this item is safe' can be found in the audio file at https://d14uq1pz7dzsdq.cloudfront.net/0546db8b-528e-4b63-9a69-d14d43ad1566_.mp3?Expires=1693316753&Signature=N0KZeK9I-1s7wTgiQOAwH7LFlltwyonSJcDnkdnr8JIJmbgSw6fo6RTxWl~VvD2Hg6igJqxtJFFWyrBmmx-f9wWLw3bZSnuMxkhTRqLX9aUA9N-vPJGiRZV5BFredaOm8pwfo8TcXhVjw08iSxv8GSuyZEIwZkiq4PzdiyVTnKKji6eyt\",\n 'intermediate_steps': [(AgentAction(tool='edenai_object_detection', tool_input='https://static.javatpoint.com/images/objects.jpg', log=' I need to determine if the image contains objects, if any of them are harmful, and then convert the text to speech.\\nAction: edenai_object_detection\\nAction Input: https://static.javatpoint.com/images/objects.jpg'),\n   'Apple - Confidence 0.94003654\\nApple - Confidence 0.94003654\\nApple - Confidence 0.94003654\\nBackpack - Confidence 0.7481894\\nBackpack - Confidence 0.7481894\\nBackpack - Confidence 0.7481894\\nLuggage & bags - Confidence 0.70691586\\nLuggage & bags - Confidence 0.70691586\\nLuggage & bags - Confidence 0.70691586\\nContainer - Confidence 0.654727\\nContainer - Confidence 0.654727\\nContainer - Confidence 0.654727\\nLuggage & bags - Confidence 0.5871518\\nLuggage & bags - Confidence 0.5871518\\nLuggage & bags - Confidence 0.5871518'),\n  (AgentAction(tool='edenai_explicit_content_detection_text', tool_input='Apple, Backpack, Luggage & bags, Container', log=' I need to check if any of the objects are harmful.\\nAction: edenai_explicit_content_detection_text\\nAction Input: Apple, Backpack, Luggage & bags, Container'),\n   'nsfw_likelihood: 2\\n\"sexually explicit\": 1\\n\"sexually suggestive\": 2\\n\"offensive\": 1\\nnsfw_likelihood: 1\\n\"sexual\": 1\\n\"hate\": 1\\n\"harassment\": 1\\n\"self-harm\": 1\\n\"sexual/minors\": 1\\n\"hate/threatening\": 1\\n\"violence/graphic\": 1\\n\"self-harm/intent\": 1\\n\"self-harm/instructions\": 1\\n\"harassment/threatening\": 1\\n\"violence\": 1'),\n  (AgentAction(tool='edenai_text_to_speech', tool_input=\"'this item is safe'\", log=\" None of the objects are harmful.\\nAction: edenai_text_to_speech\\nAction Input: 'this item is safe'\"),\n   'https://d14uq1pz7dzsdq.cloudfront.net/0546db8b-528e-4b63-9a69-d14d43ad1566_.mp3?Expires=1693316753&Signature=N0KZeK9I-1s7wTgiQOAwH7LFlltwyonSJcDnkdnr8JIJmbgSw6fo6RTxWl~VvD2Hg6igJqxtJFFWyrBmmx-f9wWLw3bZSnuMxkhTRqLX9aUA9N-vPJGiRZV5BFredaOm8pwfo8TcXhVjw08iSxv8GSuyZEIwZkiq4PzdiyVTnKKji6eytV0CrnHrTs~eXZkSnOdD2Fu0ECaKvFHlsF4IDLI8efRvituSk0X3ygdec4HQojl5vmBXJzi1TuhKWOX8UxeQle8pdjjqUPSJ9thTHpucdPy6UbhZOH0C9rbtLrCfvK5rzrT4D~gKy9woICzG34tKRxNxHYVVUPqx2BiInA__&Key-Pair-Id=K1F55BTI9AHGIK')]}\n```\n\n## Example with OCR images\u200b\n\n```python\ninput_ = \"\"\"i have this url of an id: \"https://www.citizencard.com/images/citizencard-uk-id-card-2023.jpg\"\ni want to extract the information in it.\ncreate a text welcoming the person by his name and make it into speech .\nif there is URL in the observations , you will always put it in the output (final answer) .\n\"\"\"\nresult = agent_chain(input_)\n```\n\n```output", "type": "Document"}, {"metadata": {"language": "en", "description": "Transwarp Hippo is an enterprise-level cloud-native distributed vector database that supports storage, retrieval, and management of massive vector-based datasets. It efficiently solves problems such as vector similarity search and high-density vector clustering. Hippo features high availability, high performance, and easy scalability. It has many functions, such as multiple vector search indexes, data partitioning and sharding, data persistence, incremental data ingestion, vector scalar field filtering, and mixed queries. It can effectively meet the high real-time search demands of enterprises for massive vector data", "changefreq": "weekly", "source": "https://python.langchain.com/docs/integrations/vectorstores/hippo/", "title": "Hippo | \ud83e\udd9c\ufe0f\ud83d\udd17 LangChain", "content_type": null, "lastmod": null, "priority": "0.5", "loc": "https://python.langchain.com/docs/integrations/vectorstores/hippo/", "uuid": "a3c305b4-cd08-56c7-bccd-612617eadbdb"}, "page_content": "- [Storing the Document](#storing-the-document)\n\n- [Conducting Knowledge-based Question and Answer](#conducting-knowledge-based-question-and-answer)\n\n- [Acquiring Related Knowledge Based on the Question\uff1a](#acquiring-related-knowledge-based-on-the-question)\n\n- [Constructing a Prompt Template](#constructing-a-prompt-template)\n\n- [Waiting for the Large Language Model to Generate an Answer](#waiting-for-the-large-language-model-to-generate-an-answer)\n\n- [Related](#related)", "type": "Document"}, {"metadata": {"language": "en", "description": "PebbloRetrievalQA is a Retrieval chain with Identity & Semantic Enforcement for question-answering", "changefreq": "weekly", "source": "https://python.langchain.com/docs/integrations/providers/pebblo/pebblo_retrieval_qa/", "title": "Identity-enabled RAG using PebbloRetrievalQA | \ud83e\udd9c\ufe0f\ud83d\udd17 LangChain", "content_type": null, "lastmod": null, "priority": "0.5", "loc": "https://python.langchain.com/docs/integrations/providers/pebblo/pebblo_retrieval_qa/", "uuid": "bdd2d371-9dd6-5cac-8806-1a2d4df78db5"}, "page_content": "- [Retrieval with Identity Enforcement](#retrieval-with-identity-enforcement)- [1. Questions by Authorized User](#1-questions-by-authorized-user)\n\n- [2. Questions by Unauthorized User](#2-questions-by-unauthorized-user)\n\n- [3. Using PromptTemplate to provide additional instructions](#3-using-prompttemplate-to-provide-additional-instructions)\n\n- [Retrieval with Semantic Enforcement](#retrieval-with-semantic-enforcement)- [1. Without semantic enforcement](#1-without-semantic-enforcement)\n\n- [2. Deny financial-report topic](#2-deny-financial-report-topic)\n\n- [3. Deny us-bank-account-number entity](#3-deny-us-bank-account-number-entity)", "type": "Document"}, {"metadata": {"language": "en", "description": "Retrieval is a common technique chatbots use to augment their responses with data outside a chat model's training data. This section will cover how to implement retrieval in the context of chatbots, but it's worth noting that retrieval is a very subtle and deep topic - we encourage you to explore other parts of the documentation that go into greater depth!", "changefreq": "weekly", "source": "https://python.langchain.com/docs/how_to/chatbots_retrieval/", "title": "How to add retrieval to chatbots | \ud83e\udd9c\ufe0f\ud83d\udd17 LangChain", "content_type": null, "lastmod": null, "priority": "0.5", "loc": "https://python.langchain.com/docs/how_to/chatbots_retrieval/", "uuid": "faea8c1d-2464-555e-b5bb-761ddfcaee53"}, "page_content": "{'answer': ''}\n{'answer': 'Lang'}\n{'answer': 'Smith'}\n{'answer': ' simpl'}\n{'answer': 'ifies'}\n{'answer': ' the'}\n{'answer': ' initial'}\n{'answer': ' setup'}\n{'answer': ' for'}\n{'answer': ' building'}\n{'answer': ' reliable'}\n{'answer': ' L'}\n{'answer': 'LM'}\n{'answer': ' applications'}\n{'answer': '.'}\n{'answer': ' It'}\n{'answer': ' provides'}\n{'answer': ' features'}\n{'answer': ' for'}\n{'answer': ' manually'}\n{'answer': ' reviewing'}\n{'answer': ' and'}\n{'answer': ' annot'}\n{'answer': 'ating'}\n{'answer': ' runs'}\n{'answer': ' through'}\n{'answer': ' annotation'}\n{'answer': ' queues'}\n{'answer': ','}\n{'answer': ' allowing'}\n{'answer': ' you'}\n{'answer': ' to'}\n{'answer': ' select'}\n{'answer': ' runs'}\n{'answer': ' based'}\n{'answer': ' on'}\n{'answer': ' criteria'}\n{'answer': ' like'}\n{'answer': ' model'}\n{'answer': ' type'}\n{'answer': ' or'}\n{'answer': ' automatic'}\n{'answer': ' evaluation'}\n{'answer': ' scores'}\n{'answer': ','}\n{'answer': ' and'}\n{'answer': ' queue'}\n{'answer': ' them'}\n{'answer': ' up'}\n{'answer': ' for'}\n{'answer': ' human'}\n{'answer': ' review'}\n{'answer': '.'}\n{'answer': ' As'}\n{'answer': ' a'}\n{'answer': ' reviewer'}\n{'answer': ','}\n{'answer': ' you'}\n{'answer': ' can'}\n{'answer': ' quickly'}\n{'answer': ' step'}\n{'answer': ' through'}\n{'answer': ' the'}\n{'answer': ' runs'}\n{'answer': ','}\n{'answer': ' view'}\n{'answer': ' the'}\n{'answer': ' input'}\n{'answer': ','}\n{'answer': ' output'}\n{'answer': ','}\n{'answer': ' and'}\n{'answer': ' any'}\n{'answer': ' existing'}\n{'answer': ' tags'}\n{'answer': ' before'}\n{'answer': ' adding'}\n{'answer': ' your'}\n{'answer': ' own'}\n{'answer': ' feedback'}\n{'answer': '.'}\n{'answer': ' This'}\n{'answer': ' can'}\n{'answer': ' be'}\n{'answer': ' particularly'}\n{'answer': ' useful'}\n{'answer': ' for'}\n{'answer': ' assessing'}\n{'answer': ' subjective'}\n{'answer': ' qualities'}\n{'answer': ' that'}\n{'answer': ' automatic'}\n{'answer': ' evalu'}\n{'answer': 'ators'}\n{'answer': ' struggle'}\n{'answer': ' with'}\n{'answer': '.'}\n{'answer': ''}\n```", "type": "Document"}, {"metadata": {"description": "PebbloRetrievalQA is a Retrieval chain with Identity & Semantic Enforcement for question-answering", "language": "en", "changefreq": "weekly", "source": "https://python.langchain.com/docs/integrations/providers/pebblo/pebblo_retrieval_qa/", "title": "Identity-enabled RAG using PebbloRetrievalQA | \ud83e\udd9c\ufe0f\ud83d\udd17 LangChain", "content_type": null, "lastmod": null, "priority": "0.5", "loc": "https://python.langchain.com/docs/integrations/providers/pebblo/pebblo_retrieval_qa/", "uuid": "9483e59b-08e4-5369-98dd-4706cd919703"}, "page_content": "def ask(\n    question: str,\n    topics_to_deny: Optional[List[str]] = None,\n    entities_to_deny: Optional[List[str]] = None,\n):\n    \"\"\"\n    Ask a question to the PebbloRetrievalQA chain\n    \"\"\"\n    semantic_context = dict()\n    if topics_to_deny:\n        semantic_context[\"pebblo_semantic_topics\"] = {\"deny\": topics_to_deny}\n    if entities_to_deny:\n        semantic_context[\"pebblo_semantic_entities\"] = {\"deny\": entities_to_deny}\n\n    semantic_context_obj = (\n        SemanticContext(**semantic_context) if semantic_context else None\n    )\n    chain_input_obj = ChainInput(query=question, semantic_context=semantic_context_obj)\n    return qa_chain.invoke(chain_input_obj.dict())\n```\n\n**API Reference:**[PebbloRetrievalQA](https://python.langchain.com/api_reference/community/chains/langchain_community.chains.pebblo_retrieval.base.PebbloRetrievalQA.html) | [ChainInput](https://python.langchain.com/api_reference/community/chains/langchain_community.chains.pebblo_retrieval.models.ChainInput.html) | [SemanticContext](https://python.langchain.com/api_reference/community/chains/langchain_community.chains.pebblo_retrieval.models.SemanticContext.html)\n### 1. Without semantic enforcement\u200b\n\nSince no semantic enforcement is applied, the system should return the answer without excluding any context due to the semantic labels associated with the context.\n\n```python\ntopic_to_deny = []\nentities_to_deny = []\nquestion = \"Share the financial performance of ACME Corp for the year 2020\"\nresp = ask(question, topics_to_deny=topic_to_deny, entities_to_deny=entities_to_deny)\nprint(\n    f\"Topics to deny: {topic_to_deny}\\nEntities to deny: {entities_to_deny}\\n\"\n    f\"Question: {question}\\nAnswer: {resp['result']}\"\n)\n```\n\n```output\nTopics to deny: []\nEntities to deny: []\nQuestion: Share the financial performance of ACME Corp for the year 2020\nAnswer: \nRevenue for ACME Corp increased by 15% to $50 million in 2020, with a net profit of $12 million and a strong asset base of $80 million. The company also maintained a conservative debt-to-equity ratio of 0.5.\n```\n\n### 2. Deny financial-report topic\u200b\n\nData has been ingested with the topics: `[\"financial-report\"]`.\nTherefore, an app that denies the `financial-report` topic should not receive an answer.\n\n```python\ntopic_to_deny = [\"financial-report\"]\nentities_to_deny = []\nquestion = \"Share the financial performance of ACME Corp for the year 2020\"\nresp = ask(question, topics_to_deny=topic_to_deny, entities_to_deny=entities_to_deny)\nprint(\n    f\"Topics to deny: {topic_to_deny}\\nEntities to deny: {entities_to_deny}\\n\"\n    f\"Question: {question}\\nAnswer: {resp['result']}\"\n)\n```\n\n```output\nTopics to deny: ['financial-report']\nEntities to deny: []\nQuestion: Share the financial performance of ACME Corp for the year 2020\nAnswer: \n\nUnfortunately, I do not have access to the financial performance of ACME Corp for the year 2020.\n```\n\n### 3. Deny us-bank-account-number entity\u200b\n\nSince the entity `us-bank-account-number` is denied, the system should not return the answer.\n\n```python\ntopic_to_deny = []\nentities_to_deny = [\"us-bank-account-number\"]\nquestion = \"Share the financial performance of ACME Corp for the year 2020\"\nresp = ask(question, topics_to_deny=topic_to_deny, entities_to_deny=entities_to_deny)\nprint(\n    f\"Topics to deny: {topic_to_deny}\\nEntities to deny: {entities_to_deny}\\n\"\n    f\"Question: {question}\\nAnswer: {resp['result']}\"\n)\n```\n\n```output\nTopics to deny: []\nEntities to deny: ['us-bank-account-number']\nQuestion: Share the financial performance of ACME Corp for the year 2020\nAnswer:  I don't have information about ACME Corp's financial performance for 2020.\n```\n\n#### Was this page helpful?\n\n- [Steps:](#steps)\n\n- [Setup](#setup)- [Dependencies](#dependencies)\n\n- [Identity-aware Data Ingestion](#identity-aware-data-ingestion)\n\n- [Retrieval with Identity Enforcement](#retrieval-with-identity-enforcement)- [1. Questions by Authorized User](#1-questions-by-authorized-user)", "type": "Document"}, {"metadata": {"description": "LLMs can summarize and otherwise distill desired information from text, including large volumes of text. In many cases, especially when the amount of text is large compared to the size of the model's context window, it can be helpful (or necessary) to break up the summarization task into smaller components.", "language": "en", "changefreq": "weekly", "source": "https://python.langchain.com/docs/how_to/summarize_map_reduce/", "title": "How to summarize text through parallelization | \ud83e\udd9c\ufe0f\ud83d\udd17 LangChain", "lastmod": null, "content_type": null, "priority": "0.5", "loc": "https://python.langchain.com/docs/how_to/summarize_map_reduce/", "uuid": "fc14a57d-1f4d-506f-b648-9835640f017c"}, "page_content": "See also [this tutorial](/docs/tutorials/summarization/) for more detail on summarization.\n\n#### Was this page helpful?\n\n- [Load chat model](#load-chat-model)\n\n- [Load documents](#load-documents)\n\n- [Create graph](#create-graph)- [Map step](#map-step)\n\n- [Reduce step](#reduce-step)\n\n- [Orchestration via LangGraph](#orchestration-via-langgraph)\n\n- [Invoke graph](#invoke-graph)\n\n- [Next steps](#next-steps)", "type": "Document"}, {"metadata": {"language": "en", "description": "This tutorial demonstrates text summarization using built-in chains and LangGraph.", "changefreq": "weekly", "source": "https://python.langchain.com/docs/tutorials/summarization/", "title": "Summarize Text | \ud83e\udd9c\ufe0f\ud83d\udd17 LangChain", "content_type": null, "lastmod": null, "priority": "0.5", "loc": "https://python.langchain.com/docs/tutorials/summarization/", "uuid": "bbeae299-a2fb-5af1-ad12-bf62bdcbba80"}, "page_content": "Summarize Text | \ud83e\udd9c\ufe0f\ud83d\udd17 LangChain\n\n[Skip to main content](#__docusaurus_skipToContent_fallback)# Summarize Text\n\ninfoThis tutorial demonstrates text summarization using built-in chains and [LangGraph](https://langchain-ai.github.io/langgraph/).\n\nA [previous version](https://python.langchain.com/v0.1/docs/use_cases/summarization/) of this page showcased the legacy chains [StuffDocumentsChain](/docs/versions/migrating_chains/stuff_docs_chain/), [MapReduceDocumentsChain](/docs/versions/migrating_chains/map_reduce_chain/), and [RefineDocumentsChain](https://python.langchain.com/docs/versions/migrating_chains/refine_docs_chain/). See [here](/docs/versions/migrating_chains/) for information on using those abstractions and a comparison with the methods demonstrated in this tutorial.\n\nSuppose you have a set of documents (PDFs, Notion pages, customer questions, etc.) and you want to summarize the content.\n\nLLMs are a great tool for this given their proficiency in understanding and synthesizing text.\n\nIn the context of [retrieval-augmented generation](/docs/tutorials/rag/), summarizing text can help distill the information in a large number of retrieved documents to provide context for a LLM.\n\nIn this walkthrough we'll go over how to summarize content from multiple documents using LLMs.\n\n![Image description](/assets/images/summarization_use_case_1-874f7b2c94f64216f1f967fb5aca7bc1.png)\n\n## Concepts\u200b\n\nConcepts we will cover are:\n\n- \nUsing [language models](/docs/concepts/chat_models/).\n\n- \nUsing [document loaders](/docs/concepts/document_loaders/), specifically the [WebBaseLoader](https://python.langchain.com/api_reference/community/document_loaders/langchain_community.document_loaders.web_base.WebBaseLoader.html) to load content from an HTML webpage.\n\n- \nTwo ways to summarize or otherwise combine documents.\n\n1. [Stuff](/docs/tutorials/summarization/#stuff), which simply concatenates documents into a prompt;\n\n2. [Map-reduce](/docs/tutorials/summarization/#map-reduce), for larger sets of documents. This splits documents into batches, summarizes those, and then summarizes the summaries.\n\nShorter, targeted guides on these strategies and others, including [iterative refinement](/docs/how_to/summarize_refine/), can be found in the [how-to guides](/docs/how_to/#summarization).\n\n## Setup\u200b\n\n### Jupyter Notebook\u200b\n\nThis guide (and most of the other guides in the documentation) uses [Jupyter notebooks](https://jupyter.org/) and assumes the reader is as well. Jupyter notebooks are perfect for learning how to work with LLM systems because oftentimes things can go wrong (unexpected output, API down, etc) and going through guides in an interactive environment is a great way to better understand them.\n\nThis and other tutorials are perhaps most conveniently run in a Jupyter notebook. See [here](https://jupyter.org/install) for instructions on how to install.\n\n### Installation\u200b\n\nTo install LangChain run:\n\n \nPip\n```bash\npip install langchain\n```\n\nConda\n```bash\nconda install langchain -c conda-forge\n```\n\nFor more details, see our [Installation guide](/docs/how_to/installation/).\n\n### LangSmith\u200b\n\nMany of the applications you build with LangChain will contain multiple steps with multiple invocations of LLM calls.\nAs these applications get more and more complex, it becomes crucial to be able to inspect what exactly is going on inside your chain or agent.\nThe best way to do this is with [LangSmith](https://smith.langchain.com).\n\nAfter you sign up at the link above, make sure to set your environment variables to start logging traces:\n\n```shell\nexport LANGCHAIN_TRACING_V2=\"true\"\nexport LANGCHAIN_API_KEY=\"...\"\n```\n\nOr, if in a notebook, you can set them with:\n\n```python\nimport getpass\nimport os\n\nos.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\nos.environ[\"LANGCHAIN_API_KEY\"] = getpass.getpass()\n```\n\n## Overview\u200b\n\nA central question for building a summarizer is how to pass your documents into the LLM's context window. Two common approaches for this are:", "type": "Document"}, {"metadata": {"description": "Vectara is the trusted AI Assistant and Agent platform which focuses on enterprise readiness for mission-critical applications.", "language": "en", "changefreq": "weekly", "source": "https://python.langchain.com/docs/integrations/vectorstores/vectara/", "title": "Vectara | \ud83e\udd9c\ufe0f\ud83d\udd17 LangChain", "content_type": null, "lastmod": null, "priority": "0.5", "loc": "https://python.langchain.com/docs/integrations/vectorstores/vectara/", "uuid": "31d78e5d-5fc7-5a56-baf6-6b8ead6ad6fb"}, "page_content": "```python\nconfig.summary_config.is_enabled = False\nconfig.k = 3\nretriever = vectara.as_retriever(config=config)\nretriever.invoke(query_str)\n```\n\n```output\n[Document(page_content='He thought the West and NATO wouldn\u2019t respond. And he thought he could divide us at home. We were ready.  Here is what we did. We prepared extensively and carefully. We spent months building a coalition of other freedom-loving nations from Europe and the Americas to Asia and Africa to confront Putin.', metadata={'lang': 'eng', 'section': '1', 'offset': '2160', 'len': '36', 'X-TIKA:Parsed-By': 'org.apache.tika.parser.csv.TextAndCSVParser', 'Content-Encoding': 'UTF-8', 'Content-Type': 'text/plain; charset=UTF-8', 'source': 'vectara'}),\n Document(page_content='When they came home, many of the world\u2019s fittest and best trained warriors were never the same. Dizziness. \\n\\nA cancer that would put them in a flag-draped coffin. I know. \\n\\nOne of those soldiers was my son Major Beau Biden. We don\u2019t know for sure if a burn pit was the cause of his brain cancer, or the diseases of so many of our troops. But I\u2019m committed to finding out everything we can.', metadata={'lang': 'eng', 'section': '1', 'offset': '34652', 'len': '60', 'X-TIKA:Parsed-By': 'org.apache.tika.parser.csv.TextAndCSVParser', 'Content-Encoding': 'UTF-8', 'Content-Type': 'text/plain; charset=UTF-8', 'source': 'vectara'}),\n Document(page_content='But cancer from prolonged exposure to burn pits ravaged Heath\u2019s lungs and body. Danielle says Heath was a fighter to the very end. He didn\u2019t know how to stop fighting, and neither did she. Through her pain she found purpose to demand we do better. Tonight, Danielle\u2014we are.', metadata={'lang': 'eng', 'section': '1', 'offset': '35442', 'len': '57', 'X-TIKA:Parsed-By': 'org.apache.tika.parser.csv.TextAndCSVParser', 'Content-Encoding': 'UTF-8', 'Content-Type': 'text/plain; charset=UTF-8', 'source': 'vectara'})]\n```\n\nFor backwards compatibility, you can also enable summarization with a retriever, in which case the summary is added as an additional Document object:\n\n```python\nconfig.summary_config.is_enabled = True\nconfig.k = 3\nretriever = vectara.as_retriever(config=config)\nretriever.invoke(query_str)\n```", "type": "Document"}], "answer": "To upload a PDF using LangChain, you can utilize the `PDFMinerLoader` or `PDFPlumberLoader`. Here\u2019s a brief overview of how to do it with each loader:\n\n### Using PDFMinerLoader\n1. **Install the required package**:\n   ```bash\n   pip install langchain_community\n   ```\n\n2. **Load the PDF**:\n   ```python\n   from langchain_community.document_loaders import PDFMinerLoader\n\n   file_path = \"./path_to_your_pdf/document.pdf\"\n   loader = PDFMinerLoader(file_path)\n   docs = loader.load()\n   ```\n\n### Using PDFPlumberLoader\n1. **Install the required package**:\n   ```bash\n   pip install langchain_community\n   ```\n\n2. **Load the PDF**:\n   ```python\n   from langchain_community.document_loaders import PDFPlumberLoader\n\n   loader = PDFPlumberLoader(\"./path_to_your_pdf/document.pdf\")\n   docs = loader.load()\n   ```\n\n### Notes\n- Both loaders will return a list of documents, where each document corresponds to a page in the PDF.\n- No special credentials are needed to use these loaders.\n\nFor more detailed information, you can refer to the API references for [PDFMinerLoader](https://python.langchain.com/api_reference/community/document_loaders/langchain_community.document_loaders.pdf.PDFMinerLoader.html) and [PDFPlumberLoader](https://python.langchain.com/api_reference/community/document_loaders/langchain_community.document_loaders.pdf.PDFPlumberLoader.html).", "query": "https://www.cambridge.org/core/services/aop-cambridge-core/content/view/0D4357A9A6150E706CC261B86BA47733/S0008423923000793a.pdf/ascent_of_the_canadian_judicial_council_bill_c9_and_the_move_towards_judicialized_governance.pdf  can you open this to answer questions for me "}}
{"messages": [[{"lc": 1, "type": "constructor", "id": ["langchain", "schema", "messages", "SystemMessage"], "kwargs": {"content": "You are an expert programmer and problem-solver, tasked with answering any question about LangChain.\n\nGenerate a comprehensive and informative answer for the given question based solely on the provided search results (URL and content). Do NOT ramble, and adjust your response length based on the question. If they ask a question that can be answered in one sentence, do that. If 5 paragraphs of detail is needed, do that. You must only use information from the provided search results. Use an unbiased and journalistic tone. Combine search results together into a coherent answer. Do not repeat text. Cite search results using [${number}] notation. Only cite the most relevant results that answer the question accurately. Place these citations at the end of the individual sentence or paragraph that reference them. Do not put them all at the end, but rather sprinkle them throughout. If different results refer to different entities within the same name, write separate answers for each entity.\n\nYou should use bullet points in your answer for readability. Put citations where they apply rather than putting them all at the end. DO NOT PUT THEM ALL THAT END, PUT THEM IN THE BULLET POINTS.\n\nIf there is nothing in the context relevant to the question at hand, do NOT make up an answer. Rather, tell them why you're unsure and ask for any additional information that may help you answer better.\n\nSometimes, what a user is asking may NOT be possible. Do NOT tell them that things are possible if you don't see evidence for it in the context below. If you don't see based in the information below that something is possible, do NOT say that it is - instead say that you're not sure.\n\nAnything between the following `context` html blocks is retrieved from a knowledge bank, not part of the conversation with the user.\n\n<context>\n    <documents>\n<document  language='en' description='Portable Document Format (PDF), standardized as ISO 32000, is a file format developed by Adobe in 1992 to present documents, including text formatting and images, in a manner independent of application software, hardware, and operating systems.' changefreq='weekly' source='https://python.langchain.com/docs/how_to/document_loader_pdf/' title='How to load PDFs | \ud83e\udd9c\ufe0f\ud83d\udd17 LangChain' lastmod=None content_type=None priority='0.5' loc='https://python.langchain.com/docs/how_to/document_loader_pdf/' uuid='a3f9bbc3-306a-5a26-94ac-f0fe755afbb7'>\nHow to load PDFs | \ud83e\udd9c\ufe0f\ud83d\udd17 LangChain\n\n[Skip to main content](#__docusaurus_skipToContent_fallback)# How to load PDFs\n\n[Portable Document Format (PDF)](https://en.wikipedia.org/wiki/PDF), standardized as ISO 32000, is a file format developed by Adobe in 1992 to present documents, including text formatting and images, in a manner independent of application software, hardware, and operating systems.\n\nThis guide covers how to [load](/docs/concepts/document_loaders/) `PDF` documents into the LangChain [Document](https://python.langchain.com/api_reference/core/documents/langchain_core.documents.base.Document.html) format that we use downstream.\n\nText in PDFs is typically represented via text boxes. They may also contain images. A PDF parser might do some combination of the following:\n\n- Agglomerate text boxes into lines, paragraphs, and other structures via heuristics or ML inference;\n\n- Run [OCR](https://en.wikipedia.org/wiki/Optical_character_recognition) on images to detect text therein;\n\n- Classify text as belonging to paragraphs, lists, tables, or other structures;\n\n- Structure text into table rows and columns, or key-value pairs.\n\nLangChain integrates with a host of PDF parsers. Some are simple and relatively low-level; others will support OCR and image-processing, or perform advanced document layout analysis. The right choice will depend on your needs. Below we enumerate the possibilities.\n\nWe will demonstrate these approaches on a [sample file](https://github.com/langchain-ai/langchain/blob/master/libs/community/tests/integration_tests/examples/layout-parser-paper.pdf):\n\n```python\nfile_path = (\n    \"../../docs/integrations/document_loaders/example_data/layout-parser-paper.pdf\"\n)\n```\n\nA note on multimodal modelsMany modern LLMs support inference over multimodal inputs (e.g., images). In some applications -- such as question-answering over PDFs with complex layouts, diagrams, or scans -- it may be advantageous to skip the PDF parsing, instead casting a PDF page to an image and passing it to a model directly. We demonstrate an example of this in the [Use of multimodal models](/docs/how_to/document_loader_pdf/#use-of-multimodal-models) section below.\n\n## Simple and fast text extraction\u200b\n\nIf you are looking for a simple string representation of text that is embedded in a PDF, the method below is appropriate. It will return a list of [Document](https://python.langchain.com/api_reference/core/documents/langchain_core.documents.base.Document.html) objects-- one per page-- containing a single string of the page's text in the Document's `page_content` attribute. It will not parse text in images or scanned PDF pages. Under the hood it uses the [pypdf](https://pypdf.readthedocs.io/en/stable/) Python library.\n\nLangChain [document loaders](/docs/concepts/document_loaders/) implement `lazy_load` and its async variant, `alazy_load`, which return iterators of `Document` objects. We will use these below.\n\n```python\n%pip install -qU pypdf\n```\n\n```python\nfrom langchain_community.document_loaders import PyPDFLoader\n\nloader = PyPDFLoader(file_path)\npages = []\nasync for page in loader.alazy_load():\n    pages.append(page)\n```\n\n**API Reference:**[PyPDFLoader](https://python.langchain.com/api_reference/community/document_loaders/langchain_community.document_loaders.pdf.PyPDFLoader.html)\n```python\nprint(f\"{pages[0].metadata}\\n\")\nprint(pages[0].page_content)\n```\n\n```output\n{'source': '../../docs/integrations/document_loaders/example_data/layout-parser-paper.pdf', 'page': 0}\n</document>\n<document  description='Overview' language='en' changefreq='weekly' source='https://python.langchain.com/docs/integrations/document_loaders/unstructured_pdfloader/' title='UnstructuredPDFLoader | \ud83e\udd9c\ufe0f\ud83d\udd17 LangChain' lastmod=None content_type=None priority='0.5' loc='https://python.langchain.com/docs/integrations/document_loaders/unstructured_pdfloader/' uuid='8e7d3de8-e7e7-5cc2-bee5-618901e9e15f'>\n**API Reference:**[OnlinePDFLoader](https://python.langchain.com/api_reference/community/document_loaders/langchain_community.document_loaders.pdf.OnlinePDFLoader.html)\n```output\n</document>\n<document  description='Overview' language='en' changefreq='weekly' source='https://python.langchain.com/docs/integrations/document_loaders/unstructured_pdfloader/' title='UnstructuredPDFLoader | \ud83e\udd9c\ufe0f\ud83d\udd17 LangChain' lastmod=None content_type=None priority='0.5' loc='https://python.langchain.com/docs/integrations/document_loaders/unstructured_pdfloader/' uuid='f896de9c-6074-587c-8ebd-21697b8fcf4e'>\n```python\nprint(docs[0].metadata)\n```\n\n```output\n{'source': './example_data/layout-parser-paper.pdf'}\n```\n\n### Retain Elements\u200b\n\nUnder the hood, Unstructured creates different \"elements\" for different chunks of text. By default we combine those together, but you can easily keep that separation by specifying `mode=\"elements\"`.\n\n```python\nfile_path = \"./example_data/layout-parser-paper.pdf\"\nloader = UnstructuredPDFLoader(file_path, mode=\"elements\")\n\ndata = loader.load()\ndata[0]\n```\n\n```output\nDocument(metadata={'source': './example_data/layout-parser-paper.pdf', 'coordinates': {'points': ((16.34, 213.36), (16.34, 253.36), (36.34, 253.36), (36.34, 213.36)), 'system': 'PixelSpace', 'layout_width': 612, 'layout_height': 792}, 'file_directory': './example_data', 'filename': 'layout-parser-paper.pdf', 'languages': ['eng'], 'last_modified': '2024-07-25T21:28:58', 'page_number': 1, 'filetype': 'application/pdf', 'category': 'UncategorizedText', 'element_id': 'd3ce55f220dfb75891b4394a18bcb973'}, page_content='1 2 0 2')\n```\n\nSee the full set of element types for this particular document:\n\n```python\nset(doc.metadata[\"category\"] for doc in data)\n```\n\n```output\n{'ListItem', 'NarrativeText', 'Title', 'UncategorizedText'}\n```\n\n### Fetching remote PDFs using Unstructured\u200b\n\nThis covers how to load online PDFs into a document format that we can use downstream. This can be used for various online PDF sites such as [https://open.umn.edu/opentextbooks/textbooks/](https://open.umn.edu/opentextbooks/textbooks/) and [https://arxiv.org/archive/](https://arxiv.org/archive/)\n\nNote: all other PDF loaders can also be used to fetch remote PDFs, but `OnlinePDFLoader` is a legacy function, and works specifically with `UnstructuredPDFLoader`.\n\n```python\nfrom langchain_community.document_loaders import OnlinePDFLoader\n\nloader = OnlinePDFLoader(\"https://arxiv.org/pdf/2302.03803.pdf\")\ndata = loader.load()\ndata[0]\n```\n</document>\n<document  language='en' description='DocumentLoaders load data into the standard LangChain Document format.' changefreq='weekly' source='https://python.langchain.com/docs/integrations/document_loaders/' title='Document loaders | \ud83e\udd9c\ufe0f\ud83d\udd17 LangChain' content_type=None lastmod=None priority='0.5' loc='https://python.langchain.com/docs/integrations/document_loaders/' uuid='cbcffc89-a3d2-5630-9fc5-b89ee88d3d68'>\n#### Was this page helpful?\n\n- [Webpages](#webpages)\n\n- [PDFs](#pdfs)\n\n- [Cloud Providers](#cloud-providers)\n\n- [Social Platforms](#social-platforms)\n\n- [Messaging Services](#messaging-services)\n\n- [Productivity tools](#productivity-tools)\n\n- [Common File Types](#common-file-types)\n\n- [All document loaders](#all-document-loaders)\n</document>\n<document  description='Overview' language='en' changefreq='weekly' source='https://python.langchain.com/docs/integrations/document_loaders/pdfminer/' title='PDFMiner | \ud83e\udd9c\ufe0f\ud83d\udd17 LangChain' content_type=None lastmod=None priority='0.5' loc='https://python.langchain.com/docs/integrations/document_loaders/pdfminer/' uuid='85d9d38c-a640-5f59-b00d-5ff43f93ac91'>\n5 shows two examples of how\\n<br></span><span style=\"font-family: CMTT10; font-size:9px\">LayoutParser </span><span style=\"font-family: CMR10; font-size:9px\">can be used in practical DIA projects, and Section 6 concludes.\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:134px; top:1990px; width:102px; height:11px;\"><span style=\"font-family: CMBX12; font-size:11px\">2 Related Work\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:134px; top:2016px; width:347px; height:81px;\"><span style=\"font-family: CMR10; font-size:9px\">Recently, various DL models and datasets have been developed for layout analysis\\n<br>tasks. The dhSegment [22] utilizes fully convolutional networks [20] for segmen-\\n<br>tation tasks on historical documents. Object detection-based methods like Faster\\n<br>R-CNN [28] and Mask R-CNN [12] are used for identifying document elements [38]\\n<br>and detecting tables [30, 26]. Most recently, Graph Neural Networks [29] have also\\n<br>been used in table detection [27]. However, these models are usually implemented\\n<br>individually and there is no uni\ufb01ed framework to load and use such models.\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:134px; top:2100px; width:348px; height:189px;\"><span style=\"font-family: CMR10; font-size:9px\">There has been a surge of interest in creating open-source tools for document\\n<br>image processing: a search of </span><span style=\"font-family: CMTT10; font-size:9px\">document image analysis </span><span style=\"font-family: CMR10; font-size:9px\">in Github leads to 5M\\n<br>relevant code pieces </span><span style=\"font-family: CMR7; font-size:6px\">6</span><span style=\"font-family: CMR10; font-size:9px\">; yet most of them rely on traditional rule-based methods\\n<br>or provide limited functionalities. The closest prior research to our work is the\\n<br>OCR-D project</span><span style=\"font-family: CMR7; font-size:6px\">7</span><span style=\"font-family: CMR10; font-size:9px\">, which also tries to build a complete toolkit for DIA. However,\\n<br>similar to the platform developed by Neudecker et al. [21], it is designed for\\n<br>analyzing historical documents, and provides no supports for recent DL models.\\n<br>The </span><span style=\"font-family: CMTT10; font-size:9px\">DocumentLayoutAnalysis </span><span style=\"font-family: CMR10; font-size:9px\">project</span><span style=\"font-family: CMR7; font-size:6px\">8 </span><span style=\"font-family: CMR10; font-size:9px\">focuses on processing born-digital PDF\\n<br>documents via analyzing the stored PDF data. Repositories like </span><span style=\"font-family: CMTT10; font-size:9px\">DeepLayout</span><span style=\"font-family: CMR7; font-size:6px\">9\\n<br></span><span style=\"font-family: CMR10; font-size:9px\">and </span><span style=\"font-family: CMTT10; font-size:9px\">Detectron2-PubLayNet</span><span style=\"font-family: CMR7; font-size:6px\">10 </span><span style=\"font-family: CMR10; font-size:9px\">are individual deep learning models trained on\\n<br>layout analysis datasets without support for the full DIA pipeline. The Document\\n<br>Analysis and Exploitation (DAE) platform [15] and the DeepDIVA project [2]\\n<br>aim to improve the reproducibility of DIA methods (or DL models), yet they\\n<br>are not actively maintained. OCR engines like </span><span style=\"font-family: CMTT10; font-size:9px\">Tesseract </span><span style=\"font-family: CMR10; font-size:9px\">[14], </span><span style=\"font-family: CMTT10; font-size:9px\">easyOCR</span><span style=\"font-family: CMR7; font-size:6px\">11 </span><span style=\"font-family: CMR10; font-size:9px\">and\\n<br></span><span style=\"font-family: CMTT10; font-size:9px\">paddleOCR</span><span style=\"font-family: CMR7; font-size:6px\">12 </span><span style=\"font-family: CMR10; font-size:9px\">usually do not come with comprehensive functionalities for other\\n<br>DIA tasks like layout\n</document>\n<document  description='Overview' language='en' changefreq='weekly' source='https://python.langchain.com/docs/integrations/document_loaders/pdfminer/' title='PDFMiner | \ud83e\udd9c\ufe0f\ud83d\udd17 LangChain' lastmod=None content_type=None priority='0.5' loc='https://python.langchain.com/docs/integrations/document_loaders/pdfminer/' uuid='c86c93ad-5ca1-59e1-8dfe-832cf69ffa35'>\nCMR9; font-size:8px\">the maximum is 1.\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:133px; top:9955px; width:348px; height:10px;\"><span style=\"font-family: CMR6; font-size:5px\">17 </span><span style=\"font-family: CMR9; font-size:8px\">This measures the number of edits from the ground-truth text to the predicted text,\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:144px; top:9967px; width:78px; height:8px;\"><span style=\"font-family: CMR9; font-size:8px\">and lower is better.\\n<br></span></div><span style=\"position:absolute; border: black 1px solid; left:134px; top:9931px; width:56px; height:0px;\"></span>\\n<span style=\"position:absolute; border: gray 1px solid; left:0px; top:10154px; width:612px; height:792px;\"></span>\\n<div style=\"position:absolute; top:10154px;\"><a name=\"13\">Page 13</a></div>\\n<div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:237px; top:10246px; width:210px; height:9px;\"><span style=\"font-family: CMTT9; font-size:8px\">LayoutParser</span><span style=\"font-family: CMR9; font-size:8px\">: A Uni\ufb01ed Toolkit for DL-Based DIA\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:471px; top:10246px; width:9px; height:8px;\"><span style=\"font-family: CMR9; font-size:8px\">13\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:134px; top:10398px; width:346px; height:45px;\"><span style=\"font-family: CMR10; font-size:9px\">Fig. 6: This lightweight table detector can identify tables (outlined in red) and\\n<br>cells (shaded in blue) in di\ufb00erent locations on a page. In very few cases (d), it\\n<br>might generate minor error predictions, e.g, failing to capture the top text line of\\n<br></span><span style=\"font-family: CMR10; font-size:9px\">a table.\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:134px; top:10478px; width:216px; height:9px;\"><span style=\"font-family: CMBX10; font-size:9px\">5.2 A light-weight Visual Table Extractor\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:134px; top:10518px; width:347px; height:81px;\"><span style=\"font-family: CMR10; font-size:9px\">Detecting tables and parsing their structures (table extraction) are of central im-\\n<br>portance for many document digitization tasks. Many previous works [26, 30, 27]\\n<br>and tools </span><span style=\"font-family: CMR7; font-size:6px\">18 </span><span style=\"font-family: CMR10; font-size:9px\">have been developed to identify and parse table structures. Yet they\\n<br>might require training complicated models from scratch, or are only applicable\\n<br>for born-digital PDF documents. In this section, we show how </span><span style=\"font-family: CMTT10; font-size:9px\">LayoutParser </span><span style=\"font-family: CMR10; font-size:9px\">can\\n<br>help build a light-weight accurate visual table extractor for legal docket tables\\n<br>using the existing resources with minimal e\ufb00ort.\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:134px; top:10606px; width:347px; height:177px;\"><span style=\"font-family: CMR10; font-size:9px\">The extractor uses a pre-trained layout detection model for identifying the\\n<br>table regions and some simple rules for pairing the rows and the columns in the\\n<br>PDF image. Mask R-CNN [12] trained on the PubLayNet dataset [38] from the\\n<br></span><span style=\"font-family: CMTT10; font-size:9px\">LayoutParser </span><span style=\"font-family: CMR10; font-size:9px\">Model Zoo can be used for detecting table regions. By \ufb01ltering\\n<br>out model predictions of low con\ufb01dence and removing overlapping predictions,\\n<br></span><span style=\"font-family: CMTT10; font-size:9px\">LayoutParser </span><span style=\"font-family: CMR10; font-size:9px\">can identify the tabular\n</document>\n<document  description='Portable Document Format (PDF), standardized as ISO 32000, is a file format developed by Adobe in 1992 to present documents, including text formatting and images, in a manner independent of application software, hardware, and operating systems.' language='en' changefreq='weekly' source='https://python.langchain.com/docs/how_to/document_loader_pdf/' title='How to load PDFs | \ud83e\udd9c\ufe0f\ud83d\udd17 LangChain' content_type=None lastmod=None priority='0.5' loc='https://python.langchain.com/docs/how_to/document_loader_pdf/' uuid='5a2a91d5-0d47-5a95-8791-d9a4adade490'>\n```output\n{'source': '../../docs/integrations/document_loaders/example_data/layout-parser-paper.pdf', 'page': 0}\n\nLayoutParser : A Uni\ufb01ed Toolkit for Deep\nLearning Based Document Image Analysis\nZejiang Shen1( \ufffd), Ruochen Zhang2, Melissa Dell3, Benjamin Charles Germain\nLee4, Jacob Carlson3, and Weining Li5\n1Allen Institute for AI\nshannons@allenai.org\n2Brown University\nruochen zhang@brown.edu\n3Harvard University\n{melissadell,jacob carlson }@fas.harvard.edu\n4University of Washington\nbcgl@cs.washington.edu\n5University of Waterloo\nw422li@uwaterloo.ca\nAbstract. Recent advances in document image analysis (DIA) have been\nprimarily driven by the application of neural networks. Ideally, research\noutcomes could be easily deployed in production and extended for further\ninvestigation. However, various factors like loosely organized codebases\nand sophisticated model con\ufb01gurations complicate the easy reuse of im-\nportant innovations by a wide audience. Though there have been on-going\ne\ufb00orts to improve reusability and simplify deep learning (DL) model\ndevelopment in disciplines like natural language processing and computer\nvision, none of them are optimized for challenges in the domain of DIA.\nThis represents a major gap in the existing toolkit, as DIA is central to\nacademic research across a wide range of disciplines in the social sciences\nand humanities. This paper introduces LayoutParser , an open-source\nlibrary for streamlining the usage of DL in DIA research and applica-\ntions. The core LayoutParser library comes with a set of simple and\nintuitive interfaces for applying and customizing DL models for layout de-\ntection, character recognition, and many other document processing tasks.\nTo promote extensibility, LayoutParser also incorporates a community\nplatform for sharing both pre-trained models and full document digiti-\nzation pipelines. We demonstrate that LayoutParser is helpful for both\nlightweight and large-scale digitization pipelines in real-word use cases.\nThe library is publicly available at https://layout-parser.github.io .\nKeywords: Document Image Analysis \u00b7Deep Learning \u00b7Layout Analysis\n\u00b7Character Recognition \u00b7Open Source library \u00b7Toolkit.\n1 Introduction\nDeep Learning(DL)-based approaches are the state-of-the-art for a wide range of\ndocument image analysis (DIA) tasks including document image classi\ufb01cation [ 11,arXiv:2103.15348v2  [cs.CV]  21 Jun 2021\n```\n\nNote that the metadata of each document stores the corresponding page number.\n\n### Vector search over PDFs\u200b\n\nOnce we have loaded PDFs into LangChain `Document` objects, we can index them (e.g., a RAG application) in the usual way. Below we use OpenAI embeddings, although any LangChain [embeddings](https://python.langchain.com/docs/concepts/embedding_models) model will suffice.\n\n```python\n%pip install -qU langchain-openai\n```\n\n```python\nimport getpass\nimport os\n\nif \"OPENAI_API_KEY\" not in os.environ:\n    os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"OpenAI API Key:\")\n```\n\n```python\nfrom langchain_core.vectorstores import InMemoryVectorStore\nfrom langchain_openai import OpenAIEmbeddings\n\nvector_store = InMemoryVectorStore.from_documents(pages, OpenAIEmbeddings())\ndocs = vector_store.similarity_search(\"What is LayoutParser?\", k=2)\nfor doc in docs:\n    print(f'Page {doc.metadata[\"page\"]}: {doc.page_content[:300]}\\n')\n```\n\n**API Reference:**[InMemoryVectorStore](https://python.langchain.com/api_reference/core/vectorstores/langchain_core.vectorstores.in_memory.InMemoryVectorStore.html) | [OpenAIEmbeddings](https://python.langchain.com/api_reference/openai/embeddings/langchain_openai.embeddings.base.OpenAIEmbeddings.html)\n```output\nPage 13: 14 Z. Shen et al.\n6 Conclusion\nLayoutParser provides a comprehensive toolkit for deep learning-based document\nimage analysis. The o\ufb00-the-shelf library is easy to install, and can be used to\nbuild \ufb02exible and accurate pipelines for processing documents with complicated\nstructures. It also supports hi\n</document>\n<document  language='en' description='The pace of AI application development is often rate-limited by high-quality evaluations because there is a paradox of choice. Developers often wonder how to engineer their prompt or which LLM best balances accuracy, latency, and cost. High quality evaluations can help you rapidly answer these types of questions with confidence.' changefreq=None source='https://docs.smith.langchain.com/evaluation/concepts' title='Concepts | \ud83e\udd9c\ufe0f\ud83d\udee0\ufe0f LangSmith' content_type='text/html; charset=utf-8' lastmod=None priority=None loc=None uuid='e07006e1-3edd-5630-8851-49f0e2518263'>\nUse CaseDetailReference-free?LLM-as-judge?Pairwise relevantCriteriaTag if specific criteria is metYesYes - promptNoAccuracyStandard definitionNo (ground truth class)NoNoPrecisionStandard definitionNo (ground truth class)NoNoRecallStandard definitionNo (ground truth class)NoNoWas this page helpful?You can leave detailed feedback on GitHub.PreviousQuick StartNextEvaluation how-to guidesDatasetsCreating datasetsPartitioning datasetsEvaluatorsHumanHeuristicLLM-as-judgePairwiseApplying evaluationsUnit TestsRegression TestingBack-testingPairwise-testingOnline EvaluationExperiment ConfigurationsAgentsEvaluating an agent's final responseEvaluating a single step of an agentEvaluating an agent's trajectoryBest practicesRetrieval Augmented Generation (RAG)DatasetEvaluatorApplying RAG EvaluationRAG evaluation summaryCommon use-casesSummarizationClassification / TaggingCommunityDiscordTwitterGitHubDocs CodeLangSmith SDKPythonJS/TSMoreHomepageBlogLangChain Python DocsLangChain JS/TS DocsCopyright \u00a9 2024 LangChain, Inc.\n</document>\n<document  description='AnalyticDB for PostgreSQL is a massively parallel processing (MPP) data warehousing service that is designed to analyze large volumes of data online.' language='en' changefreq='weekly' source='https://python.langchain.com/docs/integrations/vectorstores/analyticdb/' title='AnalyticDB | \ud83e\udd9c\ufe0f\ud83d\udd17 LangChain' content_type=None lastmod=None priority='0.5' loc='https://python.langchain.com/docs/integrations/vectorstores/analyticdb/' uuid='602e584b-8d9f-574d-9391-97abe4a39b64'>\nTonight, I\u2019d like to honor someone who has dedicated his life to serve this country: Justice Stephen Breyer\u2014an Army veteran, Constitutional scholar, and retiring Justice of the United States Supreme Court. Justice Breyer, thank you for your service. \n\nOne of the most serious constitutional responsibilities a President has is nominating someone to serve on the United States Supreme Court. \n\nAnd I did that 4 days ago, when I nominated Circuit Court of Appeals Judge Ketanji Brown Jackson. One of our nation\u2019s top legal minds, who will continue Justice Breyer\u2019s legacy of excellence.\n```\n\n## Related\u200b\n\n- Vector store [conceptual guide](/docs/concepts/vectorstores/)\n\n- Vector store [how-to guides](/docs/how_to/#vector-stores)\n\n#### Was this page helpful?\n\n- [Related](#related)\n</document>\n<document  description='Hologres is a unified real-time data warehousing service developed by Alibaba Cloud. You can use Hologres to write, update, process, and analyze large amounts of data in real time.' language='en' changefreq='weekly' source='https://python.langchain.com/docs/integrations/vectorstores/hologres/' title='Hologres | \ud83e\udd9c\ufe0f\ud83d\udd17 LangChain' content_type=None lastmod=None priority='0.5' loc='https://python.langchain.com/docs/integrations/vectorstores/hologres/' uuid='ab394f69-6b1c-5a06-8672-ad6c91feda6f'>\nTonight, I\u2019d like to honor someone who has dedicated his life to serve this country: Justice Stephen Breyer\u2014an Army veteran, Constitutional scholar, and retiring Justice of the United States Supreme Court. Justice Breyer, thank you for your service. \n\nOne of the most serious constitutional responsibilities a President has is nominating someone to serve on the United States Supreme Court. \n\nAnd I did that 4 days ago, when I nominated Circuit Court of Appeals Judge Ketanji Brown Jackson. One of our nation\u2019s top legal minds, who will continue Justice Breyer\u2019s legacy of excellence.\n```\n\n## Related\u200b\n\n- Vector store [conceptual guide](/docs/concepts/vectorstores/)\n\n- Vector store [how-to guides](/docs/how_to/#vector-stores)\n\n#### Was this page helpful?\n\n- [Related](#related)\n</document>\n<document  description=\"One challenge with retrieval is that usually you don't know the specific queries your document storage system will face when you ingest data into the system. This means that the information most relevant to a query may be buried in a document with a lot of irrelevant text. Passing that full document through your application can lead to more expensive LLM calls and poorer responses.\" language='en' changefreq='weekly' source='https://python.langchain.com/docs/how_to/contextual_compression/' title='How to do retrieval with contextual compression | \ud83e\udd9c\ufe0f\ud83d\udd17 LangChain' lastmod=None content_type=None priority='0.5' loc='https://python.langchain.com/docs/how_to/contextual_compression/' uuid='0e224cfa-3f17-580f-83cd-030c2df600c0'>\ncompressed_docs = compression_retriever.invoke(\n    \"What did the president say about Ketanji Jackson Brown\"\n)\npretty_print_docs(compressed_docs)\n```\n\n**API Reference:**[LLMListwiseRerank](https://python.langchain.com/api_reference/langchain/retrievers/langchain.retrievers.document_compressors.listwise_rerank.LLMListwiseRerank.html) | [ChatOpenAI](https://python.langchain.com/api_reference/openai/chat_models/langchain_openai.chat_models.base.ChatOpenAI.html)\n```output\nDocument 1:\n\nTonight. I call on the Senate to: Pass the Freedom to Vote Act. Pass the John Lewis Voting Rights Act. And while you\u2019re at it, pass the Disclose Act so Americans can know who is funding our elections. \n\nTonight, I\u2019d like to honor someone who has dedicated his life to serve this country: Justice Stephen Breyer\u2014an Army veteran, Constitutional scholar, and retiring Justice of the United States Supreme Court. Justice Breyer, thank you for your service. \n\nOne of the most serious constitutional responsibilities a President has is nominating someone to serve on the United States Supreme Court. \n\nAnd I did that 4 days ago, when I nominated Circuit Court of Appeals Judge Ketanji Brown Jackson. One of our nation\u2019s top legal minds, who will continue Justice Breyer\u2019s legacy of excellence.\n```\n\n### EmbeddingsFilter\u200b\n\nMaking an extra LLM call over each retrieved document is expensive and slow. The `EmbeddingsFilter` provides a cheaper and faster option by embedding the documents and query and only returning those documents which have sufficiently similar embeddings to the query.\n\n```python\nfrom langchain.retrievers.document_compressors import EmbeddingsFilter\nfrom langchain_openai import OpenAIEmbeddings\n\nembeddings = OpenAIEmbeddings()\nembeddings_filter = EmbeddingsFilter(embeddings=embeddings, similarity_threshold=0.76)\ncompression_retriever = ContextualCompressionRetriever(\n    base_compressor=embeddings_filter, base_retriever=retriever\n)\n\ncompressed_docs = compression_retriever.invoke(\n    \"What did the president say about Ketanji Jackson Brown\"\n)\npretty_print_docs(compressed_docs)\n```\n\n**API Reference:**[EmbeddingsFilter](https://python.langchain.com/api_reference/langchain/retrievers/langchain.retrievers.document_compressors.embeddings_filter.EmbeddingsFilter.html) | [OpenAIEmbeddings](https://python.langchain.com/api_reference/openai/embeddings/langchain_openai.embeddings.base.OpenAIEmbeddings.html)\n```output\nDocument 1:\n\nTonight. I call on the Senate to: Pass the Freedom to Vote Act. Pass the John Lewis Voting Rights Act. And while you\u2019re at it, pass the Disclose Act so Americans can know who is funding our elections. \n\nTonight, I\u2019d like to honor someone who has dedicated his life to serve this country: Justice Stephen Breyer\u2014an Army veteran, Constitutional scholar, and retiring Justice of the United States Supreme Court. Justice Breyer, thank you for your service. \n\nOne of the most serious constitutional responsibilities a President has is nominating someone to serve on the United States Supreme Court. \n\nAnd I did that 4 days ago, when I nominated Circuit Court of Appeals Judge Ketanji Brown Jackson. One of our nation\u2019s top legal minds, who will continue Justice Breyer\u2019s legacy of excellence.\n----------------------------------------------------------------------------------------------------\nDocument 2:\n\nA former top litigator in private practice. A former federal public defender. And from a family of public school educators and police officers. A consensus builder. Since she\u2019s been nominated, she\u2019s received a broad range of support\u2014from the Fraternal Order of Police to former judges appointed by Democrats and Republicans. \n\nAnd if we are to advance liberty and justice, we need to secure the Border and fix the immigration system. \n\nWe can do both. At our border, we\u2019ve installed new technology like cutting-edge scanners to better detect drug smuggling.  \n\nWe\u2019ve set up joint patrols with Mexico and Guatemala to catch more human traffickers.\n</document>\n<document  description='This notebook shows how to use DashScope Reranker for document compression and retrieval. DashScope is the generative AI service from Alibaba Cloud (Aliyun).' language='en' changefreq='weekly' source='https://python.langchain.com/docs/integrations/document_transformers/dashscope_rerank/' title='DashScope Reranker | \ud83e\udd9c\ufe0f\ud83d\udd17 LangChain' content_type=None lastmod=None priority='0.5' loc='https://python.langchain.com/docs/integrations/document_transformers/dashscope_rerank/' uuid='a9da7658-305c-5a2e-8f60-e5c6cc7296c2'>\nOne of the most serious constitutional responsibilities a President has is nominating someone to serve on the United States Supreme Court. \n\nAnd I did that 4 days ago, when I nominated Circuit Court of Appeals Judge Ketanji Brown Jackson. One of our nation\u2019s top legal minds, who will continue Justice Breyer\u2019s legacy of excellence.\n----------------------------------------------------------------------------------------------------\nDocument 3:\n\nTo all Americans, I will be honest with you, as I\u2019ve always promised. A Russian dictator, invading a foreign country, has costs around the world. \n\nAnd I\u2019m taking robust action to make sure the pain of our sanctions  is targeted at Russia\u2019s economy. And I will use every tool at our disposal to protect American businesses and consumers. \n\nTonight, I can announce that the United States has worked with 30 other countries to release 60 Million barrels of oil from reserves around the world.\n----------------------------------------------------------------------------------------------------\nDocument 4:\n\nWe cannot let this happen. \n\nTonight. I call on the Senate to: Pass the Freedom to Vote Act. Pass the John Lewis Voting Rights Act. And while you\u2019re at it, pass the Disclose Act so Americans can know who is funding our elections. \n\nTonight, I\u2019d like to honor someone who has dedicated his life to serve this country: Justice Stephen Breyer\u2014an Army veteran, Constitutional scholar, and retiring Justice of the United States Supreme Court. Justice Breyer, thank you for your service.\n----------------------------------------------------------------------------------------------------\nDocument 5:\n\nTonight I say to the Russian oligarchs and corrupt leaders who have bilked billions of dollars off this violent regime no more. \n\nThe U.S. Department of Justice is assembling a dedicated task force to go after the crimes of Russian oligarchs.  \n\nWe are joining with our European allies to find and seize your yachts your luxury apartments your private jets. We are coming for your ill-begotten gains.\n----------------------------------------------------------------------------------------------------\nDocument 6:\n\nEvery Administration says they\u2019ll do it, but we are actually doing it. \n\nWe will buy American to make sure everything from the deck of an aircraft carrier to the steel on highway guardrails are made in America. \n\nBut to compete for the best jobs of the future, we also need to level the playing field with China and other competitors.\n----------------------------------------------------------------------------------------------------\nDocument 7:\n\nWhen we invest in our workers, when we build the economy from the bottom up and the middle out together, we can do something we haven\u2019t done in a long time: build a better America. \n\nFor more than two years, COVID-19 has impacted every decision in our lives and the life of the nation. \n\nAnd I know you\u2019re tired, frustrated, and exhausted. \n\nBut I also know this.\n----------------------------------------------------------------------------------------------------\nDocument 8:\n\nA former top litigator in private practice. A former federal public defender. And from a family of public school educators and police officers. A consensus builder. Since she\u2019s been nominated, she\u2019s received a broad range of support\u2014from the Fraternal Order of Police to former judges appointed by Democrats and Republicans. \n\nAnd if we are to advance liberty and justice, we need to secure the Border and fix the immigration system.\n----------------------------------------------------------------------------------------------------\nDocument 9:\n\nMy plan will not only lower costs to give families a fair shot, it will lower the deficit. \n\nThe previous Administration not only ballooned the deficit with tax cuts for the very wealthy and corporations, it undermined the watchdogs whose job was to keep pandemic relief funds from being wasted.\n</document>\n<document  description='When splitting documents for retrieval, there are often conflicting desires:' language='en' changefreq='weekly' source='https://python.langchain.com/docs/how_to/parent_document_retriever/' title='How to use the Parent Document Retriever | \ud83e\udd9c\ufe0f\ud83d\udd17 LangChain' lastmod=None content_type=None priority='0.5' loc='https://python.langchain.com/docs/how_to/parent_document_retriever/' uuid='5c24f9cf-90e6-52f4-8da6-d8535cfad74d'>\n```python\nretrieved_docs = retriever.invoke(\"justice breyer\")\n```\n\n```python\nlen(retrieved_docs[0].page_content)\n```\n\n```output\n38540\n```\n\n## Retrieving larger chunks\u200b\n\nSometimes, the full documents can be too big to want to retrieve them as is. In that case, what we really want to do is to first split the raw documents into larger chunks, and then split it into smaller chunks. We then index the smaller chunks, but on retrieval we retrieve the larger chunks (but still not the full documents).\n\n```python\n# This text splitter is used to create the parent documents\nparent_splitter = RecursiveCharacterTextSplitter(chunk_size=2000)\n# This text splitter is used to create the child documents\n# It should create documents smaller than the parent\nchild_splitter = RecursiveCharacterTextSplitter(chunk_size=400)\n# The vectorstore to use to index the child chunks\nvectorstore = Chroma(\n    collection_name=\"split_parents\", embedding_function=OpenAIEmbeddings()\n)\n# The storage layer for the parent documents\nstore = InMemoryStore()\n```\n\n```python\nretriever = ParentDocumentRetriever(\n    vectorstore=vectorstore,\n    docstore=store,\n    child_splitter=child_splitter,\n    parent_splitter=parent_splitter,\n)\n```\n\n```python\nretriever.add_documents(docs)\n```\n\nWe can see that there are much more than two documents now - these are the larger chunks.\n\n```python\nlen(list(store.yield_keys()))\n```\n\n```output\n66\n```\n\nLet's make sure the underlying vector store still retrieves the small chunks.\n\n```python\nsub_docs = vectorstore.similarity_search(\"justice breyer\")\n```\n\n```python\nprint(sub_docs[0].page_content)\n```\n\n```output\nTonight, I\u2019d like to honor someone who has dedicated his life to serve this country: Justice Stephen Breyer\u2014an Army veteran, Constitutional scholar, and retiring Justice of the United States Supreme Court. Justice Breyer, thank you for your service. \n\nOne of the most serious constitutional responsibilities a President has is nominating someone to serve on the United States Supreme Court.\n```\n\n```python\nretrieved_docs = retriever.invoke(\"justice breyer\")\n```\n\n```python\nlen(retrieved_docs[0].page_content)\n```\n\n```output\n1849\n```\n\n```python\nprint(retrieved_docs[0].page_content)\n```\n\n```output\nIn state after state, new laws have been passed, not only to suppress the vote, but to subvert entire elections. \n\nWe cannot let this happen. \n\nTonight. I call on the Senate to: Pass the Freedom to Vote Act. Pass the John Lewis Voting Rights Act. And while you\u2019re at it, pass the Disclose Act so Americans can know who is funding our elections. \n\nTonight, I\u2019d like to honor someone who has dedicated his life to serve this country: Justice Stephen Breyer\u2014an Army veteran, Constitutional scholar, and retiring Justice of the United States Supreme Court. Justice Breyer, thank you for your service. \n\nOne of the most serious constitutional responsibilities a President has is nominating someone to serve on the United States Supreme Court. \n\nAnd I did that 4 days ago, when I nominated Circuit Court of Appeals Judge Ketanji Brown Jackson. One of our nation\u2019s top legal minds, who will continue Justice Breyer\u2019s legacy of excellence. \n\nA former top litigator in private practice. A former federal public defender. And from a family of public school educators and police officers. A consensus builder. Since she\u2019s been nominated, she\u2019s received a broad range of support\u2014from the Fraternal Order of Police to former judges appointed by Democrats and Republicans. \n\nAnd if we are to advance liberty and justice, we need to secure the Border and fix the immigration system. \n\nWe can do both. At our border, we\u2019ve installed new technology like cutting-edge scanners to better detect drug smuggling.  \n\nWe\u2019ve set up joint patrols with Mexico and Guatemala to catch more human traffickers.  \n\nWe\u2019re putting in place dedicated immigration judges so families fleeing persecution and violence can have their cases heard faster.\n</document>\n<document  description='UpTrain [github || website || docs] is an open-source platform to evaluate and improve LLM applications. It provides grades for 20+ preconfigured checks (covering language, code, embedding use cases), performs root cause analyses on instances of failure cases and provides guidance for resolving them.' language='en' changefreq='weekly' source='https://python.langchain.com/docs/integrations/callbacks/uptrain/' title='uptrain | \ud83e\udd9c\ufe0f\ud83d\udd17 LangChain' lastmod=None content_type=None priority='0.5' loc='https://python.langchain.com/docs/integrations/callbacks/uptrain/' uuid='6c5602df-140a-5c31-b5f5-cc188744c2ee'>\nQuestion: What did the president say about Ketanji Brown Jackson\nResponse: The president mentioned that he had nominated Ketanji Brown Jackson to serve on the United States Supreme Court 4 days ago. He described her as one of the nation's top legal minds who will continue Justice Breyer\u2019s legacy of excellence. He also mentioned that she is a former top litigator in private practice, a former federal public defender, and comes from a family of public school educators and police officers. He described her as a consensus builder and noted that since her nomination, she has received a broad range of support from various groups, including the Fraternal Order of Police and former judges appointed by both Democrats and Republicans.\n\nContext Relevance Score: 1.0\nFactual Accuracy Score: 1.0\nResponse Completeness Score: 1.0\n```\n\n# 2. Multi Query Generation\n\nThe **MultiQueryRetriever** is used to tackle the problem that the RAG pipeline might not return the best set of documents based on the query. It generates multiple queries that mean the same as the original query and then fetches documents for each.\n\nTo evluate this retriever, UpTrain will run the following evaluation:\n\n- **Multi Query Accuracy**: Checks if the multi-queries generated mean the same as the original query.\n\n```python\n# Create the retriever\nmulti_query_retriever = MultiQueryRetriever.from_llm(retriever=retriever, llm=llm)\n\n# Create the uptrain callback\nuptrain_callback = UpTrainCallbackHandler(key_type=KEY_TYPE, api_key=API_KEY)\nconfig = {\"callbacks\": [uptrain_callback]}\n\n# Create the RAG prompt\ntemplate = \"\"\"Answer the question based only on the following context, which can include text and tables:\n{context}\nQuestion: {question}\n\"\"\"\nrag_prompt_text = ChatPromptTemplate.from_template(template)\n\nchain = (\n    {\"context\": multi_query_retriever, \"question\": RunnablePassthrough()}\n    | rag_prompt_text\n    | llm\n    | StrOutputParser()\n)\n\n# Invoke the chain with a query\nquestion = \"What did the president say about Ketanji Brown Jackson\"\ndocs = chain.invoke(question, config=config)\n```\n\n```output\n[32m2024-04-17 17:04:10.675[0m | [1mINFO    [0m | [36muptrain.framework.evalllm[0m:[36mevaluate_on_server[0m:[36m378[0m - [1mSending evaluation request for rows 0 to <50 to the Uptrain[0m\n[32m2024-04-17 17:04:16.804[0m | [1mINFO    [0m | [36muptrain.framework.evalllm[0m:[36mevaluate[0m:[36m367[0m - [1mLocal server not running, start the server to log data and visualize in the dashboard![0m\n``````output\n\nQuestion: What did the president say about Ketanji Brown Jackson\nMulti Queries:\n  - How did the president comment on Ketanji Brown Jackson?\n  - What were the president's remarks regarding Ketanji Brown Jackson?\n  - What statements has the president made about Ketanji Brown Jackson?\n\nMulti Query Accuracy Score: 0.5\n``````output\n[32m2024-04-17 17:04:22.027[0m | [1mINFO    [0m | [36muptrain.framework.evalllm[0m:[36mevaluate_on_server[0m:[36m378[0m - [1mSending evaluation request for rows 0 to <50 to the Uptrain[0m\n[32m2024-04-17 17:04:44.033[0m | [1mINFO    [0m | [36muptrain.framework.evalllm[0m:[36mevaluate[0m:[36m367[0m - [1mLocal server not running, start the server to log data and visualize in the dashboard![0m\n``````output\n\nQuestion: What did the president say about Ketanji Brown Jackson\nResponse: The president mentioned that he had nominated Circuit Court of Appeals Judge Ketanji Brown Jackson to serve on the United States Supreme Court 4 days ago. He described her as one of the nation's top legal minds who will continue Justice Breyer\u2019s legacy of excellence. He also mentioned that since her nomination, she has received a broad range of support\u2014from the Fraternal Order of Police to former judges appointed by Democrats and Republicans.\n\nContext Relevance Score: 1.0\nFactual Accuracy Score: 1.0\nResponse Completeness Score: 1.0\n```\n\n# 3. Context Compression and Reranking\n</document>\n<document  language='en' description='Timescale Vector is PostgreSQL++ vector database for AI applications.' changefreq='weekly' source='https://python.langchain.com/docs/integrations/vectorstores/timescalevector/' title='Timescale Vector (Postgres) | \ud83e\udd9c\ufe0f\ud83d\udd17 LangChain' content_type=None lastmod=None priority='0.5' loc='https://python.langchain.com/docs/integrations/vectorstores/timescalevector/' uuid='97b75c76-ec70-52a3-a5bc-f34f7df23687'>\nTonight, I\u2019d like to honor someone who has dedicated his life to serve this country: Justice Stephen Breyer\u2014an Army veteran, Constitutional scholar, and retiring Justice of the United States Supreme Court. Justice Breyer, thank you for your service. \n\nOne of the most serious constitutional responsibilities a President has is nominating someone to serve on the United States Supreme Court. \n\nAnd I did that 4 days ago, when I nominated Circuit Court of Appeals Judge Ketanji Brown Jackson. One of our nation\u2019s top legal minds, who will continue Justice Breyer\u2019s legacy of excellence.\n--------------------------------------------------------------------------------\n--------------------------------------------------------------------------------\nScore:  0.18452197313308139\nTonight. I call on the Senate to: Pass the Freedom to Vote Act. Pass the John Lewis Voting Rights Act. And while you\u2019re at it, pass the Disclose Act so Americans can know who is funding our elections. \n\nTonight, I\u2019d like to honor someone who has dedicated his life to serve this country: Justice Stephen Breyer\u2014an Army veteran, Constitutional scholar, and retiring Justice of the United States Supreme Court. Justice Breyer, thank you for your service. \n\nOne of the most serious constitutional responsibilities a President has is nominating someone to serve on the United States Supreme Court. \n\nAnd I did that 4 days ago, when I nominated Circuit Court of Appeals Judge Ketanji Brown Jackson. One of our nation\u2019s top legal minds, who will continue Justice Breyer\u2019s legacy of excellence.\n--------------------------------------------------------------------------------\n--------------------------------------------------------------------------------\nScore:  0.21720781018594182\nA former top litigator in private practice. A former federal public defender. And from a family of public school educators and police officers. A consensus builder. Since she\u2019s been nominated, she\u2019s received a broad range of support\u2014from the Fraternal Order of Police to former judges appointed by Democrats and Republicans. \n\nAnd if we are to advance liberty and justice, we need to secure the Border and fix the immigration system. \n\nWe can do both. At our border, we\u2019ve installed new technology like cutting-edge scanners to better detect drug smuggling.  \n\nWe\u2019ve set up joint patrols with Mexico and Guatemala to catch more human traffickers.  \n\nWe\u2019re putting in place dedicated immigration judges so families fleeing persecution and violence can have their cases heard faster. \n\nWe\u2019re securing commitments and supporting partners in South and Central America to host more refugees and secure their own borders.\n--------------------------------------------------------------------------------\n--------------------------------------------------------------------------------\nScore:  0.21724902288621384\nA former top litigator in private practice. A former federal public defender. And from a family of public school educators and police officers. A consensus builder. Since she\u2019s been nominated, she\u2019s received a broad range of support\u2014from the Fraternal Order of Police to former judges appointed by Democrats and Republicans. \n\nAnd if we are to advance liberty and justice, we need to secure the Border and fix the immigration system. \n\nWe can do both. At our border, we\u2019ve installed new technology like cutting-edge scanners to better detect drug smuggling.  \n\nWe\u2019ve set up joint patrols with Mexico and Guatemala to catch more human traffickers.  \n\nWe\u2019re putting in place dedicated immigration judges so families fleeing persecution and violence can have their cases heard faster. \n\nWe\u2019re securing commitments and supporting partners in South and Central America to host more refugees and secure their own borders.\n--------------------------------------------------------------------------------\n```\n\n### Using a Timescale Vector as a Retriever\u200b\n</document>\n<document  description=\"Intel's VDMS is a storage solution for efficient access of big-\u201dvisual\u201d-data that aims to achieve cloud scale by searching for relevant visual data via visual metadata stored as a graph and enabling machine friendly enhancements to visual data for faster access. VDMS is licensed under MIT.\" language='en' changefreq='weekly' source='https://python.langchain.com/docs/integrations/vectorstores/vdms/' title=\"Intel's Visual Data Management System (VDMS) | \ud83e\udd9c\ufe0f\ud83d\udd17 LangChain\" lastmod=None content_type=None priority='0.5' loc='https://python.langchain.com/docs/integrations/vectorstores/vdms/' uuid='4f15705d-8620-58e1-9dfd-0218bc8b858c'>\nMetadata:\n\tid:\t32\n\tpage_number:\t32\n\tpresident_included:\tTrue\n\tsource:\t../../how_to/state_of_the_union.txt\n--------------------------------------------------\n\nContent:\n\tAs Frances Haugen, who is here with us tonight, has shown, we must hold social media platforms accountable for the national experiment they\u2019re conducting on our children for profit. \n\nIt\u2019s time to strengthen privacy protections, ban targeted advertising to children, demand tech companies stop collecting personal data on our children. \n\nAnd let\u2019s get all Americans the mental health services they need. More people they can turn to for help, and full parity between physical and mental health care. \n\nThird, support our veterans. \n\nVeterans are the best of us. \n\nI\u2019ve always believed that we have a sacred obligation to equip all those we send to war and care for them and their families when they come home. \n\nMy administration is providing assistance with job training and housing, and now helping lower-income veterans get VA care debt-free.  \n\nOur troops in Iraq and Afghanistan faced many dangers.\n\nMetadata:\n\tid:\t37\n\tpage_number:\t37\n\tpresident_included:\tFalse\n\tsource:\t../../how_to/state_of_the_union.txt\n--------------------------------------------------\n\nContent:\n\tA former top litigator in private practice. A former federal public defender. And from a family of public school educators and police officers. A consensus builder. Since she\u2019s been nominated, she\u2019s received a broad range of support\u2014from the Fraternal Order of Police to former judges appointed by Democrats and Republicans. \n\nAnd if we are to advance liberty and justice, we need to secure the Border and fix the immigration system. \n\nWe can do both. At our border, we\u2019ve installed new technology like cutting-edge scanners to better detect drug smuggling.  \n\nWe\u2019ve set up joint patrols with Mexico and Guatemala to catch more human traffickers.  \n\nWe\u2019re putting in place dedicated immigration judges so families fleeing persecution and violence can have their cases heard faster. \n\nWe\u2019re securing commitments and supporting partners in South and Central America to host more refugees and secure their own borders.\n\nMetadata:\n\tid:\t33\n\tpage_number:\t33\n\tpresident_included:\tFalse\n\tsource:\t../../how_to/state_of_the_union.txt\n--------------------------------------------------\n```\n\n```python\n# Query (with filtering)\nk = 3\nconstraints = {\"page_number\": [\">\", 30], \"president_included\": [\"==\", True]}\nquery = \"What did the president say about Ketanji Brown Jackson\"\nreturned_docs = db_FaissFlat.similarity_search(query, k=k, filter=constraints)\nprint_results(returned_docs, score=False)\n```\n\n```output\n--------------------------------------------------\n\nContent:\n\tTonight. I call on the Senate to: Pass the Freedom to Vote Act. Pass the John Lewis Voting Rights Act. And while you\u2019re at it, pass the Disclose Act so Americans can know who is funding our elections. \n\nTonight, I\u2019d like to honor someone who has dedicated his life to serve this country: Justice Stephen Breyer\u2014an Army veteran, Constitutional scholar, and retiring Justice of the United States Supreme Court. Justice Breyer, thank you for your service. \n\nOne of the most serious constitutional responsibilities a President has is nominating someone to serve on the United States Supreme Court. \n\nAnd I did that 4 days ago, when I nominated Circuit Court of Appeals Judge Ketanji Brown Jackson. One of our nation\u2019s top legal minds, who will continue Justice Breyer\u2019s legacy of excellence.\n\nMetadata:\n\tid:\t32\n\tpage_number:\t32\n\tpresident_included:\tTrue\n\tsource:\t../../how_to/state_of_the_union.txt\n--------------------------------------------------\n\nContent:\n\tAnd for our LGBTQ+ Americans, let\u2019s finally get the bipartisan Equality Act to my desk. The onslaught of state laws targeting transgender Americans and their families is wrong.\n</document>\n<document  description=\"When working with files, like PDFs, you're likely to encounter text that exceeds your language model's context window. To process this text, consider these strategies:\" language='en' changefreq='weekly' source='https://python.langchain.com/docs/how_to/extraction_long_text/' title='How to handle long text when doing extraction | \ud83e\udd9c\ufe0f\ud83d\udd17 LangChain' content_type=None lastmod=None priority='0.5' loc='https://python.langchain.com/docs/how_to/extraction_long_text/' uuid='7dfd32a5-8904-50c5-b15c-624f51caf4e1'>\nWe suggest experimenting with your use case and determining whether this approach works or not.\n\nTo implement the RAG based approach:\n\n1. Chunk up your document(s) and index them (e.g., in a vectorstore);\n\n2. Prepend the `extractor` chain with a retrieval step using the vectorstore.\n\nHere's a simple example that relies on the `FAISS` vectorstore.\n\n```python\nfrom langchain_community.vectorstores import FAISS\nfrom langchain_core.documents import Document\nfrom langchain_core.runnables import RunnableLambda\nfrom langchain_openai import OpenAIEmbeddings\nfrom langchain_text_splitters import CharacterTextSplitter\n\ntexts = text_splitter.split_text(document.page_content)\nvectorstore = FAISS.from_texts(texts, embedding=OpenAIEmbeddings())\n\nretriever = vectorstore.as_retriever(\n    search_kwargs={\"k\": 1}\n)  # Only extract from first document\n```\n\n**API Reference:**[FAISS](https://python.langchain.com/api_reference/community/vectorstores/langchain_community.vectorstores.faiss.FAISS.html) | [Document](https://python.langchain.com/api_reference/core/documents/langchain_core.documents.base.Document.html) | [RunnableLambda](https://python.langchain.com/api_reference/core/runnables/langchain_core.runnables.base.RunnableLambda.html) | [OpenAIEmbeddings](https://python.langchain.com/api_reference/openai/embeddings/langchain_openai.embeddings.base.OpenAIEmbeddings.html) | [CharacterTextSplitter](https://python.langchain.com/api_reference/text_splitters/character/langchain_text_splitters.character.CharacterTextSplitter.html)\nIn this case the RAG extractor is only looking at the top document.\n\n```python\nrag_extractor = {\n    \"text\": retriever | (lambda docs: docs[0].page_content)  # fetch content of top doc\n} | extractor\n```\n\n```python\nresults = rag_extractor.invoke(\"Key developments associated with cars\")\n```\n\n```python\nfor key_development in results.key_developments:\n    print(key_development)\n```\n\n```output\nyear=2006 description='Car-sharing services in the US experienced double-digit growth in revenue and membership.' evidence='in the US, some car-sharing services have experienced double-digit growth in revenue and membership growth between 2006 and 2007.'\nyear=2020 description='56 million cars were manufactured worldwide, with China producing the most.' evidence='In 2020, there were 56 million cars manufactured worldwide, down from 67 million the previous year. The automotive industry in China produces by far the most (20 million in 2020).'\n```\n\n## Common issues\u200b\n\nDifferent methods have their own pros and cons related to cost, speed, and accuracy.\n\nWatch out for these issues:\n\n- Chunking content means that the LLM can fail to extract information if the information is spread across multiple chunks.\n\n- Large chunk overlap may cause the same information to be extracted twice, so be prepared to de-duplicate!\n\n- LLMs can make up data. If looking for a single fact across a large text and using a brute force approach, you may end up getting more made up data.\n\n#### Was this page helpful?\n\n- [Setup](#setup)\n\n- [Define the schema](#define-the-schema)\n\n- [Create an extractor](#create-an-extractor)\n\n- [Brute force approach](#brute-force-approach)- [Merge results](#merge-results)\n\n- [RAG based approach](#rag-based-approach)\n\n- [Common issues](#common-issues)\n</document>\n<document  description=\"When working with files, like PDFs, you're likely to encounter text that exceeds your language model's context window. To process this text, consider these strategies:\" language='en' changefreq='weekly' source='https://python.langchain.com/docs/how_to/extraction_long_text/' title='How to handle long text when doing extraction | \ud83e\udd9c\ufe0f\ud83d\udd17 LangChain' lastmod=None content_type=None priority='0.5' loc='https://python.langchain.com/docs/how_to/extraction_long_text/' uuid='5c687db0-8502-5dc9-8617-22f2d5ecf7f1'>\n```python\nkey_developments = []\n\nfor extraction in extractions:\n    key_developments.extend(extraction.key_developments)\n\nkey_developments[:10]\n```\n\n```output\n[KeyDevelopment(year=1769, description='Nicolas-Joseph Cugnot built the first full-scale, self-propelled mechanical vehicle, a steam-powered tricycle.', evidence='Nicolas-Joseph Cugnot is widely credited with building the first full-scale, self-propelled mechanical vehicle in about 1769; he created a steam-powered tricycle.'),\n KeyDevelopment(year=1807, description=\"Nic\u00e9phore Ni\u00e9pce and his brother Claude created what was probably the world's first internal combustion engine.\", evidence=\"In 1807, Nic\u00e9phore Ni\u00e9pce and his brother Claude created what was probably the world's first internal combustion engine (which they called a Pyr\u00e9olophore), but installed it in a boat on the river Saone in France.\"),\n KeyDevelopment(year=1886, description='Carl Benz patented the Benz Patent-Motorwagen, marking the birth of the modern car.', evidence='In November 1881, French inventor Gustave Trouv\u00e9 demonstrated a three-wheeled car powered by electricity at the International Exposition of Electricity. Although several other German engineers (including Gottlieb Daimler, Wilhelm Maybach, and Siegfried Marcus) were working on cars at about the same time, the year 1886 is regarded as the birth year of the modern car\u2014a practical, marketable automobile for everyday use\u2014when the German Carl Benz patented his Benz Patent-Motorwagen; he is generally acknowledged as the inventor of the car.'),\n KeyDevelopment(year=1886, description='Carl Benz began promotion of his vehicle, marking the introduction of the first commercially available automobile.', evidence='Benz began promotion of the vehicle on 3 July 1886.'),\n KeyDevelopment(year=1888, description=\"Bertha Benz undertook the first road trip by car to prove the road-worthiness of her husband's invention.\", evidence=\"In August 1888, Bertha Benz, the wife and business partner of Carl Benz, undertook the first road trip by car, to prove the road-worthiness of her husband's invention.\"),\n KeyDevelopment(year=1896, description='Benz designed and patented the first internal-combustion flat engine, called boxermotor.', evidence='In 1896, Benz designed and patented the first internal-combustion flat engine, called boxermotor.'),\n KeyDevelopment(year=1897, description='The first motor car in central Europe and one of the first factory-made cars in the world, the Pr\u00e4sident automobil, was produced by Nesselsdorfer Wagenbau.', evidence='The first motor car in central Europe and one of the first factory-made cars in the world, was produced by Czech company Nesselsdorfer Wagenbau (later renamed to Tatra) in 1897, the Pr\u00e4sident automobil.'),\n KeyDevelopment(year=1901, description='Ransom Olds started large-scale, production-line manufacturing of affordable cars at his Oldsmobile factory in Lansing, Michigan.', evidence='Large-scale, production-line manufacturing of affordable cars was started by Ransom Olds in 1901 at his Oldsmobile factory in Lansing, Michigan.'),\n KeyDevelopment(year=1913, description=\"Henry Ford introduced the world's first moving assembly line for cars at the Highland Park Ford Plant.\", evidence=\"This concept was greatly expanded by Henry Ford, beginning in 1913 with the world's first moving assembly line for cars at the Highland Park Ford Plant.\")]\n```\n\n## RAG based approach\u200b\n\nAnother simple idea is to chunk up the text, but instead of extracting information from every chunk, just focus on the the most relevant chunks.\n\ncautionIt can be difficult to identify which chunks are relevant.\n\nFor example, in the `car` article we're using here, most of the article contains key development information. So by using\n**RAG**, we'll likely be throwing out a lot of relevant information.\n\nWe suggest experimenting with your use case and determining whether this approach works or not.\n\nTo implement the RAG based approach:\n</document>\n<document  description='This guide assumes familiarity with the following concepts:' language='en' changefreq='weekly' source='https://python.langchain.com/docs/tutorials/extraction/' title='Build an Extraction Chain | \ud83e\udd9c\ufe0f\ud83d\udd17 LangChain' lastmod=None content_type=None priority='0.5' loc='https://python.langchain.com/docs/tutorials/extraction/' uuid='f4b59370-e4c5-529d-9adc-b2a6eb8d4eef'>\nclass Data(BaseModel):\n    \"\"\"Extracted data about people.\"\"\"\n\n    # Creates a model so that we can extract multiple entities.\n    people: List[Person]\n```\n\nimportantExtraction might not be perfect here. Please continue to see how to use **Reference Examples** to improve the quality of extraction, and see the **guidelines** section!\n\n```python\nrunnable = prompt | llm.with_structured_output(schema=Data)\ntext = \"My name is Jeff, my hair is black and i am 6 feet tall. Anna has the same color hair as me.\"\nrunnable.invoke({\"text\": text})\n```\n\n```output\nData(people=[Person(name='Jeff', hair_color=None, height_in_meters=None), Person(name='Anna', hair_color=None, height_in_meters=None)])\n```\n\ntipWhen the schema accommodates the extraction of **multiple entities**, it also allows the model to extract **no entities** if no relevant information\nis in the text by providing an empty list.\n\nThis is usually a **good** thing! It allows specifying **required** attributes on an entity without necessarily forcing the model to detect this entity.\n\nWe can see the LangSmith trace here: [https://smith.langchain.com/public/7173764d-5e76-45fe-8496-84460bd9cdef/r](https://smith.langchain.com/public/7173764d-5e76-45fe-8496-84460bd9cdef/r)\n\n## Next steps\u200b\n\nNow that you understand the basics of extraction with LangChain, you're ready to proceed to the rest of the how-to guides:\n\n- [Add Examples](/docs/how_to/extraction_examples/): Learn how to use **reference examples** to improve performance.\n\n- [Handle Long Text](/docs/how_to/extraction_long_text/): What should you do if the text does not fit into the context window of the LLM?\n\n- [Use a Parsing Approach](/docs/how_to/extraction_parse/): Use a prompt based approach to extract with models that do not support **tool/function calling**.\n\n#### Was this page helpful?\n\n- [Setup](#setup)- [Jupyter Notebook](#jupyter-notebook)\n\n- [Installation](#installation)\n\n- [LangSmith](#langsmith)\n\n- [The Schema](#the-schema)\n\n- [The Extractor](#the-extractor)\n\n- [Multiple Entities](#multiple-entities)\n\n- [Next steps](#next-steps)\n</document>\n<document  language='en' description='This Jupyter Notebook demonstrates how to use Eden AI tools with an Agent.' changefreq='weekly' source='https://python.langchain.com/docs/integrations/tools/edenai_tools/' title='Eden AI | \ud83e\udd9c\ufe0f\ud83d\udd17 LangChain' lastmod=None content_type=None priority='0.5' loc='https://python.langchain.com/docs/integrations/tools/edenai_tools/' uuid='c2b59f24-a6ed-5923-b04e-763734df2c8f'>\nyou can have more details of the execution by printing the result\n\n```python\nresult\n```\n\n```output\n{'input': ' i have this url of an image : \"https://static.javatpoint.com/images/objects.jpg\"\\n                   first : i want to know if the image contain objects .\\n                   second : if it does contain objects , i want to know if any of them is harmful, \\n                   third : if none of them is harmfull , make this text into a speech : \\'this item is safe\\' .\\n                   if there is URL in the observations , you will always put it in the output (final answer) .\\n                   ',\n 'output': \"The image contains objects such as Apple, Backpack, Luggage & bags, and Container. None of them are harmful. The text 'this item is safe' can be found in the audio file at https://d14uq1pz7dzsdq.cloudfront.net/0546db8b-528e-4b63-9a69-d14d43ad1566_.mp3?Expires=1693316753&Signature=N0KZeK9I-1s7wTgiQOAwH7LFlltwyonSJcDnkdnr8JIJmbgSw6fo6RTxWl~VvD2Hg6igJqxtJFFWyrBmmx-f9wWLw3bZSnuMxkhTRqLX9aUA9N-vPJGiRZV5BFredaOm8pwfo8TcXhVjw08iSxv8GSuyZEIwZkiq4PzdiyVTnKKji6eyt\",\n 'intermediate_steps': [(AgentAction(tool='edenai_object_detection', tool_input='https://static.javatpoint.com/images/objects.jpg', log=' I need to determine if the image contains objects, if any of them are harmful, and then convert the text to speech.\\nAction: edenai_object_detection\\nAction Input: https://static.javatpoint.com/images/objects.jpg'),\n   'Apple - Confidence 0.94003654\\nApple - Confidence 0.94003654\\nApple - Confidence 0.94003654\\nBackpack - Confidence 0.7481894\\nBackpack - Confidence 0.7481894\\nBackpack - Confidence 0.7481894\\nLuggage & bags - Confidence 0.70691586\\nLuggage & bags - Confidence 0.70691586\\nLuggage & bags - Confidence 0.70691586\\nContainer - Confidence 0.654727\\nContainer - Confidence 0.654727\\nContainer - Confidence 0.654727\\nLuggage & bags - Confidence 0.5871518\\nLuggage & bags - Confidence 0.5871518\\nLuggage & bags - Confidence 0.5871518'),\n  (AgentAction(tool='edenai_explicit_content_detection_text', tool_input='Apple, Backpack, Luggage & bags, Container', log=' I need to check if any of the objects are harmful.\\nAction: edenai_explicit_content_detection_text\\nAction Input: Apple, Backpack, Luggage & bags, Container'),\n   'nsfw_likelihood: 2\\n\"sexually explicit\": 1\\n\"sexually suggestive\": 2\\n\"offensive\": 1\\nnsfw_likelihood: 1\\n\"sexual\": 1\\n\"hate\": 1\\n\"harassment\": 1\\n\"self-harm\": 1\\n\"sexual/minors\": 1\\n\"hate/threatening\": 1\\n\"violence/graphic\": 1\\n\"self-harm/intent\": 1\\n\"self-harm/instructions\": 1\\n\"harassment/threatening\": 1\\n\"violence\": 1'),\n  (AgentAction(tool='edenai_text_to_speech', tool_input=\"'this item is safe'\", log=\" None of the objects are harmful.\\nAction: edenai_text_to_speech\\nAction Input: 'this item is safe'\"),\n   'https://d14uq1pz7dzsdq.cloudfront.net/0546db8b-528e-4b63-9a69-d14d43ad1566_.mp3?Expires=1693316753&Signature=N0KZeK9I-1s7wTgiQOAwH7LFlltwyonSJcDnkdnr8JIJmbgSw6fo6RTxWl~VvD2Hg6igJqxtJFFWyrBmmx-f9wWLw3bZSnuMxkhTRqLX9aUA9N-vPJGiRZV5BFredaOm8pwfo8TcXhVjw08iSxv8GSuyZEIwZkiq4PzdiyVTnKKji6eytV0CrnHrTs~eXZkSnOdD2Fu0ECaKvFHlsF4IDLI8efRvituSk0X3ygdec4HQojl5vmBXJzi1TuhKWOX8UxeQle8pdjjqUPSJ9thTHpucdPy6UbhZOH0C9rbtLrCfvK5rzrT4D~gKy9woICzG34tKRxNxHYVVUPqx2BiInA__&Key-Pair-Id=K1F55BTI9AHGIK')]}\n```\n\n## Example with OCR images\u200b\n\n```python\ninput_ = \"\"\"i have this url of an id: \"https://www.citizencard.com/images/citizencard-uk-id-card-2023.jpg\"\ni want to extract the information in it.\ncreate a text welcoming the person by his name and make it into speech .\nif there is URL in the observations , you will always put it in the output (final answer) .\n\"\"\"\nresult = agent_chain(input_)\n```\n\n```output\n</document>\n</documents>\n<context/>", "type": "system"}}, {"lc": 1, "type": "constructor", "id": ["langchain", "schema", "messages", "HumanMessage"], "kwargs": {"content": "how do i upload a pdf", "type": "human", "id": "acdae6e0-4fa7-459f-8906-67b9372aba8f"}}, {"lc": 1, "type": "constructor", "id": ["langchain", "schema", "messages", "AIMessage"], "kwargs": {"content": "To upload a PDF using LangChain, you can utilize the `PDFMinerLoader` or `PDFPlumberLoader`. Here\u2019s a brief overview of how to do it with each loader:\n\n### Using PDFMinerLoader\n1. **Install the required package**:\n   ```bash\n   pip install langchain_community\n   ```\n\n2. **Load the PDF**:\n   ```python\n   from langchain_community.document_loaders import PDFMinerLoader\n\n   file_path = \"./path_to_your_pdf/document.pdf\"\n   loader = PDFMinerLoader(file_path)\n   docs = loader.load()\n   ```\n\n### Using PDFPlumberLoader\n1. **Install the required package**:\n   ```bash\n   pip install langchain_community\n   ```\n\n2. **Load the PDF**:\n   ```python\n   from langchain_community.document_loaders import PDFPlumberLoader\n\n   loader = PDFPlumberLoader(\"./path_to_your_pdf/document.pdf\")\n   docs = loader.load()\n   ```\n\n### Notes\n- Both loaders will return a list of documents, where each document corresponds to a page in the PDF.\n- No special credentials are needed to use these loaders.\n\nFor more detailed information, you can refer to the API references for [PDFMinerLoader](https://python.langchain.com/api_reference/community/document_loaders/langchain_community.document_loaders.pdf.PDFMinerLoader.html) and [PDFPlumberLoader](https://python.langchain.com/api_reference/community/document_loaders/langchain_community.document_loaders.pdf.PDFPlumberLoader.html).", "response_metadata": {"finish_reason": "stop", "model_name": "gpt-4o-mini-2024-07-18", "system_fingerprint": "fp_0705bf87c0"}, "type": "ai", "id": "run-646bc662-d299-4ff8-9700-03482e843756", "tool_calls": [], "invalid_tool_calls": []}}, {"lc": 1, "type": "constructor", "id": ["langchain", "schema", "messages", "HumanMessage"], "kwargs": {"content": "https://www.cambridge.org/core/services/aop-cambridge-core/content/view/0D4357A9A6150E706CC261B86BA47733/S0008423923000793a.pdf/ascent_of_the_canadian_judicial_council_bill_c9_and_the_move_towards_judicialized_governance.pdf  can you open this to answer questions for me ", "type": "human", "id": "97919fe7-0599-486c-90d0-7355c6c587d1"}}]]}
